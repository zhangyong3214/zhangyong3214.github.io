{"meta":{"title":"tankの记忆","subtitle":"积极乐观，喜欢软件","description":"欢迎来到tankの记忆","author":"tank","url":"https://zhangyong3214.github.io","root":"/"},"pages":[{"title":"分类","date":"2022-01-27T08:31:13.129Z","updated":"2022-01-27T08:31:13.129Z","comments":true,"path":"categories/index.html","permalink":"https://zhangyong3214.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2022-04-05T09:32:31.595Z","updated":"2022-04-05T09:32:31.595Z","comments":true,"path":"css/custom.css","permalink":"https://zhangyong3214.github.io/css/custom.css","excerpt":"","text":"/* 文章页H1-H6图标样式效果 */ h1::before, h2::before, h3::before, h4::before, h5::before, h6::before { -webkit-animation: ccc 1.6s linear infinite ; animation: ccc 1.6s linear infinite ; } @-webkit-keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } @keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } #content-inner.layout h1::before { color: #ef50a8 ; margin-left: -1.55rem; font-size: 1.3rem; margin-top: -0.23rem; } #content-inner.layout h2::before { color: #fb7061 ; margin-left: -1.35rem; font-size: 1.1rem; margin-top: -0.12rem; } #content-inner.layout h3::before { color: #ffbf00 ; margin-left: -1.22rem; font-size: 0.95rem; margin-top: -0.09rem; } #content-inner.layout h4::before { color: #a9e000 ; margin-left: -1.05rem; font-size: 0.8rem; margin-top: -0.09rem; } #content-inner.layout h5::before { color: #57c850 ; margin-left: -0.9rem; font-size: 0.7rem; margin-top: 0.0rem; } #content-inner.layout h6::before { color: #5ec1e0 ; margin-left: -0.9rem; font-size: 0.66rem; margin-top: 0.0rem; } #content-inner.layout h1:hover, #content-inner.layout h2:hover, #content-inner.layout h3:hover, #content-inner.layout h4:hover, #content-inner.layout h5:hover, #content-inner.layout h6:hover { color: #49b1f5 ; } #content-inner.layout h1:hover::before, #content-inner.layout h2:hover::before, #content-inner.layout h3:hover::before, #content-inner.layout h4:hover::before, #content-inner.layout h5:hover::before, #content-inner.layout h6:hover::before { color: #49b1f5 ; -webkit-animation: ccc 3.2s linear infinite ; animation: ccc 3.2s linear infinite ; } /* 页面设置icon转动速度调整 */ #rightside_config i.fas.fa-cog.fa-spin { animation: fa-spin 5s linear infinite ; } /*--------更换字体------------*/ @font-face { font-family: 'tzy'; /* 字体名自定义即可 */ src: url('https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/font/ZhuZiAWan.woff2'); /* 字体文件路径 */ font-display: swap; } body, .gitcalendar { font-family: tzy !important; } .categoryBar-list { max-height: 400px; } .clock-row { overflow: hidden; text-overflow: ellipsis; } /*3s为加载动画的时间，1为加载动画的次数，ease-in-out为动画效果*/ #page-header, #web_bg { -webkit-animation: imgblur 2s 1 ease-in-out; animation: imgblur 2s 1 ease-in-out; } @keyframes imgblur { 0% { filter: blur(5px); } 100% { filter: blur(0px); } } /*适配使用-webkit内核的浏览器 */ @-webkit-keyframes imgblur { 0% { -webkit-filter: blur(5px); } 100% { -webkit-filter: blur(0px); } } .table-wrap img { margin: .6rem auto .1rem !important; } /* 标签外挂 网站卡片 start */ .site-card-group img { margin: 0 auto .1rem !important; } .site-card-group .info a img { margin-right: 10px !important; } [data-theme='dark'] .site-card-group .site-card .info .title { color: #f0f0f0 !important; } [data-theme='dark'] .site-card-group .site-card .info .desc { color: rgba(255, 255, 255, .7) !important; } .site-card-group .info .desc { margin-top: 4px !important; } /* 代码块颜色 */ figure.highlight pre .addition { color: #00bf03 !important; }"},{"title":"","date":"2022-04-05T09:32:31.667Z","updated":"2022-04-05T09:32:31.667Z","comments":true,"path":"js/chocolate.js","permalink":"https://zhangyong3214.github.io/js/chocolate.js","excerpt":"","text":"/* * @Author: tzy1997 * @Date: 2020-12-15 20:55:25 * @LastEditors: tzy1997 * @LastEditTime: 2021-01-12 19:02:25 */ // 友情链接页面 头像找不到时 替换图片 if (location.href.indexOf(\"link\") !== -1) { var imgObj = document.getElementsByTagName(\"img\"); for (i = 0; i < imgObj.length; i++) { imgObj[i].onerror = function() { this.src = \"https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/theme_f/friend_404.gif\" } } } $(function() { // 气泡 function bubble() { $('#page-header').circleMagic({ radius: 10, density: .2, color: 'rgba(255,255,255,.4)', clearOffset: 0.99 }); }! function(p) { p.fn.circleMagic = function(t) { var o, a, n, r, e = !0, i = [], d = p.extend({ color: \"rgba(255,0,0,.5)\", radius: 10, density: .3, clearOffset: .2 }, t), l = this[0]; function c() { e = !(document.body.scrollTop > a) } function s() { o = l.clientWidth, a = l.clientHeight, l.height = a + \"px\", n.width = o, n.height = a } function h() { if (e) for (var t in r.clearRect(0, 0, o, a), i) i[t].draw(); requestAnimationFrame(h) } function f() { var t = this; function e() { t.pos.x = Math.random() * o, t.pos.y = a + 100 * Math.random(), t.alpha = .1 + Math.random() * d.clearOffset, t.scale = .1 + .3 * Math.random(), t.speed = Math.random(), \"random\" === d.color ? t.color = \"rgba(\" + Math.floor(255 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.random().toPrecision(2) + \")\" : t.color = d.color } t.pos = {}, e(), this.draw = function() { t.alpha"},{"title":"标签","date":"2022-01-27T08:31:13.242Z","updated":"2022-01-27T08:31:13.242Z","comments":true,"path":"tags/index.html","permalink":"https://zhangyong3214.github.io/tags/index.html","excerpt":"","text":""},{"title":"留言板","date":"2022-01-27T08:31:13.242Z","updated":"2022-01-27T08:31:13.242Z","comments":true,"path":"message/index.html","permalink":"https://zhangyong3214.github.io/message/index.html","excerpt":"","text":"本页面还在开发中……"},{"title":"关于我","date":"2022-04-05T09:32:31.668Z","updated":"2022-04-05T09:32:31.668Z","comments":true,"path":"关于我/index.html","permalink":"https://zhangyong3214.github.io/%E5%85%B3%E4%BA%8E%E6%88%91/index.html","excerpt":"","text":"关于我一个记性不好的人，通过结构化的文档记录自己的前进之路。 偶遇良友，一起前行….."},{"title":"关于我","date":"2022-04-05T09:32:31.669Z","updated":"2022-04-05T09:32:31.669Z","comments":true,"path":"关于我/index_bak.html","permalink":"https://zhangyong3214.github.io/%E5%85%B3%E4%BA%8E%E6%88%91/index_bak.html","excerpt":"","text":"关于我十年生死两茫茫,写程序，到天亮。千行代码，Bug何处藏。纵使上线又怎样，朝令改，夕断肠。领导每天新想法，天天改，日日忙。 相顾无言，惟有泪千行。每晚灯火阑珊处，程序员，又加班，工作狂~ 来一张楼主无美颜生活照，见笑了！🤣🤣🤣 基本信息 类别 信息 出生年月 1990年2月 现居地 北京市朝阳区 籍贯 辽宁省锦州市 邮箱 &#x38;&#x33;&#x34;&#54;&#x31;&#51;&#50;&#64;&#113;&#x71;&#46;&#99;&#111;&#109; 教育经历 时间 学校 专业 备注 2009.09~2013.07 沈阳化工大学 电子科学与技术 统招本科 2006.09~2009.07 辽宁省北镇市高级中学 高级基础教育 市重点 工作经历 时间 公司 职位 2021.04~至今 龙湖集团 Java 开发工程师 2017.05~2021.04 包头市包银消费金融股份有限公司 Java 开发工程师 2016.09~2017.04 大连灵动科技发展有限公司 Java 开发工程师 2013.07~2016.08 大连安吉尼尔科技有限公司 Java 开发工程师 专业技能 Java 基础扎实、掌握 JVM 原理、多线程、网络原理、设计模式、常用的数据结构和算法 熟悉 Windows、Mac、Linux 操作系统，熟练使用 linux 常用操作指令 熟练使用 IntelliJ IDEA 开发工具(及各种插件)、熟练使用 Git 版本同步工具 阅读过 Spring、SpringMVC、等开源框架源码，理解其设计原理及底层架构，具备框架定制开发能力 理解 Redis 线程模型，Netty 线程模型，掌握基于响应式的异步非阻塞模型的基本原理，了解 Webflux 熟练掌握分布式缓存 Redis、Elaticsearch，对分布式锁，幂等等常见问题有深入研究及多年实战经验 熟悉常见消息中间件的使用，有多年 RabbitMQ 的实战开发经验，对高级消息队列有深入理解 熟练掌握 Mysql 事务，索引，锁，SQL 优化相关知识，可根据业务场景给出详细及高性能设计方案 熟练使用数据库操作框架 Mybatis、Mybatsi-plus 进行高效业务功能开发 掌握 springCloud 相关框架，对 SpringBoot、SpringCloud 原理有一定了解，有成熟项目经验 熟悉定时任务及延迟任务等业务相关设计，如 xxl-job，延迟消息等相关技术有多年开发经验 熟悉微服务思想，MVC 分层，DDD 理论，服务拆分，治理，监控，服务熔断，降级等相关能力 熟悉 jvm 原理，熟悉垃圾回收以 jvm 性能调优技术，有过线上服务器性能监测及调优经验 熟悉多线程及线程池使用，有多年多线程业务处理经验，封装过多线程批处理工具类等公用组建 了解 Mysql 分库分表相关原理，如 Sardingsphere、Mycat 等框架有相关使用经验 了解操作系统底层原理以及 C、C++程序开发，对计算机底层原理有初步了解 了解前端开发，了解 html，css，js，vue 等前端技术，对前端开发有一定的了解 研究过单片机等硬件开发，喜欢科技产品，喜欢软件，喜欢折腾各种电子产品以及软件 项目经验​ 项目经验只写了在北京之后参与过的相关项目，在大连做的项目偏向于传统，项目也都是单点部署，主要用的框架都是spring、mybatis、Hibernate、springMVC等相互结合使用，即：SSM，SSH，相比于springBoot来说不值一提，现在应该没有几个公司还没用springBoot了吧(#^.^#)，值得一提的是，刚毕业那会，做了半年的C语言嵌入式开发，外包到大连东软做对日的佳能相机系统，虽然目前我已经做了多年的java开发，但是那毕竟是我第一次参加开发项目，人都是有初恋情节的嘛，对自己的第一次念念不忘(我指得是工作🤭)，那半年让我对硬件底层有了一些理解，也算是最大的收获了吧。 —— 包银消费金融(现名：蒙商消费) ——​ 包头市包银消费金融股份有限公司是经中国银监会批准成立的持牌消费金融公司，由包商银行发起设立，包银消费金融为个人消费者提供消费信贷服务。其主要合作渠道有：证大财富，京东金条，微粒贷，去哪儿，京东借贷平台，分期乐，小米等多家放款渠道。目前，已累计完成 1200 多万客户注册和 320 多亿放款规模。 acs：核心交易系统主要包含信贷核算业务和虚拟账户业务，信贷核算主要负责借还款、核销减免交易、利息、罚息计提、各种费用等业务的计算和落地，日终生成交易流水文件供会计核算系统生成会计分录；虚拟账户部分主要为清结算人员提供交易产生的不同资金账户金额的变化及资金流向，为清结算人员对账提供数据支持；系统可以处理每分钟峰值 640 多笔授信申请，每小时峰值 2 万笔授信申请，贷后支持每小时 17 万客户数据。核心日终处理量达 152 万笔(借据数量)。 gls：财务核算系统对核心交易系统日终生成的交易流水解析之后按照分录借贷规则生成财务分录文件交给金蝶系统，17 年财务核算系统是买来的系统，19 年由我重新开发出属于公司自己的财务核算系统，并增加了财务对账功能(核心交易系统和财务分录对账)，不但及时发现线上交易的错误数据，及时解决问题，更提升了月终对账，年结的效率，实现了财务对账自动化，解决了年结人工对账的痛点。 ecif：渠道系统要负责对接第三方引流渠道，客户通过第三方渠道授信、借款，渠道引流到包银，由于不同渠道的授信、放款业务逻辑不同，针对不同渠道提供不同的功能开发。其中部分渠道积累一天客户授信请求指定时间统一发送授信申请到包银，系统可处理每分钟 800 笔授信请求。 css：清结算系统此系统是公司内部清结算人员使用的内部业务系统，主要功能有个人溢缴款账户管理、对公付款、对私付款、退款以及清结算同事转账业务的发起和审核功能 联合贷款系统主要功能有联合贷款协议，路由配置，路由规则，借据还款计划拆分，资方授信，借据、交易流水文件，联合贷款授信影音资料推送 监管报送系统按照监管报送需求，对借据(每月报送全量数据)，还款计划，还款流水，客户，产品，核销，借款申请，资产证券化，五级分类等信息进行加工之后推送给监管报送系统 自我评价业精于勤，荒于嬉 、行成于思，毁于随。 性格乐观开朗，话痨，热爱生活，喜欢拍视频记录生活，喜欢分享知识，分享技术，分享生活中的点点滴滴，脾气好，怕老婆 个人爱好 电子科技产品 软件 —— 喜欢win、Mac、Android 好用无广告软件研究及分享 足球 —— 喜欢但是没机会玩，怀念高中时代呀…. 三国杀 —— 基本已经被凉企逼到退游了….而且生活中也很难找到一起玩这个游戏的朋友了🤣 逛B站 —— 生活区和科技区一个不知名阿婆主😂，佛系更新视频 👉 点击打开我的B站个人空间 记得三连 👍👍👍 看电影 —— 喜欢科幻、漫威粉、追斗罗大陆….."},{"title":"技术笔记","date":"2022-01-27T08:31:13.243Z","updated":"2022-01-27T08:31:13.243Z","comments":true,"path":"技术笔记/index.html","permalink":"https://zhangyong3214.github.io/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/index.html","excerpt":"","text":"我是技术笔记"}],"posts":[{"title":"","slug":"学习笔记/网络编程","date":"2022-04-13T11:17:46.547Z","updated":"2022-04-14T12:36:54.875Z","comments":true,"path":"2022/04/13/学习笔记/网络编程/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","excerpt":"","text":"1、深入理解网络通讯1.1 计算机网络发展历史 计算机网络的标准定义是:利用通信线路将地理上分散的、具有独立功能的计算机系统 和通信设备按不同的形式连接起来，以功能完善的网络软件及协议实现资源共享和信息传递 的系统。 1.2 网络分类 局域网 城域网 广域网 1.3 网络发展历史 美国国防部，设计一种离散的，去中心话的网络拓扑。 互联网产品开始发展。 OSI：七层模型，理论模型。OSI参考模型。 IEEE：五层模型。实践化模型。TCP/IP模型。 1.4 OSI七层模型 应用层：为应用层提供服务 表示层：数据格式转化、数据加密 会话层：建立、管理和维护会话 传输层：建立、管理和维护端到端的链接 网络层：IP地址以及路由选择 数据链路层：提供介质访问和链路管理 物理层：物理层 1.5 TCP/IP五层模型 应用层：http,https的协议层。 传输层：tcp协议。操作系统完成的。 网络层：IP地址。操作系统完成的。 数据链路层：近似网卡驱动程序。mac地址。 物理层：对应计算机的网卡和网线。 1.6 TCP/IP协议簇 所有公开的：https://www.rfc-editor.org/ DPTK： 1.7 TCP/IP网络术语 数据包(packet) 报文/消息(message)：应用协议的数据单位。 报文段(segment)：TCP数据流信息 数据报(datagram):IP中的数据单位。 帧(frame):用于数据链路层的包单位 1.8 IP地址和MAC地址 IP地址 DHCH分配。手动配置。 IPV4：4个字节。IPv6 ip地址作用在网络层。 不同子网寻址方式。 MAC地址/物理地址 用网卡制造商，写在硬件上的。总共6位16进制。mac地址主要在数据链路层。 同一个子网内通过mac地址寻址。 1.9 TCP特性 面向连接的协议 TCP提供的是一种可靠的数据流服务，数据有可能呗差费 具体过程 客户端和服务端 1、客户端发起报文给服务端，进行连接请求。SYN=1;seq=随机值x。客户端进入syn_send 2、服务端基于连接进行响应。SYN=1;ACK=1;ack_no = x+1;seq_no=随机数y;服务端进入syn_revd 3、客户端再次响应服务端。ACK=1;ack_no = y+1.客户端进入ESTABleSHED,服务端也进入ESTABleSHED； 2、BIO、NIO编程与直接内存、零拷贝深入辨析 WireShark:https://www.wireshark.org/.抓包工具。 2.0 NIO三大组件 Slector Channel Buffer 2.1 Reactor模式类型 单线程Reactor模式 单线程Reactor，工作线程池模式 多线程主从Reactor mainReactor主线程只处理网络链接 subReactor处理读写数据。 ThreadPool处理业务逻辑。 3、深入Linux内核理解epoll4、Netty使用常用组件解析4.1","categories":[],"tags":[]},{"title":"数据结构与算法","slug":"面试基地/算法刷题记录","date":"2022-04-11T16:00:00.000Z","updated":"2022-04-21T02:42:18.901Z","comments":true,"path":"2022/04/12/面试基地/算法刷题记录/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/12/%E9%9D%A2%E8%AF%95%E5%9F%BA%E5%9C%B0/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"常见算法技巧巧用位运算1、如果和char字符串变为一个int整形 ,不能强转,通过减去’0’ 123char c = &#x27;0&#x27;;int i = (int)c;//实际值为48，ASCII的值，详细请查看:https://easeapi.com/tool/asciiint j = c -&#x27;0&#x27;;// 结果为0 2、巧用与或运算。int数或0x00000000,int数与0xffffffff 123int a = 100;int b = a | 0x00000000;//结果是100，int c = a &amp; 0xffffffff;//结果是100 3、巧用位运算。奇偶数判断，用a&amp;1 12int num = 31;int num1 = num &amp; 1;//想想下二进制的8421,只要为的最后一位为1，那它一定是基数，否则就是偶数 4、巧用异或 a^a = 0,a^0=a;异或进行数据交换 12345int x = 1;int y = 2;x = x^y;//记住原本xy的属性，相当于tempy = x^y;//(x^y)^y=x^(y^y)=x^0=x,完成y=x的交换x = x^y;//x^y^x=(x^x)^y=0^y=y,完成x=y的交换 5、高效找中间值 1234int a = 1;// 0int b = 2;//length-1int middle = (a+b)/2;//越界int middle = b-(b-a)&lt;&lt;1; 常见技巧6、动态规划五部曲 来源于代码随想录的解法思路 确定dp数组（dp table）以及下标的含义 确定递推公式 dp数组如何初始化 确定遍历顺序 举例推导dp数组 7、双指针解法 8、滑动窗口解法 9、树的深度遍历和广度遍历解法 10、贪心算法 11、动态规划 12、递归解法 确定递归函数的参数和返回值 确定终止条件 确定单层递归逻辑 常见算法二分查找算法 有序集合，时间复杂度为O(logN) 12345678910111213141516171819public static int binaryQuery(int[] arr, int target) &#123; if (arr == null || arr.length == 0) &#123; return -1; &#125; int left = 0; int right = arr.length - 1; while (left &lt;= right) &#123; // 其中中间值可以 优化为 int mid = right - ((right-left)&gt;&gt;1); int mid = (left + right) / 2; if (arr[mid] == target) &#123; return mid; &#125; else if (arr[mid] &gt; target) &#123; right = mid - 1; &#125; else &#123; left = mid + 1; &#125; &#125; return -1; &#125; 常见算法题单链表反转 遍历方式反转 通过遍历形式反转，需要记录保存全局当前节点和前一个节点，循环内为了防止断链，通过局域变量保存下一个。 1234567891011121314151617public static ListNode revertList(ListNode head) &#123; // 给下一个节点使用 ListNode pre = null; ListNode current = head; while (current != null) &#123; // 保存下一个节点，防止断链 ListNode next = current.next; // 当前节点指向上一个节点 current.next = pre; // 把新的当前节点记录下来，给下一个节点使用 pre = current; // 移动处理 current = next; &#125; return pre; &#125; 递归形式反转 递归形式反转需要注意递归的三条原则。1.大问题可以拆为小问题。2.小问题的求解方式和大问题一样。3.小问题存在解。参考斐波拉切数的解决方案。 1234567891011public static ListNode revertList2(ListNode head) &#123; if (head == null || head.next == null) &#123; return head; &#125; // 递，一直拆分，知道剩下一个节点。假设我们的只剩下两个节点head和head.next ListNode revert = revertList2(head.next); // 归并，如果有两个节点 head.next.next = head;//把下一个节点的next指向自己，这个时候是个双链表 head.next = x,x.next=head; head.next = null;//断开本身的链接 return revert; &#125; 异位字符串 https://leetcode-cn.com/problems/valid-anagram/ 错误思路，通过每个字符进行异或不行，因为可能出现aa和bb这种情况，所以必须要知道每个字符出现的次数。 通过hash表进行进行映射，hash表的巧妙使用方式 12345678910111213141516171819202122232425public static boolean solution3(String param1, String param2) &#123; if (s == null || t == null) &#123; return false; &#125; if (s.length() != t.length()) &#123; return false; &#125; // 字符-&#x27;a&#x27;代表是相对的位置，ASCII int[] record = new int[26]; for (int i = 0; i &lt; s.length(); i++) &#123; // 该字符出现次数 record[s.charAt(i) - &#x27;a&#x27;]++; &#125; for (int i = 0; i &lt; t.length(); i++) &#123; // 减一 record[s.charAt(i) - &#x27;a&#x27;]--; &#125; for (int i = 0; i &lt; record.length; i++) &#123; // 如果存在不为0的位置，该字符没出现， if (record[i] != 0) &#123; return false; &#125; &#125; return true;&#125; 两数之和 https://leetcode-cn.com/problems/two-sum/submissions/ easy 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 通过HashMap进行数据的存储，注意缓存中数据应该在0位置 123456789101112131415161718public int[] twoNumSum(int[] nums, int target) &#123; int[] result = new int[2]; if (nums == null || nums.length &lt; 2) &#123; return result; &#125; HashMap&lt;Integer, Integer&gt; cache = new HashMap(); for (int i = 0; i &lt; nums.length; i++) &#123; Integer second = nums[i]; Integer first = target - second; if (cache.containsKey(first)) &#123; result[1] = i; result[0] = cache.get(first); return result; &#125; cache.put(second, i); &#125; return result; &#125; 大数相加 https://leetcode-cn.com/problems/add-strings/ 给定两个字符串形式的非负整数 num1 和num2 ，计算它们的和并同样以字符串形式返回。 你不能使用任何內建的用于处理大整数的库（比如 BigInteger）， 也不能直接将输入的字符串转换为整数形式。 把两个值进行比较，如果长度不一致改成前面补0，后续进行按位想加，有进位注意考虑 注意int num = char-‘0’ 解法二：双指指针，从后往前递归。注意点 1.carry用完要置0.2、最后要补0,3、字符串要反转 1234567891011121314151617181920212223242526272829303132333435363738public String addStrings(String num1, String num2) &#123; int carry = 0; boolean firstBigger = num1.length()&gt;=num2.length(); int length = firstBigger?num1.length():num2.length(); if(firstBigger)&#123; // 前面补0，让两个长度一致 int differ = length-num2.length(); StringBuffer sb = new StringBuffer(); for(int i=0;i&lt;differ;i++)&#123; sb.append(&quot;0&quot;); &#125; sb.append(num2); num2 = sb.toString(); &#125;else&#123; int differ = length-num1.length(); StringBuffer sb = new StringBuffer(); for(int i=0;i&lt;differ;i++)&#123; sb.append(&quot;0&quot;); &#125; sb.append(num1); num1 = sb.toString(); &#125; StringBuffer sb = new StringBuffer(); for(int i = length-1;i&gt;=0;i--)&#123; int sum = num1.charAt(i)-&#x27;0&#x27;+num2.charAt(i)-&#x27;0&#x27;+carry; if(sum&gt;=10)&#123; carry = 1; sum -= 10; &#125;else&#123; carry = 0; &#125; sb.append(sum); &#125; if(carry == 1)&#123; sb.append(&#x27;1&#x27;); &#125; return sb.reverse().toString(); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 通过双指针处理 * 注意用完carry的置0操作 * @param num1 * @param num2 * @return */ public static String bigNumberAdd3(String num1, String num2) &#123; if (num1 == null &amp;&amp; num2 == null) &#123; return null; &#125; if(num1 == null )&#123; return num2; &#125; if(num2 == null)&#123; return num1; &#125; int carry = 0; // 第一个数的开始位置 int i = num1.length()-1; // 第二个数的开始位置 int j = num2.length()-1; StringBuffer sb = new StringBuffer(); while(i &gt;=0 || j&gt;=0)&#123; int fNum = i&lt;0?0:num1.charAt(i)-&#x27;0&#x27;; int sNum = j&lt;0?0:num2.charAt(j)-&#x27;0&#x27;; int sum = fNum + sNum + carry; if(sum&gt;=10)&#123; carry = 1; sum -= 10; &#125;else&#123;// 注意一定要置0 carry = 0; &#125; sb.append(sum); i--; j--; &#125; if(carry&gt;0)&#123; sb.append(&#x27;1&#x27;); &#125; return sb.reverse().toString(); &#125; 最长回文子串 https://leetcode-cn.com/problems/longest-palindromic-substring/ 给你一个字符串 s，找到 s 中最长的回文子串。 思路一：第一步找到所有回文的字符串，第二步，找最长的子串 思路二：动态规划 思路三：双指针 1234567891011121314151617181920212223public String longestPalindrome(String s) &#123; String s1 = &quot;&quot;; String s2 = &quot;&quot;; String res = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) &#123; // 分两种情况：即一个元素作为中心点，两个元素作为中心点 s1 = extend(s, i, i); // 情况1 res = s1.length() &gt; res.length() ? s1 : res; s2 = extend(s, i, i + 1); // 情况2 res = s2.length() &gt; res.length() ? s2 : res; &#125; return res; // 返回最长的 &#125; public String extend(String s, int start, int end)&#123; String tmp = &quot;&quot;; while (start &gt;= 0 &amp;&amp; end &lt; s.length() &amp;&amp; s.charAt(start) == s.charAt(end))&#123; tmp = s.substring(start, end + 1); // Java中substring是左闭右开的，所以要+1 // 向两边扩散 start--; end++; &#125; return tmp; &#125; 找小于给定数的最大数 给定一个数n，如23121;给定一组数字A如{2,4,9}，求由A中元素组成的、小于n的最大数。如小于23121的最大数为22999。 思路一、分析解法。确定第一 求一棵树的最小深度 注意最小深度是指通过root到各个叶子节点最短的距离 解法一：树的深度优先。递归，通过子节点开始计算。递归处理。 解法二：树的广度优先。找到子节点结束。层级遍历。 解法一 123456789101112131415public static int treeDeep(TreeNode root) &#123; //1、判断边界值 if (root == null) &#123; return 0; &#125; int leftMinDeep = treeDeep(root.left); int rightMinDeep = treeDeep(root.right); if (root.left == null &amp;&amp; root.right != null) &#123; return 1 + rightMinDeep; &#125; if (root.right == null &amp;&amp; root.left != null) &#123; return 1 + leftMinDeep; &#125; return Math.min(leftMinDeep + 1, rightMinDeep + 1); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 通过广度优先遍历 * * @param root * @return */ public static int treeDeep1(TreeNode root) &#123; // 1、边界值判断 if (root == null) &#123; return 0; &#125; if (root.left == null &amp;&amp; root.right == null) &#123; return 1; &#125; // 2、通过容器保存进行层级遍历 Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); root.deep = 1; queue.offer(root); // 3、遍历容器 while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); // 4、退出条件判断 if (node.left == null &amp;&amp; node.right == null) &#123; return node.deep; &#125; // 5、补充容器 if (node.left != null) &#123; node.left.deep = node.deep + 1; queue.offer(node.left); &#125; if (node.right != null) &#123; node.right.deep = node.deep + 1; queue.offer(node.right); &#125; &#125; return 0; &#125; static class TreeNode &#123; int value; TreeNode left; TreeNode right; /** * 增加深度字段 */ int deep; public TreeNode(int value, TreeNode left, TreeNode right) &#123; this.value = value; this.left = left; this.right = right; &#125; &#125; 路径之和 https://leetcode-cn.com/problems/path-sum/ 给你二叉树的根节点 root 和一个表示目标和的整数 targetSum 。判断该树中是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 targetSum 。如果存在，返回 true ；否则，返回 false 。 解法1：递归解法。1、递归方法。f(x)=hasPathSum(TreeNode,int),2、终止条件，节点为null或者找到target节点，但是该节点为叶子节点。3、确定单层逻辑。左右节点找target-root.val取并集; 解法2: 123456789public boolean hasPathSum(TreeNode root, int targetSum) &#123; if(root==null)&#123; return false; &#125; if(root.val == targetSum&amp;&amp;root.left==null&amp;&amp;root.right == null)&#123; return true; &#125; return hasPathSum(root.left,targetSum-root.val)||hasPathSum(root.right,targetSum-root.val);&#125; 二叉树的遍历 二叉树的前序遍历：根左右 二叉树的中序遍历：左根右 二叉树的后续遍历：左右根 二叉树的层级遍历：按照树的深度进行遍历 三种遍历方式：递归遍历。迭代遍历。 123456789101112131415161718class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; // 通过递归形式打印 List&lt;Integer&gt; result = new LinkedList(); inOrder(root,result); return result; &#125; private void inOrder(TreeNode root,List&lt;Integer&gt; result)&#123; if(root == null)&#123; return ; &#125; inOrder(root.left,result); // 放入数组的时机代表什么遍历顺序。这是中序 result.add(root.val); inOrder(root.right,result); &#125;&#125; 层级遍历 1234567891011121314151617181920212223public static List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); if (root == null) &#123; return list; &#125; levelOrder(root, 1, list); return list; &#125; private static void levelOrder(TreeNode root, int index, List&lt;List&lt;Integer&gt;&gt; list) &#123; List&lt;Integer&gt; cList = new LinkedList&lt;&gt;(); // 初始化一下数组防止空指针 if (list.size() &lt; index) &#123; list.add(new ArrayList&lt;&gt;()); &#125; list.get(index - 1).add(root.val); if (root.left != null) &#123; levelOrder(root.left, index + 1, list); &#125; if (root.right != null) &#123; levelOrder(root.right, index + 1, list); &#125; &#125; 递归解法-先序遍历 123456789101112131415161718// 先序遍历的层级遍历 根左右 public static void preOrder1(TreeNode root) &#123; if (root == null) &#123; return; &#125; Stack&lt;TreeNode&gt; stack = new Stack(); stack.push(root); while (!stack.isEmpty()) &#123; TreeNode treeNode = stack.pop(); System.out.println(treeNode.val); if (treeNode.right != null) &#123; stack.push(treeNode.right); &#125; if (treeNode.left != null) &#123; stack.push(treeNode.left); &#125; &#125; &#125; 判断一个树是否另一个树的子树 给定两个非空二叉树 s 和 t，检验 s 中是否包含和 t 具有相同结构和节点值的子树。s 的一个子树包括 s 的一个节点和这个节点的所有子孙。s 也可以看做它自身的一棵子树。 两个树都是空树，返回true 如果两个树一个是空，一个不是空，不包含 两个树都是非空a）比较根节点的值是不是相等，如果相等的话，比较一下s和t是不是相同的树b）递归的判定一下，t是否被s的左子树包含c）递归的判定一下，t是否被s的右子树包含。 https://leetcode-cn.com/problems/subtree-of-another-tree/ 12345678910111213141516171819202122public static boolean isSubTree(TreeNode father, TreeNode child) &#123; if (father == null &amp;&amp; child == null) &#123; return true; &#125; if (father == null || child == null) &#123; return false; &#125; return isSameTree(father.left, child) || isSameTree(father.right, child) || isSameTree(father, child); &#125; private static boolean isSameTree(TreeNode left, TreeNode child) &#123; if (left == null &amp;&amp; left == null) &#123; return true; &#125; if (left == null || child == null) &#123; return false; &#125; if (left.val != child.val) &#123; return false; &#125; return isSameTree(left.left, left.left) &amp;&amp; isSameTree(left.right, child.right); &#125; 求给数组中组合的小于目前数的最大数 给定一个数 n，如 23121；给定一组数字 A 如 {2,4,9}，求由 A 中元素组成的、小于 n 的最大数，如小于 23121 的最大数为 22999。","categories":[{"name":"算法刷题","slug":"算法刷题","permalink":"https://zhangyong3214.github.io/categories/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98/"}],"tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zhangyong3214.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"","slug":"学习笔记/Dubbo","date":"2022-04-07T12:28:22.613Z","updated":"2022-04-07T14:03:37.720Z","comments":true,"path":"2022/04/07/学习笔记/Dubbo/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Dubbo/","excerpt":"","text":"Apache Dubbo 是一款高性能、轻量级的开源服务框架 Dubbo 入门分布式RPC的通用方案","categories":[],"tags":[]},{"title":"军事级别安全强度，免费密码管理工具KeePass，永远滴神","slug":"软件工具/免费密码管理工具KeePass永远的神","date":"2022-04-05T09:32:31.592Z","updated":"2022-04-05T09:32:31.592Z","comments":true,"path":"2022/04/05/软件工具/免费密码管理工具KeePass永远的神/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E5%85%8D%E8%B4%B9%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7KeePass%E6%B0%B8%E8%BF%9C%E7%9A%84%E7%A5%9E/","excerpt":"","text":"前言​ 欢迎大家收看本篇文章对应B站视频解说：👉 点此跳转B站视频解说教程 👈 ​ 大家好，我是喜欢科技，喜欢分享，喜欢软件，喜欢折腾，有洁癖又有强迫症的科技农名工—李苟蛋，今天我来给大家分享一款密码管理软件：KeePass。你是否有过这种经历：平均每半个月或者一个月，我们再登录某些网站或者登录某些账号的时候，发现我们的密码记不住了，用常用的密码试过几次之后，发现还是不对，干脆直接点击忘记密码，用手机验证码或者邮箱验证码找回密码更改成为我们常用的密码，如果这个网站或者这个账号我们好久没登录过，绑定的手机号还是我之前用过的手机号，可能就得通过申诉提供各种资料找回密码，那等待你的将是噩梦级别的操作，如果这个账号不太重要，我不要了也就算了，如果这个账号很重要，那此时此刻你的内心应该已经万马(羊驼)崩腾了。有些人可能喜欢把密码记录在一个特定的笔记本上面，但是如果这个笔记本丢了….丢在家里找不到还好说，万一丢在外面，那你担心的应该不是你有很多网站登录不上了，而是你的密码很可能被别人知道了；还有人喜欢把密码记录在电脑的本地记事本，或者手机的记事本里面，但是这只存在于你电脑本地或者手机本地，万一电脑重装系统，或者换手机……又是个难题，此时此刻聪明的你可能会想，那我把密码放在云笔记里面，我把这个笔记在加个打开密码，那不就好了吗？没错，我在认识KeePass之前，我就是这么做的，但是你放在云笔记里面，在加个笔记的开启密码，这种情况，你的密码就依赖了云笔记服务商的服务器，而且你把密码都放到人家的服务器上，你觉得这是安全的吗？难道你真的认为你加了一个开启密码，就没有人能看到了吗？你的开启密码的加密算法可都是人家云笔记运营商给你提供的….. ​ 现在我就来给大家隆重介绍一下今天的主角，KeePass，并详细说明它是如何解决我们上述的这些问题的。目前主流的密码管理工具主要有：KeePass（免费 开源 兼容性强），LastPass（最大的优势是跨浏览器平台，收费），1Password（跨平台管理 用户认可度高），Enpass（支持平台多 20条密码免费）。可以看出，除了KeePass，其他都是收费的，所以我们毫无悬念的选择了它，KeePass从2003年至今具有近20年的时间，而且开源免费，开源的好处就是民间大神都可以看他的源代码，只要发现安全漏洞就可以去提交评论做修复，所以安全级别是可以放心的，如果你担心有安全问题想阅读源码也可以去官方查看。 接下来就让我介绍一下如何用KeePass搭建一个可以实现云同步的密码管理工具吧。 KeePass下载及使用Keepa介绍​ KeePass不会上传你的账号密码，你的账号密码保存在你本地(数据库)，你只需要创建一个开启这个数据库的钥匙，这个钥匙非常重要，它是你能否打开软件的关键，这个钥匙可以是一串密码，也可以是一个文件，文件可以是任何文件，一部电影，一个word文档，一个txt文本，一首歌等，都可以当做开启数据库的密钥文件，或者是密码加文件的组合的方式来设置你的开启钥匙，还可以是一个实体密钥(类似于U盾)，本人推荐使用密码加文件的方式作为数据库的开启钥匙，这样，开启密码我们就不用设置的太复杂，也不用担心开启密码泄露导致我们的数据库文件被别人拿到之后被别人打开，别人能同时拿到密码和文件简直太难了。 PC端客户端KeePassXC​ KeePass官网，提供了KeePass软件的下载，官方只提供了PC端下载，不过还好，很多民间大神也做了很多支持KeePass的客户端供我们使用，官方也有推荐列表。电脑端（windows和Mac平台），我推荐使用KeePassXC，这也是支持KeePass的由非官方开发的一款软件，KeePass官方推荐列表里面有，之所以推荐它，是因为他界面美观，还有对应的浏览器插件，可以实现密码自动填充。安卓端我推荐使用KeePass2Android，这款软件下载需要上谷歌商店，可能得需要科学上网，这里我给大家提供了蓝奏云下载，方便大家下载安装，由于本人没有苹果手机，所以IPhone用户就需要小伙伴自己去官方推荐的软件里面寻找适合苹果手机的客户端了(#^.^#)~ KeePassXC使用介绍下图为我的KeePass的客户端安装配置之后的效果，怎么样，还不错吧~ 下载安装KeePass之后，我们需要设置一下我们数据库存放的本地位置，然后设置数据库开启密码，开启密钥文件，这里我推荐手动创建一个文件，后缀名随意，然后用记事本打开，在里面输入一些文章，例如你喜欢的诗词之类的，字书不要太多，尽量控制在1千字以内就行，避免文件过大，然后吧这个密钥文件好好保存起来，我建议用你常用的邮箱给自己发个邮件然后以附件的方式保存在你的邮件里面，这样他就永远不会丢了，或者放到你的云盘，NAS上面，不要把它和数据库放在一起！！！如果是Mac本支持指纹识别，输入一次密码和密钥文件之后，下次就可以通过指纹打开你的数据库了，但是这不代表你的密码和密钥文件就没用了，指纹打开数据库的原理其实就是通过指纹映射到你的密码和密钥文件，所以说，数据库开启密码和密钥文件很重要，这个一定不能丢~ 进入之后，我们就可以添加分类，然后添加账号密码等等，具体的使用方法我会出视频讲解，欢迎朋友来B站关注我。 浏览器插件使用(谷歌为例)本地软件开启相应功能​ 在KeePassXC打开设置-浏览器集成-启用浏览器集成-然后为你用的浏览器开启集成（见下图），这里墙裂建议使用谷歌浏览器，这是浏览器中的神。当然，想成为神，需要科学上网安装必要的插件才能够给谷歌浏览器注入神之灵魂，不要下载下来之后连个插件都没装就说浏览器不行，行不行得看用的人会不会用。总之，科技农民工里面应该没有几个人不用谷歌吧~ 浏览器插件下载使用​ 打开谷歌应用商店（注：这里可能需要科学上网），找到KeePassXC这个插件，安装之…. 安装之后用浏览器插件链接本地KeePassXC软件，链接之后，就可以实现网站账号密码自动填充了，需要注意的是，自动填充的时候，一定要是你本地数据库打开的情况下，这样你就可以吧浏览器的记住密码功能关闭了，不过这个自动填充功能并不一定所有网站都可以，大概百分之80的网站都没问题，还有就是想要能关联到填充项目，需要你在你添加密码的时候，把对应的URL填写成为网站的登录地址或者网站的官网。 实现数据库云同步我们的数据库只存在于我们本地肯定是不行的，这跟我直接在本地搞一个记事本保存密码也差不了多少，重装系统之后，数据库丢了，就直接回到解放前了，这里我建议使用两种工具实现数据库云同步功能，第一款是微软出品的OneDrive，这款云盘可以实现云盘映射到本地指定路径，路径中的文件发生改变，会自动同步到云端，这样我们添加或者修改了账号密码之后，数据库都会自动同步到微软的OneDrive云盘，这样我们就实现了电脑端的数据库云同步，手机端Keepass2Android，也是支持读取OneDrive云盘文件的功能的；第二款同步工具是坚果云，原理和OneDrive一样，不过坚果云要实现手机同步，需要通过WebDav功能实现，坚果云是支持云文件设置成为WebDav服务的，而且坚果云号称是国内最安全的云盘，军工级的加密方案，你的数据库放在坚果云是安全的，就算有人能拿到你的数据库，没有密码和密钥文件，也是打不开的… 尾声​ 无论使用哪种同步方案，这种同步的思路明白了，也可以试试其他的KeePass 的客户端软件，文章中介绍的都是本人认为最好的方案，也是爱折腾的我在工作之余肝了好几个晚上定下的最终方案，也请大家多多关注我的个人博客和B站，有什么问题可以加我QQ或者B站留言私信给我…谢谢大家！","categories":[{"name":"软件分享","slug":"软件分享","permalink":"https://zhangyong3214.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"吐血整理IDEA必备插件(๑•̀ㅂ•́)و✧，让撸码效率提升1000%","slug":"软件工具/吐血整理IDEA必备插件","date":"2022-04-05T09:32:31.592Z","updated":"2022-04-05T09:32:31.592Z","comments":true,"path":"2022/04/05/软件工具/吐血整理IDEA必备插件/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E5%90%90%E8%A1%80%E6%95%B4%E7%90%86IDEA%E5%BF%85%E5%A4%87%E6%8F%92%E4%BB%B6/","excerpt":"","text":"俗话说：“工欲善其事，必先利其器”，好的开发工具能让我们的工作效率翻倍，而好的开发工具加上优秀的插件，能让我们的工作效率提升十倍（(@^_^@)我要打十个），这也是我们区别于其他程序猿的必备工具，下面就是我从十余年工作中总结出来的好用的idea插件（好像工作的前五年我用的都是eclipse，哈哈(╯&gt;д&lt;)╯⁽˙³˙⁾，这不重要！）。插件主要分为：代码生成类，日常开发类，主题美化类，以下插件大都可以通过 IDEA 自带的插件管理中心安装，如果搜不到可以去 IDEA 插件官网下载本地导入。星号代表我个人的推荐指数 。 代码生成Lombok 推荐指数：★★★★★ 自动生成get、set方法 EasyCode 推荐指数：★★ 数据库逆向工程 GsonFormat 推荐指数：★★★★ 通过json生成实体类 Codota 推荐指数：★★★★★ 代码提示 该插件的强大之处在于： 支持智能代码自动提示，该功能可以增强 IDEA 的代码提示功能； 支持 JDK 和知名第三方库的函数的使用方法搜索，可以看到其他知名开源项目对该函数的用法。 当我们第一次使用某个类，对某个函数不够熟悉时，可以通过该插件搜索相关用法，快速模仿学习，使用方法：右键要搜索的类，选择 Get relevant exanples GenerateAllSetter 推荐指数：★★★★★ 变量自动生成set方法 插件官网地址 。我们定义好从 A 类转换到 B 类的函数转换函数后，使用这两个插件可以自动调用 Getter 和 Setter 函数实行自动转换。实际开发中还有一个非常常见的场景：我们创建一个对象后，想依次调用 Setter 函数对属性赋值，如果属性较多很容易遗漏或者重复。可以使用GenerateAllSetter 提供的功能，自动调用所有 Setter 函数（可填充默认值），然后自己再跟进实际需求设置属性值。 .ignore 推荐指数：★★★★ git提交时过滤掉不需要提交的文件，很方便，有些本地文件是不需要提交到Git上的，插件：ProjectView涵盖了此功能 CamelCase 推荐指数：★★★★ 将不是驼峰格式的名称，快速转成驼峰格式，安装好后，选中要修改的名称，按快捷键shift+alt+u。 代码规范Alibaba Java Coding Guidelines 推荐指数：★★★ 插件功能：代码规范插件 jclasslib bytecode viewer 推荐指数：★★★ 插件功能：可视化的字节码查看插件 使用方法： 在 IDEA 打开想研究的类； 编译该类或者直接编译整个项目（ 如果想研究的类在 jar 包中，此步可略过）； 打开“view” 菜单，选择“Show Bytecode With jclasslib” 选项； 选择上述菜单项后 IDEA 中会弹出 jclasslib 工具窗口。 那么有自带的强大的反汇编工具 javap 还有必要用这个插件吗？ 这个插件的强大之处在于： 不需要敲命令，简单直接，在右侧方便和源代码进行对比学习； 字节码命令支持超链接，点击其中的虚拟机指令即可跳转到 jvms 相关章节，超级方便。 该插件对我们学习虚拟机指令有极大的帮助。 FindBugs 推荐指数：★★ 插件功能：查找代码bug 程序员总是想尽可能地避免写 BUG， FindBugs 作为静态代码检查插件，可以检查你代码中的隐患，并给出原因。 SonarLine 推荐指数：★★ 插件功能：代码质量管理工具 日常开发Translation 推荐指数：★★★★ 插件功能：翻译 Jrebel 推荐指数：★★★ 插件功能：热部署 Key Promoter X 推荐指数：★★ 插件功能：快捷键提示 MyBatis Log Plugin 推荐指数：★★★★★ 插件功能：打印sql MyBatisX 推荐指数：★★★★★ 插件功能：Mapper跳转Dao Maven Search 推荐指数：★★★★ 插件功能：查询maven Maven Helper 推荐指数：★★★★★ 插件功能：依赖关系图 安装后 IDEA 中打开 pom.xml 文件时，就会多出一个 “Dependency Analyzer” 选项卡。 SequenceDiagram 推荐指数：★★★★ 插件功能：时序图 SequenceDiagram 可以根据代码调用链路自动生成时序图，超级赞，超级推荐！这对研究源码，梳理工作中的业务代码有极大的帮助，堪称神器。安装完成后，在某个类的某个函数中，右键 –&gt; Sequence Diagaram 即可调出。 主题美化Active power mode 推荐指数：★★ 插件功能：打字特效 Rainbow Branckets 推荐指数：★★★ 插件功能：彩虹扩号 插件github地址 。由于很多人没有养成好的编码风格，没有随手 format 代码的习惯，甚至有些同事会写代码超过几百行，阅读起来将非常痛苦。痛苦的原因之一就是找到上下文，由于括号太多，不确定当前代码行是否属于某个代码块，此时这个插件就会帮上大忙。双击顶部的类名可以跳转到对应类的源码中，双击调用的函数名可以直接调入某个函数的源码，总之非常强大。 CodeGlance 推荐指数：★★★ 插件功能：代码迷你小地图 类似于sublime的右侧代码小地图，CodeGlance2为原版加强 Xcode Drak theme 推荐指数：★ 插件功能：主题 Material Theme UI 推荐指数：★ 插件功能：多种主题 对于很多人而言，写代码时略显枯燥的，如果能够安装自己喜欢的主题将为开发工作带来些许乐趣。IDEA 支持各种主题插件，其中最出名的当属 Material Theme UI。安装后，可以从该插件内置的各种风格个选择自己最喜欢的一种。","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"IDEA常用快捷键(Mac版)","slug":"软件工具/IDEA常用快捷键","date":"2022-04-05T09:32:31.591Z","updated":"2022-04-05T09:32:31.591Z","comments":true,"path":"2022/04/05/软件工具/IDEA常用快捷键/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/IDEA%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"Mac键盘符号和修饰键说明 ⌘ Command ⇧ Shift ⌥ Option ⌃ Control ↩︎ Return/Enter ⌫ Delete ⌦ 向前删除键（Fn+Delete） ↑ 上箭头 ↓ 下箭头 ← 左箭头 → 右箭头 ⇞ Page Up（Fn+↑） ⇟ Page Down（Fn+↓） Home Fn + ← End Fn + → ⇥ 右制表符（Tab键） ⇤ 左制表符（Shift+Tab） ⎋ Escape (Esc) Editing（编辑） ⌃Space 基本的代码补全（补全任何类、方法、变量） ⌃⇧Space 智能代码补全（过滤器方法列表和变量的预期类型） ⌘⇧↩ 自动结束代码，行末自动添加分号 ⌘P 显示方法的参数信息 ⌃J, Mid. button click 快速查看文档 ⇧F1 查看外部文档（在某些代码上会触发打开浏览器显示相关文档） ⌘+鼠标放在代码上 显示代码简要信息 ⌘F1 在错误或警告处显示具体描述信息 ⌘N, ⌃↩, ⌃N 生成代码（getter、setter、构造函数、hashCode/equals,toString） ⌃O 覆盖方法（重写父类方法） ⌃I 实现方法（实现接口中的方法） ⌘⌥T 包围代码（使用if..else, try..catch, for, synchronized等包围 选中的代码） ⌘/ 注释/取消注释与行注释 ⌘⌥/ 注释/取消注释与块注释 ⌥↑ 连续选中代码块fa ⌥↓ 减少当前选中的代码块 ⌃⇧Q 显示上下文信息 ⌥↩ 显示意向动作和快速修复代码 ⌘⌥L 格式化代码 ⌃⌥O 优化import ⌃⌥I 自动缩进线 ⇥ / ⇧⇥ 缩进代码 / 反缩进代码 ⌘X 剪切当前行或选定的块到剪贴板 ⌘C 复制当前行或选定的块到剪贴板 ⌘V 从剪贴板粘贴 ⌘⇧V 从最近的缓冲区粘贴 ⌘D 复制当前行或选定的块 ⌘⌫ 删除当前行或选定的块的行 ⌃⇧J 智能的将代码拼接成一行 ⌘↩ 智能的拆分拼接的行 ⇧↩ 开始新的一行 ⌘⇧U 大小写切换 ⌘⇧] / ⌘⇧[ 选择直到代码块结束/开始 ⌥⌦ 删除到单词的末尾（⌦键为Fn+Delete） ⌥⌫ 删除到单词的开头 ⌘+ / ⌘- 展开 / 折叠代码块 ⌘⇧+ 展开所以代码块 ⌘⇧- 折叠所有代码块 ⌘W 关闭活动的编辑器选项卡 Search/Replace（查询/替换） Double ⇧ 查询任何东西 ⌘F 文件内查找 ⌘G 查找模式下，向下查找 ⌘⇧G 查找模式下，向上查找 ⌘R 文件内替换 ⌘⇧F 全局查找（根据路径） ⌘⇧R 全局替换（根据路径） ⌘⇧S 查询结构（Ultimate Edition 版专用，需要在Keymap中设置） ⌘⇧M 替换结构（Ultimate Edition 版专用，需要在Keymap中设置） Usage Search（使用查询） ⌥F7 / ⌘F7 在文件中查找用法 / 在类中查找用法 ⌘⇧F7 在文件中突出显示的用法 ⌘⌥F7 显示用法 Compile and Run（编译和运行） ⌘F9 编译Project ⌘⇧F9 编译选择的文件、包或模块 ⌃⌥R 弹出 Run 的可选择菜单 ⌃⌥D 弹出 Debug 的可选择菜单 ⌃R 运行 ⌃D 调试 ⌃⇧R, ⌃⇧D 从编辑器运行上下文环境配置 Debugging（调试） F8 进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F7 进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该 方法体还有方法，则不会进入该内嵌的方法中 ⇧F7 智能步入，断点所在行上有多个方法调用，会弹出进入哪个方法 ⇧F8 跳出 ⌥F9 运行到光标处，如果光标前有其他断点会进入到该断点 ⌥F8 计算表达式（可以更改变量值使其生效） ⌘⌥R 恢复程序运行，如果该断点下面代码还有断点则停在下一个断点上 ⌘F8 切换断点（若光标当前行有断点则取消断点，没有则加上断点） ⌘⇧F8 查看断点信息 Navigation（导航） ⌘O 查找类文件 ⌘⇧O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ ⌘⌥O 前往指定的变量 / 方法 ⌃← / ⌃→ 左右切换打开的编辑tab页 F12 返回到前一个工具窗口 ⎋ 从工具窗口进入代码文件窗口 ⇧⎋ 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 ⌘⇧F4 关闭活动run/messages/find/… tab ⌘L 在当前文件跳转到某一行的指定处 ⌘E 显示最近打开的文件记录列表 ⌘⌥← / ⌘⌥→ 退回 / 前进到上一个操作的地方 ⌘⇧⌫ 跳转到最后一个编辑的地方 ⌥F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在 代码编辑窗口可以选择显示该文件的Finder) ⌘B / ⌘ 鼠标点击 进入光标所在的方法/变量的接口或是定义处 ⌘⌥B 跳转到实现处，在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 ⌥ Space, ⌘Y 快速打开光标所在方法、类的定义 ⌃⇧B 跳转到类型声明处 ⌘U 前往当前光标所在方法的父类的方法 / 接口定义 ⌃↓ / ⌃↑ 当前光标跳转到当前文件的前一个/后一个方法名位置 ⌘] / ⌘[ 移动光标到当前所在代码的花括号开始/结束位置 ⌘F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） ⌃H 显示当前类的层次结构 ⌘⇧H 显示方法层次结构 ⌃⌥H 显示调用层次结构 F2 / ⇧F2 跳转到下一个/上一个突出错误或警告的位置 F4 / ⌘↓ 编辑/查看代码源 ⌥ Home 显示到当前文件的导航条 F3选中文件/文件夹/代码行，添加/取消书签 ⌥F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 ⌃0…⌃9 定位到对应数值的书签位置 ⌘F3 显示所有书签 Refactoring（重构） F5 复制文件到指定目录 F6 移动文件到指定目录 ⌘⌫ 在文件上为安全删除文件，弹出确认框 ⇧F6 重命名文件 ⌘F6 更改签名 ⌘⌥N 一致性 ⌘⌥M 将选中的代码提取为方法 ⌘⌥V 提取变量 ⌘⌥F 提取字段 ⌘⌥C 提取常量 ⌘⌥P 提取参数 VCS/Local History（版本控制/本地历史记录） ⌘K 提交代码到版本控制器 ⌘T 从版本控制器更新代码 ⌥⇧C 查看最近的变更记录 ⌃C 快速弹出版本控制器操作面板 Live Templates（动态代码模板） ⌘⌥J 弹出模板选择窗口，将选定的代码使用动态模板包住 ⌘J 插入自定义动态代码模板 General（通用） ⌘1…⌘9 打开相应编号的工具窗口 ⌘S 保存所有 ⌘⌥Y 同步、刷新 ⌃⌘F 切换全屏模式 ⌘⇧F12 切换最大化编辑器 ⌥⇧F 添加到收藏夹 ⌥⇧I 检查当前文件与当前的配置文件 `§⌃, ⌃``快速切换当前的scheme（切换主题、代码样式等） ⌘, 打开IDEA系统设置 ⌘; 打开项目结构对话框 ⇧⌘A 查找动作（可设置相关选项） ⌃⇥ 编辑窗口标签和工具窗口之间切换（如果在切换的过程加按上delete，则是关闭对应选中的窗口） Other（一些官方文档上没有体现的快捷键） ⌘⇧8 竖编辑模式 导航 ⌘O 查找类文件 Ctrl + N ⌘⌥O 前往指定的变量 / 方法 Ctrl + Shift + Alt + N ⌃← / ⌃→ 左右切换打开的编辑tab页 Alt← / Alt→ ⎋ 从工具窗口进入代码文件窗口 ESC ⌘L 在当前文件跳转到某一行的指定处 Ctrl + G ⌘E 显示最近打开的文件记录列表 Ctrl + E ⌘⌥← / ⌘⌥→ 退回 / 前进到上一个操作的地方 Ctrl + Alt + ← Ctrl + Alt + → ⌘⇧⌫ 跳转到最后一个编辑的地方 ⌃H 显示当前类的层次结构 Ctrl + H ⌘⇧H 显示方法层次结构 ⌃⌥H 显示调用层次结构 F4 / ⌘↓ 编辑/查看代码源 ⌘⌥U 显示类UML图 ⌃J 查看注释 编辑 ⌥⌦ 删除到单词的末尾（⌦键为Fn+Delete） ⌥⌫ 删除到单词的开头 ⌘+ / ⌘- 展开 / 折叠代码块 ⌘F1 在错误或警告处显示具体描述信息 ⌘⌥L 格式化代码 ⌃⌥O 优化import ⇧↩ 开始新的一行 ⌘⇧↩ 自动结束代码，行末自动添加分号 ⌃I 实现方法（实现接口中的方法） ⇧F6 重命名文件或者变量 ⌘N, ⌃↩, ⌃N 生成代码（getter、setter、构造函数、hashCode/equals,toString） ⌘P 显示方法的参数信息 查找 Double⇧ 查找任何东西 ⌘⇧F 全局查找（根据路径） ⌘F 文件内查找 ⌘G 查找模式下，向下查找 ⌘⇧G 查找模式下，向上查找 ⌘⌥B 跳转到接口的实现 ⌘U 查看接口定义 ⌘⌥← / ⌘⌥→ 退回 / 前进到上一个操作的地方 ⌘B / ⌘ 鼠标点击 进入光标所在的方法/变量的接口或是定义处 ⌃⇧B 跳转到类型声明处 ⌥ Space, ⌘Y 快速打开光标所在方法、类的定义 ⌘O 查找类文件 ⌘⇧O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ F12 返回到前一个工具窗口 ⎋ 从工具窗口进入代码文件窗口 ⇧⎋ 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 F3选中文件/文件夹/代码行，添加/取消书签 ⌥F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 ⌃0…⌃9 定位到对应数值的书签位置 ⌘F3 显示所有书签 ⌥F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在代码编辑窗口可以选择显示该文件的Finder) ⌘F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） 通用 ⌃⌘F 切换全屏模式","categories":[{"name":"笔记","slug":"笔记","permalink":"https://zhangyong3214.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"为MacOS打造自己炫酷终端-Iterm2+oh-my-zsh","slug":"软件工具/为MacOS打造自己炫酷终端-","date":"2022-04-05T09:32:31.591Z","updated":"2022-04-05T09:32:31.592Z","comments":true,"path":"2022/04/05/软件工具/为MacOS打造自己炫酷终端-/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E4%B8%BAMacOS%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%82%AB%E9%85%B7%E7%BB%88%E7%AB%AF-/","excerpt":"1、iTerm2 iTerm2 是一款完全免费，专为 Mac OS 用户打造多命令行应用。 安装完成后，在/bin目录下会多出一个zsh的文件。 Mac系统默认使用dash作为终端，可以使用命令修改默认使用zsh：chsh -s /bin/zsh 如果想修改回默认dash，同样使用chsh命令即可：chsh -s /bin/bash Zsh 是一款强大的虚拟终端，既是一个系统的虚拟终端，也可以作为一个脚本语言的交互解析器。","text":"1、iTerm2 iTerm2 是一款完全免费，专为 Mac OS 用户打造多命令行应用。 安装完成后，在/bin目录下会多出一个zsh的文件。 Mac系统默认使用dash作为终端，可以使用命令修改默认使用zsh：chsh -s /bin/zsh 如果想修改回默认dash，同样使用chsh命令即可：chsh -s /bin/bash Zsh 是一款强大的虚拟终端，既是一个系统的虚拟终端，也可以作为一个脚本语言的交互解析器。 1.1、iterm2 安装下载地址 1.2、iTerm操作快捷键 command + t：新建窗口 command + d：垂直分屏， command + shift + d：水平分屏。 command + ] 和command + [ 在最近使用的分屏直接切换. command + alt + 方向键：切换到指定位置的分屏。 command + 数字：切换标签页。 command + 方向键：按方向切换标签页。 shift + command + s：保存当前窗口快照。 command + alt + b：快照回放。很有意思的功能，你可以对你的操作根据时间轴进行回放。可以拖动下方的时间轴，也可以按左右方向键 1.3、创建一键登录服务器1.3.1、第一步：新建配置文件，内容：12345678set user 用户名set host IP地址set password 密码spawn ssh $user@$hostexpect &quot;*assword:*&quot;send &quot;$password\\r&quot;interactexpect eof 1.3.2、第二步：iTerm2配置添加1expect ~/.ssh/SIT02-10.231.143.184 2、Oh My ZshOh My Zsh 官网 Oh My Zsh 是一款社区驱动的命令行工具，它基于 zsh 命令行，提供了主题配置，插件机制，已经内置的便捷操作。给我们一种全新的方式使用命令行。 2.1、oh my zsh 安装2.1.1、方式11sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 2.1.2、方式21`sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot;` 2.1.3、方式3（国内推荐使用）1sh -c &quot;$(curl -fsSL https://gitee.com/pocmon/ohmyzsh/raw/master/tools/install.sh)&quot; 2.2、卸载oh my zsh1uninstall_on_my_zsh 2.3、更换主题12vi ~/.zshrcZSH_THEME=&quot;macovsky-ruby&quot; &quot;steeef&quot; 2.4、安装语法高亮插件1234# 进入文件夹cd ~/.oh-my-zsh/custom/plugins# 下载插件git clone https://github.com/zsh-users/zsh-syntax-highlighting.git 2.5、自动补全插件1git clone https://github.com/zsh-users/zsh-autosuggestions.git 2.5.1、启用插件12345vi ~/.zshrcplugins=( git zsh-autosuggestions zsh-syntax-highlighting )source ~/.zshrc","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"Git笔记-常用命令以及日常操作技巧汇总","slug":"软件工具/git笔记","date":"2022-04-05T09:32:31.591Z","updated":"2022-04-05T09:32:31.591Z","comments":true,"path":"2022/04/05/软件工具/git笔记/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/git%E7%AC%94%E8%AE%B0/","excerpt":"1、为Git配置代理（解决国内连接git慢问题）相关文章：解决git无法clone提示443以及配置git代理方法 12345678# 添加当前仓库配置：git config --local http.proxy &quot;127.0.0.1:1087&quot; # 删除当前仓库配置：git config --unset --local http.proxy# 添加全局配置：git config --global http.proxy &quot;127.0.0.1:1087&quot; # 删除全局配置：git config --unset --global http.proxy","text":"1、为Git配置代理（解决国内连接git慢问题）相关文章：解决git无法clone提示443以及配置git代理方法 12345678# 添加当前仓库配置：git config --local http.proxy &quot;127.0.0.1:1087&quot; # 删除当前仓库配置：git config --unset --local http.proxy# 添加全局配置：git config --global http.proxy &quot;127.0.0.1:1087&quot; # 删除全局配置：git config --unset --global http.proxy 注：添加相关配置也可以到本地仓库对应的目录，修改.git文件夹里面的config文件，如下图，我的本地的1087端口是我的科学上网地址 config 配置有system级别 global（用户级别） 和local（当前仓库）三个 设置先从system-》global-》local 底层配置会覆盖顶层配置 分别使用–system/global/local 可以定位到配置文件 查看系统config 1git config --system --list 查看当前用户（global）配置 1git config --global --list 查看当前仓库配置信息 1git config --local --list","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"Docker操作笔记-从小白到入门","slug":"软件工具/Docker操作笔记-从小白到入门","date":"2022-04-05T09:32:31.590Z","updated":"2022-04-05T09:32:31.591Z","comments":true,"path":"2022/04/05/软件工具/Docker操作笔记-从小白到入门/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/Docker%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0-%E4%BB%8E%E5%B0%8F%E7%99%BD%E5%88%B0%E5%85%A5%E9%97%A8/","excerpt":"1、Docker安装centos 为例：查看版本：cat /etc/redhat-release 参考网址 121.先安装gcc：yum -y install gcc 2.查看版本：gcc -v 安装需要的软件包","text":"1、Docker安装centos 为例：查看版本：cat /etc/redhat-release 参考网址 121.先安装gcc：yum -y install gcc 2.查看版本：gcc -v 安装需要的软件包 1yum install -y yum-utils device-mapper-persistent-data lvm2 1.1、阿里加速：1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 查看配置： vi /etc/yum.repos.d/docker-ce.repo 更新软件包： yum makecache fast 安装docker： yum install docker-ce docker-ce-cli containerd.io 配置文件位置： /etc/sysconfig/docker 启动docker： systemctl start docker 设置开机启动： systemctl enable docker 查看docker启动进程： ps -ef|grep docker 查看docker版本： docker version docker info 1.2、下载镜像1234docker pull mysql:5.7 docker pull rabbitmq:management （带管理台的MQ）docker pull zookeeper:latest docker pull redis:rc-buster 镜像搜索地址 镜像加速地址 1.3、权限问题解决docker守护进程启动的时候，会默认赋予名字为docker的用户组读写Unix socket的权限，因此只要创建docker用户组，并将当前用户加入到docker用户组中，那么当前用户就有权限访问Unix socket了，进而也就可以执行docker相关命令 添加docker用户组 sudo groupadd docker 将登陆用户加入到docker用户组中 sudo gpasswd -a $USER docker 更新用户组 newgrp docker 测试docker命令是否可以使用sudo正常使用 docker ps 2、镜像操作 查看镜像：docker images 展示所有所有镜像（包含中间镜像层）：docker images -a 查询镜像：docker search 镜像名字 删除镜像：docker rmi 镜像id 3、容器操作 启动mysql： docker run -p 3306:3306 --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 启动rabitmq： docker run -d -p 5672:5672 -p 15672:15672 --name myrabitmq 镜像id 启动redis： docker run -d -p 6379:6379 --name myredis 镜像id 启动zookeeper： docker run --name zk01 -p 2181:2181 --restart always -d 镜像id 启动nacos： docker run --name nacos-2.0.1 -e MODE=standalone -p 8849:8848 -d nacos/nacos-server:2.0.1 启动kibana： docker run -d --name kibana7.7.1 --net mynet -p 5601:5601 kibana:7.7.1 Kibana 在Doker中启动相关配置 123docker exec -it kibana7.7.1 bashcd config vi kibana.yml 查看日志： docker logs -f -t –tail 100 kibana7.7.1 更新启动参数： docker update –restart=always xxx 查看所有容器： docker ps -a 查看启动容器： docker ps 启动已停止的容器： docker start 容器id或名字 关闭容器 ： docker stop 容器id 取消容器开机启动： docker update --restart=no 容器ID 强制关闭： docker kill 容器id 删除已停止容器 ： docker rm 容器id 删除没有停止容器： docker rm -f 容器id 进入容器内部： docker exec -it 程序id /bin/bash exit 关闭容器退出(自测不会退出)： ctrl+p+q 查看日志： docker logs -f (追加) -t (加入时间戳) --tail 3 (显示最后3行) 容器id 查看容器结构细节： docker inspect 容器id 拷贝容器中的文件： docker cp 容器id:文件路径 要拷贝到的路径 提交自己的docker镜像： docker commit -a=&quot;lgd&quot; -m=&quot;mysql-lgd&quot; 243baa0ea2a7 ligoudan/lgd-mysql:1.0","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"","slug":"知识整理/netty知识点","date":"2022-04-05T09:32:31.589Z","updated":"2022-04-05T09:32:31.589Z","comments":true,"path":"2022/04/05/知识整理/netty知识点/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/netty%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"nettyIO模型 IO模型就是说用什么样的通道进行数据的发放和接收 t BIO 同步阻塞模型，一个客户端连接一个线程，如果有多个客户端，需要有多个线程来处理，可能超过服务端的资源限制。 在使用NIO过程中使用了socket.accept()。服务端的outputStream.write()。客户端的inputStream.read();都是阻塞方法。为了提升服务端的吞吐量，一般都会才会多线程的方式。 这个模型有以下几个致命问题 线程的创建和销毁，在Linux这样的操作系统中，线程本质是一个进程。创建和销毁都是重量级的系统函数。 线程本身占用较大的内存，内存一般都会有内存的分配，如果系统的线程过多，那么整个JVM内存可能会吃完。 线程的切换成本也很很高，操作系统在发生线程切换时候需要保存线程的上线文，然后执行系统调用。 结论：NIO模型在线程过多时候(客户端并发度很高时候)，那么这种模型很占用大量的服务资源。 NIO 同步非阻塞IO模型。 Channel、Buffer、选择器 ServerSocketChannel Selector注册。多路复用选择器 和BIO相比，NIO把原来的阻塞读写(占用线程)编程了单线程轮训，找到可以进行读写的网络文件描述符进行读写。除了时间轮训是阻塞的，剩余IO操作都是存CPU操作，没必要开启多线程。 由于线程的节约，连接数大的时候因为携程切换带来的问题也随之解决，进而为处理海量了解提供了可能。 在NIO的模型下，我们需要三类线程 事件分发器，单线程选择就绪事件。 I/O处理器，包括connnect、read、write等，这种存CPU操作，一般开启CPU核心线程数就可以 业务线程，在处理完I/O后，业务一般还会有自己的业务逻辑，有时候还会有阻塞I/O，如DB操作、PRC等操作 AIO 异步非阻塞。AIO底层是NIO的封装，同步转异步的方式。 tcp的连接，数据读取和写入都不进行等待，通过回调的方式进行连接和读写。 netty核心功能netty的源码解析netty的高性能场景","categories":[],"tags":[]},{"title":"面试知识点整理","slug":"知识整理/知识点梳理-2022","date":"2022-04-05T09:32:31.589Z","updated":"2022-04-05T09:32:31.590Z","comments":true,"path":"2022/04/05/知识整理/知识点梳理-2022/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-2022/","excerpt":"","text":"2022-知识点梳理1、redis keys执行了会怎么样 1、当redis集群中的key数量不多时候没有什么大问题，但是随着key数量的增长，这样可能引起redis的客户端访问redis阻塞。 2、因为Redis是单线程的，执行任何命令时候其他命令会阻塞，而且由于key命令的时间复杂度是O(n)，redis服务端会匹配查找完所有的key才结束，比较耗时，如果在线上执行非常危险。 3、如果命令执行时间过长可能会触发服务器的安全策略，导致主从切换或者重新选主 可用scan命令替换keys命令，达到同样效果 Scan命令在Redis的2.8版本爱是支持，相当于db中的分页查询,虽然也是O(n)的时间复杂度，但是数量进行制定，查询时间稳定 Scan 0 match test* count 100 2、redis缓存击穿 穿透前提条件：我们把db的热点数据放在了redis，并设置了超时时间，目前是较少DB的访问次数或者DB支持不了这么大压力。但是在查询时候有又进行了DB兜底的情况。 缓存击穿：当缓存过期的一瞬间，大量请求达到redis，因为redis没有，所以一瞬间的所有流量都打到了DB 缓存穿透:在缓存中查询不到数据，去数据库中查询数据也没查到，相当于无效请求到了BD，有大量这样请求都打到了DB。 缓存击穿的解决方案()： 访问DB的位置加互斥锁 热点数据续时 异步同步，不用db兜底 缓存击穿(前置拦截)： 接口验证。非法请求降级等等。 缓存空值并进行超时时间控制 布隆过滤器–不存在请求先过滤 3、 zookeeper eureka区别相同点 都可以作为注册中心 不同点 Eureka 是AP模型(关注可用性)，ZK是CP模型(关注数据一致性) Eureka支持负载均衡策略，ZK不支持 Eureka访问支持http协议，ZK不支持 4、dubbo robin负载均衡Dubbo负载均衡算法： RandomLoadBalance:权重随机算法，根据权重值进行随机负载 假设有一组服务器A，B，C,对应的权重为[1,2,7]权重总和为10，[0,0]区间属于服务A,[1,2]属于B，[3,9]属于服务C。每次负载时候，通过随机生成一个范围在[0,9]之间的随机数，计算这个随机数在哪个区间，找到属于这个区间的服务就可以。 LeastActiveLoadBalance：最少活跃数调用法 活跃度调用越小，表明该服务提供者的效率越高，单位时间内可以处理更多的请求。 每个服务提供者对应一个活跃数的active，初始为0，每收到一个请求，活跃度+1，处理完成一个请求活跃度-1。活跃度可以代表该服务还未处理完成的请求。路由按照活跃度越小，优先级越高。 ConsistentHashLoadBalance：hash一致性算法 hash一致性算法，相同参数的请求总时发送到同一提供者。当某一台挂掉时，请求分摊到其他提供者。 RoundRobiLoadBalance:加权轮训算法 轮训是将每个请求轮流分配到每台服务器。假如说有三台服务器A,B,C。轮训 是一种状态负载均衡算法，实现简单，适用于每台服务器性能接近的场景。但是实际情况，每台服务器性能可能不一致，如果我们把流量均分，那么性能较差的机器会最先成为瓶颈。一次可以对轮训进行加权，实现调控每台机器的负载。经过加权后，每台服务器会进行请求的比例分配。比如A、B、C的权重为1:2:7,那么10次请求中1笔到A,2笔到B,7笔到C。 5、 spring中的设计模式和用法示例工厂模式BeanFactory是Spring中的容器工厂，我们可以通过这个方法获取不同的对象。通过抽象类元素，形成beanDefinition—&gt;通过BeanDefinition 单例模式获取bean时候通过三级缓存实现。 装饰器模式各种Wrapper 代理模式AOP底层就是动态代理 具体可以讲讲Spring的bean实例化后的动态代理过程。PostProcessor 模板设计模式 具体可以参照不同的容器启动过程 策略设计模式6、 数据库查询最近100万的数据7、mysql acid怎么保证 a(Atomicity):原子性,每一个事务是一个最小单位，事务内部的操作要么都成功，要么都失败。 c(Consistency):一致性，一致性是指事务执行前后，数据数据存于一中合法状态，这种状态是指语义上而不是语法上。合法状态是指满足预定的约束就叫做合法的状态。 i(Isolation):隔离性，隔离性是指多个事务并发执行，内部的操作和其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 d(Durability):持久性，持久性是指事务一旦提交，他怼数据库的改变是永久性的。接下来的其他操作或者故障都不应该对这个结果有任何影响。 原子性通过InnoDB的undo log实现。unlog也叫做回归日志，是实现原子性的关键，当事务回滚时能够撤销已经成功执行的sql语句，undo log的实现原理是记录一条相反操作的操作。insert–&gt; delete。update(后) –&gt; update(前) ，delete –&gt; insert 一致性是数据库需要达到的目的。从数据库层面，通过原子性、隔离性、持久性来保证。从应用层面，通过代码判断数据库是否有效，然后决定回滚还是提交数据，也是一致性的 持久性是通过InnoDB 的redo log实现的。redo log也倨傲重做日志。当做数据修改时候，不仅需要在内存中操作，还会在redo log中记录这次操作。当事务提交时候，会将redo log 进行刷盘.当数据库宕机重启时候，会将redo log中内存恢复到数据库中，再根据undo log和binlog内容决定回归数据还是提交数据。 隔离性通过InnoDB的隔离界别和MVCC来实现。 8、mysql b+树和b树 avl树区别avl:平衡二叉树 9、分布式锁redis宕机怎么办 首先确定业务场景是否强依赖这个分布式锁，如果是那么你的业务就进行不下去。 如果不是就要分具体情况。 10、dubbo zookeeper集群宕机还能发现吗问题不清晰。可以分为两个问题来回答 dubbo集群通过zk作为注册中心，ZK集群宕机，dubbo客户端还能被发现么 这个问题是是问，dubbo客户端缓存服务端节点的问题 dubbo 的注册中心zk集群宕机后还能重新启动么 问的是zk的故障恢复，可以聊聊zk的zab协议。 11、springboot properties yaml读取顺序12、dubbo properties xml读取顺序13、Java类加载的过程 加载：把.class类加载到JVM虚拟中，并生成访问入口 通过类的全限定名获取该类的二进制流 将改二进制流中的静态存储结构转换为方法区运行时数据结构 在内存中生成该类的Class对象，作为该类的数据访问入口 验证：目的是确保加载进.class类是合法的，并且是不危害到JVM虚拟机的。验证有四种分别如下 文件格式验证。是否符合Class文件的规范。CAFEBABE 元数据验证：对字节码描述信息进行语义分析，这个类是否有父类，是否继承了不能被继承的类等等 字节码验证：通过数据流和控制流分析，确定程序语义是否正确，主要针对方法体验证。如：方法中的类型转换是否正确，跳转执行是否正确。 符号引用验证：这个动作在后面的解析过程中发生，主要是为了确保解析动作能正确执行。 准备：准备阶段是为类的静态变量分配内存并将其初始化为默认值，这些内存都将在方法区中进行分配。准备阶段不分配实例变量的内存，实例变量将会在对象实例化是随着对象一起分配在Java堆中。 解析：该阶段主要完成符号引用到直接引用的转换动作。解析动作不一定在初始化之前完成，也有可能在初始化之后完成。 初始化：初始化是类加载的最后一步，前面的类加载过程，除了在加载阶段用户应用程序能够通过自定义类加载器以外，其他动作完全由虚拟机主导和控制。到了初始化阶段，才开始真正执行类中定义的java程序代码。 使用 卸载 14、类加载器 启动类加载器：BootstrapClassLoader。加载jre/lib/下的类。 扩展类加载器：ExtensionsClassLoader：用来加载Java的扩展库。加载jre/ext/lib/下的类 系统类加载器：SystemClassLoader：加载用户的类路径classPath下的class 用户自定义类加载器：通过加成java.lang.ClassLoader类方式加载 15、 双亲委派当一个类加载器收到类加载请求时候，不会自己先去加载这个类，而是委派父类加载，一只到顶层的BootstrapClassLoader,如果还没有加载到，那么才由子类加载。 16、数据一致性协议分布式系统需要维护多个副本来进行容错，提供系统的可用性。要实现次目标，就必须要解决分布式系统的最核心问题：维护多个副本的一致性。 zab协议Raft协议核心流程分为一下几步 选主(Leader Election) 每一个副本都可以分为三种角色。Loader、Follower、Candidate Candidate代表主节点故障，正在选举过程。 日志复制(Log Replication) 日志压缩(Log compaction) HashMap整理：HashMap是一个用于存储key-value键值对的集合，每个键值对我们通常称为为一个entry。这些键值对分散存储在一个数组中，这个数组就是HashMap的主干。 JDK1.8下的数据结构 123456789101112131415public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; // 省略其他代码 /* ---------------- Fields -------------- */ transient Node&lt;K,V&gt;[] table; transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; transient int size; transient int modCount; int threshold; final float loadFactor;&#125; 123456789101112131415static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; // 其他代码....&#125; HashMap提供了两个核心的方法，put(key,value); get(key); put(key,value) 通过hash(key)获取数组的位置。 如果位置为空，把key,value包装成Entry放入相应的位置 如果位置不为空，首先判断数据结构是树，那么把节点放入树种 看下目前的链表数目是否已经再放一个节点会进行树化，如果是就树化 否则直接放在这个链表上 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; get1、对key进行hash. 2、 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 17、线程的几种状态及其转换操作系统 新建(new) 就绪(Runnable) 运行(Running) 阻塞(Blocked) 运行结束(Dead)JAVA 线程状态 NEW RUNNABLE BLOCKED WAITING TIME_WAITING TERMINAL 为什么Java的线程状态有六中状态 JWT JSON WEB TOKEN header reload signature 18、ConcurrentHash 线程安全的key-value集合类，相对于Hashtable 使用了分段锁的设计原则。 1、JDK1.7123456789101112131415161718public class ConcurrentHashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements ConcurrentMap&lt;K, V&gt;, Serializable &#123; // 通过分段式锁进行 final Segment&lt;K,V&gt;[] segments; // Segement实现可重入锁的实现 static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; transient volatile HashEntry&lt;K,V&gt;[] table; &#125; static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; 12345678910111213public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; // ConcurrentHashMap不支持key和value为null if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); // 最终使用的是Segement的put方法 return s.put(key, hash, value, false); &#125; Segement ReetrantLock 线程安全 2、JDK1.81.8 Synchonized+CAS乐观锁 CAS在查找替换，1.8锁头节点 19、Mysql的MVCC MVCC(Multi-version concurrency control)又叫做多版本并发控制。代替锁来实现数据库的隔离性。 在InnoDB的聚簇索引中，局促索引中有两个必要的隐藏列 Trx_id：这个ID用来储存每次对该条举措索引记录进行修改的事务ID。递增。 roll_point：存储一个指针，这个指针这条聚簇索引的上一个版本的位置，通过他获取上一个版本的记录信息。 MVCC只在数据库隔离界别为读已提交(RC)，可重复度读(RR)两种模式下生效。其他模式不兼容。 Mysql通过undo log实现了数据的多版本 20、volatile作用 valatile修饰的变量能够保证可见性，并防止指令重排序 synchonized修饰的代码块能够保证代码的原子性和可见性。 valitile能解决 保证了不同线程对该变量操作的内存可见性 禁止指令重排序 但是不能保证操作的原子性 Java虚拟机规范试图定义一种Java内存模型（JMM）,来屏蔽掉各种硬件和操作系统的内存访问差异，让Java程序在各种平台上都能达到一致的内存访问效果。简单来说，由于CPU执行指令的速度是很快的，但是内存访问的速度就慢了很多，相差的不是一个数量级，所以搞处理器的那群大佬们又在CPU里加了好几层高速缓存。 vaitile能解决并发问题中的有序性和可见性，按时 21、Redis的rehash内部实现在redis中，键值对(key-value pair)，字典底层是通过哈希列来实现的，通过哈希表中的节点保存字段中的键值对。 1234567/* hash表结构定义 */typedef struct dictht &#123; dictEntry **table; // 哈希表数组 unsigned long size; // 哈希表的大小 unsigned long sizemask; // 哈希表大小掩码 unsigned long used; // 哈希表现有节点的数量&#125; dictht; 123456789101112/* 哈希桶 */typedef struct dictEntry &#123; void *key; // 键定义 // 值定义 union &#123; void *val; // 自定义类型 uint64_t u64; // 无符号整形 int64_t s64; // 有符号整形 double d; // 浮点型 &#125; v; struct dictEntry *next; //指向下一个哈希表节点&#125; dictEntry; Redis 哈希表中的table数组存放着哈希桶结构（dictEntry），里面就是Redis的键值对；类似Java实现的HashMap，Redis的dictEntry也是通过链表（next指针）方式来解决hash冲突： Redis Dict 中定义了两张哈希表，是为了后续字典的扩展作Rehash之用： 123456789/* 字典结构定义 */typedef struct dict &#123; dictType *type; // 字典类型 void *privdata; // 私有数据 dictht ht[2]; // 哈希表[两个] long rehashidx; // 记录rehash 进度的标志，值为-1表示rehash未进行 int iterators; // 当前正在迭代的迭代器数&#125; dict; ![image-20220316144721437](/Users/admin/Library/Application Support/typora-user-images/image-20220316144721437.png) 总结一下： 在Cluster模式下，一个Redis实例对应一个RedisDB(db0); 一个RedisDB对应一个Dict; 一个Dict对应2个Dictht，正常情况只用到ht[0]；ht[1] 在Rehash时使用。 22、AQS AbstractQueueSynconizer,中文名为抽象的队列同步器，在AQS内部有一个资源访问的状态status和一个FIFO的双向队列，用来保存等待共享资源的变量的等待线程。基本上juc包下的并发类都是基于AQS来实现的，比如ReentratLock,Semaphore,CountDownLatch,CyclicBarrier等 1、semaphore 信号量，juc包下的工具类，用来公职同事访问特定资源的线程数。，内部内置了Syn锁，基于AQS实现。 核心方法有acquire和release(); 12345678910111213141516171819202122232425262728293031static class Task extends Thread &#123; Semaphore semaphore; public Task(Semaphore semaphore, String tname) &#123; super(tname); this.semaphore = semaphore; //this.setName(tname); &#125; public void run() &#123; try &#123; //semaphore.acquireUninterruptibly(); semaphore.acquire();//获取公共资源 System.out.println(Thread.currentThread().getName() + &quot;:aquire() at time:&quot; + System.currentTimeMillis()); Thread.sleep(5000); semaphore.release(); /*if(semaphore.tryAcquire(500,TimeUnit.MILLISECONDS))&#123; System.out.println(Thread.currentThread().getName()+&quot;:aquire() at time:&quot;+System.currentTimeMillis()); Thread.sleep(5000); semaphore.release();//释放公共资源 &#125;else&#123; fallback(); &#125;*/ &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; Acquire()可以相应中断，抛出异常。 2、CountDownLatch ConntDownLatch是JDK提供的同步工具，可以让一个或者多个线程等待，一致等待其他线程完成一组操作。 countDown()。计数器减1.当调用await()方法时，计数器加1.当计数器大于0时候线程会被阻塞，一致到计数器 核心方法，countDown(),await(); 3、CyclicBarrier 一个同步辅助，他允许一组线程的所有等待同时达到共同屏障点 核心方法awate()","categories":[{"name":"面试知识","slug":"面试知识","permalink":"https://zhangyong3214.github.io/categories/%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"}]},{"title":"","slug":"知识整理/Spring知识整理","date":"2022-04-05T09:32:31.588Z","updated":"2022-04-05T09:32:31.589Z","comments":true,"path":"2022/04/05/知识整理/Spring知识整理/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/Spring%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/","excerpt":"","text":"Spring知识点Spring 底层核心原理解析ApplicationContext123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123; /** * Return the unique id of this application context. * @return the unique id of the context, or &#123;@code null&#125; if none */ @Nullable String getId(); /** * Return a name for the deployed application that this context belongs to. * @return a name for the deployed application, or the empty String by default */ String getApplicationName(); /** * Return a friendly name for this context. * @return a display name for this context (never &#123;@code null&#125;) */ String getDisplayName(); /** * Return the timestamp when this context was first loaded. * @return the timestamp (ms) when this context was first loaded */ long getStartupDate(); /** * Return the parent context, or &#123;@code null&#125; if there is no parent * and this is the root of the context hierarchy. * @return the parent context, or &#123;@code null&#125; if there is no parent */ @Nullable ApplicationContext getParent(); /** * Expose AutowireCapableBeanFactory functionality for this context. * &lt;p&gt;This is not typically used by application code, except for the purpose of * initializing bean instances that live outside of the application context, * applying the Spring bean lifecycle (fully or partly) to them. * &lt;p&gt;Alternatively, the internal BeanFactory exposed by the * &#123;@link ConfigurableApplicationContext&#125; interface offers access to the * &#123;@link AutowireCapableBeanFactory&#125; interface too. The present method mainly * serves as a convenient, specific facility on the ApplicationContext interface. * &lt;p&gt;&lt;b&gt;NOTE: As of 4.2, this method will consistently throw IllegalStateException * after the application context has been closed.&lt;/b&gt; In current Spring Framework * versions, only refreshable application contexts behave that way; as of 4.2, * all application context implementations will be required to comply. * @return the AutowireCapableBeanFactory for this context * @throws IllegalStateException if the context does not support the * &#123;@link AutowireCapableBeanFactory&#125; interface, or does not hold an * autowire-capable bean factory yet (e.g. if &#123;@code refresh()&#125; has * never been called), or if the context has been closed already * @see ConfigurableApplicationContext#refresh() * @see ConfigurableApplicationContext#getBeanFactory() */ AutowireCapableBeanFactory getAutowireCapableBeanFactory() throws IllegalStateException;&#125; ApplicationContext我们通常称之为Spring的上下文，基本上Spring的核心操作都能通过这个上线文获取。 Spring的bean前提条件 Bean的创建的生命周期 xxxService –&gt;容器初始化(产生一个对象)–&gt;依赖注入(属性赋值)-&gt;初始化前-&gt;初始化–&gt;初始化后-&gt;Spring的bean Spring上线文的初始化 扫描bean 创建非懒加载的单例bean BeanDefinition AbstractBeanDefinition AnnotatedBeanDefinition GenericBeanDefinition AnnotatedGenericBeanDefinition ScannerGenericBeanDefinition BeanDefinitionReader AnnotatedBeanDefinitionReader：读取注解的reader,把一个普通类转换为一个Spring容器的Bean定义(BeanDefinition) XmlBeanFefinitionReader：xml定义的读取器，获取 ClassPathBeanDefinitionScanner：扫描器，通过输入的路径进行扫描 BeanFactoryDefautListableBeanFactory ApplicationContext类型转换Property ConditionConverter SimpleTypeConverter 比较器OrderComparator MetadataReader读取一个类的元数据，解析类。 FactoryBeanConfigirableListableBeanFactoryConfigurable 可配置 Listable 可列举 类型转换器 1beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); 默认beanPostProcesssor 123456beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));## 通过环境变量 忽略接口 1234567beanFactory.ignoreDependencyInterface(EnvironmentAware.class);beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);beanFactory.ignoreDependencyInterface(MessageSourceAware.class);beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);beanFactory.ignoreDependencyInterface(ApplicationStartupAware.class); 解析实现 1234beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);beanFactory.registerResolvableDependency(ResourceLoader.class, this);beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);beanFactory.registerResolvableDependency(ApplicationContext.class, this); HierarchicalMessageSourceSpring bean的扫描过程Spring bean初始化 实例化前: InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() 。有就直接返回，给用户提供了自己实例化bean的机会(如果有的话) @Resource通过CommonAnnotationBeanPostProcessor 循环依赖 实例化AService 填充BService属性 –&gt;去单例池找BService–&gt;没有则创建BService 实例化BService–&gt;得到了对象 填充AService属性–&gt;去单例池找AService-&gt;没有则创建AService。。。(也找不到) 填充其他属性 –&gt; 初始化前、初始化 初始化后 放入单例池 三级缓存 singletonObjects：单例池。完成了完整生命周期的单例bean. earlySingletonObjects：只进行了实例化，还没有进行数据赋值的对象。解决循环依赖，解决单例的情况 singletonFacories：出现循环信赖时候，创建bean的lambda表达式。 earlyProxyObjects：因为循环信赖提前进行了AOP的对象池 Spring循环依赖只能解决单例的情况，如果是原型的情况下是支持不了的 构造方法的循环依赖，情况直接用也是不行的，需要用@Lazy BeanProcesson和advise","categories":[],"tags":[]},{"title":"Java中的各种O","slug":"知识整理/0、Java中的各种O","date":"2022-04-05T09:32:31.587Z","updated":"2022-04-05T09:32:31.587Z","comments":true,"path":"2022/04/05/知识整理/0、Java中的各种O/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/0%E3%80%81Java%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8DO/","excerpt":"","text":"0、Java中的各种O1、POJO Plain Ordinary Java Object 简单Java对象。 简单的Java对象，实际上就是一个普通的JavaBeans。使用POJO是为了避免和EJB混淆起来，而且简称比较直接。其中有一些属性及其getter/setter方法的类，没有业务逻辑。有时候可以作为VO或者DTO来使用。 2、PO Presistant Object 持久化对象 它们是一组属性和属性的setter/getter方法组成。基于O/R映射出现的概念。属性通常对应数据库/数据模型，并且本身也就可以有一些业务逻辑的处理，可以看做是数据库表映射的对象。 3、BO Business Object 业务对象 业务对象就是将业务抽象逻辑封装成的对象。这个对象可以包含很多种其他对象，比如DAO作为数据库访问，或者DTO作为业务数据的传递，也可以持有很多的POJO对象。 4、DO Domain Object 领域对象 就是从显示世界中抽象出来的有形或者无形的业务实体 5、DAO Data Access Obejct 数据访问对象 一般指数据库的访问对象。相当于一个数据的访问接口。加在业务层和数据层中间。通过调用DAO的方法，业务层可以获取一个或者多个PO数据。 6、 DTO Data Transfer Object 数据传输对象 一般只用于客户端和服务端，展示层和服务层，应用间为传递数据而封装的对象。内部可以包含很多VO和POJO 7、 VO Value Object 值对象 通常用于业务层之间的数据传递和PO一样也仅仅包含数据而已。但应对抽象的业务对象，可以和表对应，也可以不，这个需要根据业务需求，用new 关键字创建，由GC回收。","categories":[{"name":"基础知识","slug":"基础知识","permalink":"https://zhangyong3214.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"}]},{"title":"企业开发规范和技巧","slug":"开发工作/开发规范和技巧","date":"2022-04-05T09:32:31.586Z","updated":"2022-04-05T09:32:31.586Z","comments":true,"path":"2022/04/05/开发工作/开发规范和技巧/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C/%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%E5%92%8C%E6%8A%80%E5%B7%A7/","excerpt":"","text":"开发规范前言​ 没有看过阿里开发规范的同学可以先阅读一遍规范里面的内容，《Java 开发手册》是阿里巴巴集团技术团队的集体智慧结晶和经验总结，经历了多次大规模一 线实战的检验及不断完善，公开到业界后，众多社区开发者踊跃参与，共同打磨完善，系统化地整理 成册。为提高软件的最终交付质量，五花八门的错误码人为地 增加排查问题的难度;数据库的表结构和索引设计缺陷带来的系统架构缺陷或性能风险;工程结构混 乱导致后续项目维护艰难;没有鉴权的漏洞代码易被黑客攻击等等，制定一套开发规范出来还是很有必要的，对于增强代码的可读性，提高项目的维护成本，提高问题的排查速度，都会有重要的作用。 命名","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"开发","slug":"开发","permalink":"https://zhangyong3214.github.io/tags/%E5%BC%80%E5%8F%91/"}]},{"title":"Spring技术笔记","slug":"学习笔记/Spring","date":"2022-04-05T09:32:31.585Z","updated":"2022-04-05T09:32:31.585Z","comments":true,"path":"2022/04/05/学习笔记/Spring/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Spring/","excerpt":"","text":"Spring底层核心原理解析下载Spring源码git clone的地址为：https://gitee.com/archguide/spring-framework-5.3.10.git Bean的创建过程那么Spring到底是如何来创建一个Bean的呢，这个就是Bean创建的生命周期，大致过程如下： 利用该类的构造方法来实例化得到一个对象（但是如何一个类中有多个构造方法，Spring则会进行选择，这个叫做推断构造方法） 得到一个对象后，Spring会判断该对象中是否存在被@Autowired注解了的属性，把这些属性找出来并由Spring进行赋值（依赖注入） 依赖注入后，Spring会判断该对象是否实现了BeanNameAware接口、BeanClassLoaderAware接口、BeanFactoryAware接口，如果实现了，就表示当前对象必须实现该接口中所定义的setBeanName()、setBeanClassLoader()、setBeanFactory()方法，那Spring就会调用这些方法并传入相应的参数（Aware回调） Aware回调后，Spring会判断该对象中是否存在某个方法被@PostConstruct注解了，如果存在，Spring会调用当前对象的此方法（初始化前） 紧接着，Spring会判断该对象是否实现了InitializingBean接口，如果实现了，就表示当前对象必须实现该接口中的afterPropertiesSet()方法，那Spring就会调用当前对象中的afterPropertiesSet()方法（初始化） 最后，Spring会判断当前对象需不需要进行AOP，如果不需要那么Bean就创建完了，如果需要进行AOP，则会进行动态代理并生成一个代理对象做为Bean（初始化后） 通过最后一步，我们可以发现，当Spring根据UserService类来创建一个Bean时： 如果不用进行AOP，那么Bean就是UserService类的构造方法所得到的对象。 如果需要进行AOP，那么Bean就是UserService的代理类所实例化得到的对象，而不是UserService本身所得到的对象。 Bean对象创建出来后： 如果当前Bean是单例Bean，那么会把该Bean对象存入一个Map&lt;String,Object&gt;，Map的key为beanName，value为Bean对象。这样下次getBean时就可以直接从Map中拿到对应的Bean对象了。（实际上，在Spring源码中，这个Map就是单例池） 如果当前Bean是原型Bean，那么后续没有其他动作，不会存入一个Map，下次getBean时会再次执行上述创建过程，得到一个新的Bean对象。 推断构造方法Spring在基于某个类生成Bean的过程中，需要利用该类的构造方法来实例化得到一个对象，但是如果一个类存在多个构造方法，Spring会使用哪个呢？ Spring的判断逻辑如下： 如果一个类只存在一个构造方法，不管该构造方法是无参构造方法，还是有参构造方法，Spring都会用这个构造方法 如果一个类存在多个构造方法a. 这些构造方法中，存在一个无参的构造方法，那么Spring就会用这个无参的构造方法b. 这些构造方法中，不存在一个无参的构造方法，那么Spring就会报错 Spring的设计思想是这样的： 如果一个类只有一个构造方法，那么没得选择，只能用这个构造方法 如果一个类存在多个构造方法，Spring不知道如何选择，就会看是否有无参的构造方法，因为无参构造方法本身表示了一种默认的意义 不过如果某个构造方法上加了@Autowired注解，那就表示程序员告诉Spring就用这个加了注解的方法，那Spring就会用这个加了@Autowired注解构造方法了 需要重视的是，如果Spring选择了一个有参的构造方法，Spring在调用这个有参构造方法时，需要传入参数，那这个参数是怎么来的呢？ Spring会根据入参的类型和入参的名字去Spring中找Bean对象（以单例Bean为例，Spring会从单例池那个Map中去找）： 先根据入参类型找，如果只找到一个，那就直接用来作为入参 如果根据类型找到多个，则再根据入参名字来确定唯一一个 最终如果没有找到，则会报错，无法创建当前Bean对象 确定用哪个构造方法，确定入参的Bean对象，这个过程就叫做推断构造方法。 AOP大致流程AOP就是进行动态代理，在创建一个Bean的过程中，Spring在最后一步会去判断当前正在创建的这个Bean是不是需要进行AOP，如果需要则会进行动态代理。 如何判断当前Bean对象需不需要进行AOP: 找出所有的切面Bean 遍历切面中的每个方法，看是否写了@Before、@After等注解 如果写了，则判断所对应的Pointcut是否和当前Bean对象的类是否匹配 如果匹配则表示当前Bean对象有匹配的的Pointcut，表示需要进行AOP 利用cglib进行AOP的大致流程： 生成代理类UserServiceProxy，代理类继承UserService 代理类中重写了父类的方法，比如UserService中的test()方法 代理类中还会有一个target属性，该属性的值为被代理对象（也就是通过UserService类推断构造方法实例化出来的对象，进行了依赖注入、初始化等步骤的对象） 代理类中的test()方法被执行时的逻辑如下：a. 执行切面逻辑（@Before）b. 调用target.test() 当我们从Spring容器得到UserService的Bean对象时，拿到的就是UserServiceProxy所生成的对象，也就是代理对象。UserService代理对象.test()—&gt;执行切面逻辑—&gt;target.test()，注意target对象不是代理对象，而是被代理对象。 Spring事务当我们在某个方法上加了@Transactional注解后，就表示该方法在调用时会开启Spring事务，而这个方法所在的类所对应的Bean对象会是该类的代理对象。 Spring事务的代理对象执行某个方法时的步骤： 判断当前执行的方法是否存在@Transactional注解 如果存在，则利用事务管理器（TransactionMananger）新建一个数据库连接 修改数据库连接的autocommit为false 执行target.test()，执行程序员所写的业务逻辑代码，也就是执行sql 执行完了之后如果没有出现异常，则提交，否则回滚 Spring事务是否会失效的判断标准：某个加了@Transactional注解的方法被调用时，要判断到底是不是直接被代理对象调用的，如果是则事务会生效，如果不是则失效。","categories":[{"name":"框架","slug":"框架","permalink":"https://zhangyong3214.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"}]},{"title":"RabbitMQ消息中间件技术笔记","slug":"学习笔记/RabbitMQ","date":"2022-04-05T09:32:31.582Z","updated":"2022-04-05T09:32:31.584Z","comments":true,"path":"2022/04/05/学习笔记/RabbitMQ/","link":"","permalink":"https://zhangyong3214.github.io/2022/04/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/RabbitMQ/","excerpt":"","text":"MQ相关概念什么是MQMQ(message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用了 MQ之后，消息发送上游只需要依赖 MQ，不用依赖其他服务。 为什么要用MQ 流量消峰 举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。 应用解耦 以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。 异步提速 有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完，以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题，A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样 B 服务也不用做这些操作。A 服务还能及时的得到异步处理成功的消息。 MQ的分类 ActiveMQ优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，消息可靠性较低的概率丢失数据。 缺点：官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。 Kafka大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为大数据而生的消息中间件，以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。 优点：性能卓越，单机写入 TPS 约在百万条/秒，最大的优点，就是吞吐量高。时效性 ms 级可用性非常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用,消费者采用 Pull 方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;有优秀的第三方Kafka Web 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；功能支持：功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。 缺点：Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序，但是一台代理宕机后，就会产生消息乱序，社区更新较慢。 RocketMQRocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场景。 优点：单机吞吐量十万级,可用性非常高，分布式架构,消息可以做到 0 丢失,MQ 功能较为完善，还是分布式的，扩展性好,支持 10 亿级别的消息堆积，不会因为堆积导致性能下降,源码是 java 我们可以自己阅读源码，定制自己公司的 MQ。 缺点：支持的客户端语言不多，目前是 java 及 c++，其中 c++不成熟；社区活跃度一般,没有在 MQ核心中去实现 JMS 等接口,有些系统要迁移需要修改大量代码。 RabbitMQ2007 年发布，是一个在 AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。 优点：由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备,健壮、稳定、易用、跨平台、支持多种语言 如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持 AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用,社区活跃度高；更新频率相当高。 缺点：商业版需要收费,学习成本较高。 MQ的选择KafkaKafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。 RocketMQ天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。 RabbitMQ结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。 RabbitMQ简介2007年，Rabbit 技术公司基于 AMQP 标准开发的 RabbitMQ 1.0 发布。RabbitMQ 采用 Erlang 语言开发。Erlang 语言由 Ericson 设计，专门为开发高并发和分布式系统的一种语言，在电信领域使用广泛。 RabbitMQ四大核心概念 生产者产生数据发送消息的程序是生产者 交换机交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定。 队列 队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式。 消费者 消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。 RabbitMQ的工作模式 简单模式 HelloWorld： 一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。 工作队列模式 Work Queue： 一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。 发布订阅模式 Publish/subscribe：需要设置类型为 fanout 的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。 路由模式 Routing： 需要设置类型为 direct 的交换机，交换机和队列进行绑定，并且指定 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 通配符模式 Topic：需要设置类型为 topic 的交换机，交换机和队列进行绑定，并且指定通配符方式的 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 RabbitMQ工作原理 Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等 Connection：publisher／consumer 和 broker 之间的 TCP 连接 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCPConnection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。 l Channel 作为轻量级的Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange ： message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout(multicast) Queue ： 消息最终被送到这里等待 consumer 取走 Binding ： exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据 RabbitMQ安装略….推荐使用Docker安装学习，参考文章：Docker操作笔记-从小白到入门 RabbitMQ在安装好后，可以访问http://ip地址:15672 ;其自带了guest/guest的 用户名和密码。 角色说明 超级管理员(administrator)：可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操 作。 监控者(monitoring)：可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用 情况，磁盘使用情况等)。 策略制定者(policymaker)：可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上 图红框标识的部分)。 普通管理者(management)：仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他：无法登陆管理控制台，通常就是普通的生产者和消费者。 消息应答及持久化消息应答机制概念消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成了部分突然它挂掉了，会发生什么情况。RabbitMQ 一旦向消费者传递了一条消息，便立即将该消息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息。以及后续发送给该消费这的消息，因为它无法接收到。为了保证消息在发送过程中不丢失，rabbitmq 引入消息应答机制，消息应答就是: 消费者在接收到消息并且处理该消息之后，告诉rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。 自动应答消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡,因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失了,当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，当然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终使得内存耗尽，最终这些消费者线程被操作系统杀死， 所以这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。 总结：尽量少用自动应答，自动应答是在接收到消息的一刹那就进行了应答，如果后续对消息进行了处理出现错误，不能重新从队列中获取消息处理。 手动应答消息应答的方法 Channel.basicAck(用于肯定确认)：RabbitMQ 已知道该消息并且成功的处理消息，可以将其丢弃了 Channel.basicNack(用于否定确认) Channel.basicReject(用于否定确认)：与 Channel.basicNack 相比少一个参数(是否批量处理)，不处理该消息了直接拒绝，可以将其丢弃了 手动应答的好处是可以批量应答并且减少网络拥堵 multiple 的 true 和 false 代表不同意思 true 代表批量应答 channel 上未应答的消息，比如说 channel 上有传送 tag 的消息 5,6,7,8 当前 tag 是 8 那么此时5-8 的这些还未应答的消息都会被确认收到消息应答 false 同上面相比只会应答 tag=8 的消息 5,6,7 这三个消息依然不会被确认收到消息应答 消息自动重新入队如果消费者由于某些原因失去连接(其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。 消息手动应答代码编写默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改为手动应答，消费者在上面代码的基础上增加下面画红色部分代码。 消息生产者123456789101112131415161718public class Producer &#123; // 队列名称 public static final String TASK_QUEUE_NAME = &quot;ack_queue&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 声明队列：队列名称，是否持久化，是否共享，自动删除，参数 channel.queueDeclare(TASK_QUEUE_NAME, false, false, false, null); Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) &#123; String message = scanner.next(); channel.basicPublish(&quot;&quot;, TASK_QUEUE_NAME, null, message.getBytes(StandardCharsets.UTF_8)); log.info(&quot;生产者发送消息：&#123;&#125;&quot;, message); &#125; &#125;&#125; RabbitMQ 连接工具类 123456789101112131415public class RabbitMqUtils &#123; // 得到一个连接的 channel public static Channel getChannel() throws Exception &#123; // 创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;127.0.0.1&quot;); factory.setPort(5672); factory.setUsername(&quot;guest&quot;); factory.setPassword(&quot;guest&quot;); factory.setVirtualHost(&quot;demo&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); return channel; &#125;&#125; 消费者1234567891011121314151617181920212223242526public class Work01 &#123; private static final String ACK_QUEUE_NAME = &quot;ack_queue&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); System.out.println(&quot;Work01 等待接收消息处理时间较短&quot;); // 消息消费的时候如何处理消息 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody()); // 业务处理耗时1秒 SleepUtils.sleep(1); System.out.println(&quot; 接收到消息:&quot; + message); /** * 采用手动应答 * 1. 消息标记 tag * 2. 是否批量应答未应答消息：不批量信道中的消息 */ channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;; // ***采用手动应答 boolean autoAck = false; channel.basicConsume(ACK_QUEUE_NAME, autoAck, deliverCallback, (consumerTag) -&gt; &#123; System.out.println(consumerTag + &quot; 消费者取消消费接口回调逻辑&quot;); &#125;); &#125;&#125; 睡眠工具 123456789public class SleepUtils &#123; public static void sleep(int second) &#123; try &#123; Thread.sleep(1000L * second); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; RabbitMQ 持久化持久化概念刚刚我们已经看到了如何处理任务不丢失的情况，但是如何保障当 RabbitMQ 服务停掉以后消息生产者发送过来的消息不丢失。默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事：我们需要将队列和消息都标记为持久化。 队列实现持久化之前我们创建的队列都是非持久化的，rabbitmq 如果重启的化，该队列就会被删除掉，如果 要队列实现持久化 需要在声明队列的时候把 durable 参数设置为持久化 但是需要注意的就是如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误。 以下为控制台中持久化与非持久化队列的 UI 显示区： 这个时候即使重启 rabbitmq 队列也依然存在。 消息实现持久化要想让消息实现持久化需要在消息生产者修改代码，MessageProperties.PERSISTENT_TEXT_PLAIN 添加这个属性，如下图 将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是 这里依然存在当消息刚准备存储在磁盘的时候 但是还没有存储完，消息还在缓存的一个间隔点。此时并没 有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。如果需要 更强有力的持久化策略，参考后边课件发布确认章节。 不公平分发在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好，但是RabbitMQ 并不知道这种情况它依然很公平的进行分发。 注：为了避免这种情况，我们可以设置参数 channel.basicQos(1)，不公平分发由消费方设置，生产环境应该设置为不公平分发。 意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略。 发布确认发布确认原理生产者将信道设置成 confirm 模式，一旦信道进入confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker 就会发送一个确认给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传 给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消 息，生产者应用程序同样可以在回调方法中处理该nack消息。 发布确认的策略开启发布确认的方法发布确认默认是没有开启的，如果要开启需要调用方法 confirmSelect，每当你要想使用发布确认，都需要在 channel 上调用该方法。 12Channel channel = connection.createchannel();channel.confirmselect(); 第一种：单个确认发布这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它 被确认发布，后续的消息才能继续发布,waitForConfirmsOrDie(long)这个方法只有在消息被确认 的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。这种确认方式有一个最大的缺点就是:发布速度特别的慢，因为如果没有确认发布的消息就会 阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某 些应用程序来说这可能已经足够了。 123456789101112131415161718192021// 发布单条消息1000条耗时测试： 722mspublic static void publishMessageOne() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = i + &quot;&quot;; channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); // 发送之后马上进行发布确认，服务端返回 false 或超时时间内未返回，生产者可以消息重发 boolean flag = channel.waitForConfirms(); if (flag) &#123; System.out.println(&quot; 消息发送成功&quot;); &#125; &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个单独确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 第二种：批量确认发布上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地 提高吞吐量，当然这种方式的缺点就是:当发生故障导致发布出现问题时，不知道是哪个消息出现 问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种 方案仍然是同步的，也一样阻塞消息的发布。 123456789101112131415161718192021222324252627282930// 批量发布确认 发布1000个消息，耗时141mspublic static void publishMessageBatch() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); // 批量确认消息大小 int batchSize = 100; // 未确认消息个数 int outstandingMessageCount = 0; long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = i + &quot;&quot;; channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); outstandingMessageCount++; // 100条确认一次 if (outstandingMessageCount == batchSize) &#123; channel.waitForConfirms(); outstandingMessageCount = 0; &#125; &#125; // 为了确保还有剩余没有确认消息 再次确认 if (outstandingMessageCount &gt; 0) &#123; channel.waitForConfirms(); &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个批量确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 第三种：异步确认发布异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说， 他是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功， 下面就让我们来详细讲解异步确认是怎么实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 异步发布确认 发布1000个消息，耗时62mspublic static void publishMessageAsync() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); /** * 线程安全有序的一个哈希表，适用于高并发的情况 * 1. 轻松的将序号与消息进行关联 * 2. 轻松批量删除条目 只要给到序列号 * 3. 支持并发访问 */ ConcurrentSkipListMap&lt;Long, String&gt; outstandingConfirms = new ConcurrentSkipListMap&lt;&gt;(); /** * 确认收到消息的一个回调 * 1. 消息序列号 * 2.true 可以确认小于等于当前序列号的消息 * false 确认当前序列号消息 */ ConfirmCallback ackCallback = (sequenceNumber, multiple) -&gt; &#123; if (multiple) &#123; // 返回的是小于等于当前序列号的未确认消息 是一个 map ConcurrentNavigableMap&lt;Long, String&gt; confirmed = outstandingConfirms.headMap(sequenceNumber, true); // 清除该部分未确认消息 confirmed.clear(); &#125;else&#123; // 只清除当前序列号的消息 outstandingConfirms.remove(sequenceNumber); &#125; &#125;; ConfirmCallback nackCallback = (sequenceNumber, multiple) -&gt; &#123; String message = outstandingConfirms.get(sequenceNumber); System.out.println(&quot; 发布的消息&quot;+message+&quot; 未被确认，序列号&quot;+sequenceNumber); &#125;; /** * 添加一个异步确认的监听器 * 1. 确认收到消息的回调 * 2. 未收到消息的回调 */ channel.addConfirmListener(ackCallback, null); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = &quot; 消息&quot; + i; /** * channel.getNextPublishSeqNo() 获取下一个消息的序列号 * 通过序列号与消息体进行一个关联 * 全部都是未确认的消息体 */ outstandingConfirms.put(channel.getNextPublishSeqNo(), message); channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个异步确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 如何处理异步未确认消息好的解决的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列， 比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传 递。 3种发布确认速度对比 单独发布消息：同步等待确认，简单，但吞吐量非常有限。 批量发布消息：批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是那条消息出现了问题。 异步处理：最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些。 交换机在上一节中，我们创建了一个工作队列。我们假设的是工作队列背后，每个任务都恰好交付给一个消 费者(工作进程)。在这一部分中，我们将做一些完全不同的事情-我们将消息传达给多个消费者。这种模式 称为 ”发布/订阅”，为了说明这种模式，我们将构建一个简单的日志系统。它将由两个程序组成:第一个程序将发出日志消 息，第二个程序是消费者。其中我们会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘，另外一个消费者接收到消息后把消息打印在屏幕上，事实上第一个程序发出的日志消息将广播给所有消费者。 Exchanges概念RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。相反，**生产者只能将消息发送到交换机(exchange)**，交换机工作的内容非常简单，一方面它接收来 自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息。是应该把这些消 息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。 Exchanges 的类型 直接(direct) — 路由类型 主题(topic) — 通配符匹配模式 标题(headers) — 已经不用了 扇出(fanout) — 发布订阅类型 无名 exchange第一个参数是交换机的名称。空字符串表示默认或无名称交换机：消息能路由发送到队列中其实是由 routingKey(bindingkey)绑定 key 指定的。 临时队列每当我们连接到 Rabbit 时，我们都需要一个全新的空队列，为此我们可以创建一个具有随机名称的队列，或者能让服务器为我们选择一个随机队列名称那就更好了。其次一旦我们断开了消费者的连接，队列将被自动删除。创建临时队列的方式如下:String queueName = channel.queueDeclare().getQueue(); 绑定(bindings)什么是 bingding 呢，binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和那个队 列进行了绑定关系。比如说下面这张图告诉我们的就是 X 与 Q1 和 Q2 进行了绑定 Fanout(发布订阅交换机)Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的 所有队列中。系统中默认有些 exchange 类型 Fanout 实战 Logs 和临时队列的绑定关系如下图 发布订阅发布者1234567891011121314151617181920public class EmitLog &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; /** * 声明一个 exchange * 1.exchange 的名称 * 2.exchange 的类型 */ channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); Scanner sc = new Scanner(System.in); System.out.println(&quot; 请输入信息&quot;); while (sc.hasNext()) &#123; String message = sc.nextLine(); channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot; 生产者发出消息&quot; + message); &#125; &#125; &#125;&#125; 发布订阅接收者112345678910111213141516171819202122public class ReceiveLogs01 &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); // 把该临时队列绑定我们的 exchange 其中 routingkey( 也称之为 binding key) 为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); System.out.println(&quot;01等待接收消息, 把接收到的消息打印在屏幕.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;01控制台打印接收到的消息&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 发布订阅接收者212345678910111213141516171819202122public class ReceiveLogs02 &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); // 把该临时队列绑定我们的 exchange 其中 routingkey( 也称之为 binding key) 为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); System.out.println(&quot;02等待接收消息, 把接收到的消息打印在屏幕.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;02控制台打印接收到的消息&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; Direct exchange(直接交换机)上一节中，我们构建了一个简单的日志记录系统。我们能够向许多接收者广播日志消息。在本节我们将向其中添加一些特别的功能-比方说我们只让某个消费者订阅发布的部分消息。例如我们只把严重错误消息定向存储到日志文件(以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息。我们再次来回顾一下什么是 bindings，绑定是交换机和队列之间的桥梁关系。也可以这么理解：队列只对它绑定的交换机的消息感兴趣。绑定用参数：routingKey 来表示也可称该参数为 binding key，创建绑定我们用代码:channel.queueBind(queueName, EXCHANGE_NAME, &quot;routingKey&quot;);绑定之后的意义由其交换类型决定。 直接交换机发布者12345678910111213141516171819202122public class EmitLogDirect &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 创建多个 bindingKey Map&lt;String, String&gt; bindingKeyMap = new HashMap&lt;&gt;(); bindingKeyMap.put(&quot;info&quot;, &quot; 普通 info 信息&quot;); bindingKeyMap.put(&quot;warning&quot;, &quot; 警告 warning 信息&quot;); bindingKeyMap.put(&quot;error&quot;, &quot; 错误 error 信息&quot;); //debug 没有消费这接收这个消息 所有就丢失了 bindingKeyMap.put(&quot;debug&quot;, &quot; 调试 debug 信息&quot;); for (Map.Entry&lt;String, String&gt; bindingKeyEntry : bindingKeyMap.entrySet()) &#123; String bindingKey = bindingKeyEntry.getKey(); String message = bindingKeyEntry.getValue(); channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(StandardCharsets.UTF_8)); System.out.println(&quot; 生产者发出消息:&quot; + message); &#125; &#125; &#125;&#125; 直接交换机消费者11234567891011121314151617181920public class ReceiveLogsDirect01 &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = &quot;disk&quot;; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, &quot;error&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); message = &quot; 接收绑定键:&quot; + delivery.getEnvelope().getRoutingKey() + &quot;, 消息:&quot; + message; // 写磁盘忽略 System.out.println(&quot; 错误日志已经接收&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 直接交换机消费者212345678910111213141516171819public class ReceiveLogsDirect02 &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = &quot;console&quot;; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, &quot;info&quot;); channel.queueBind(queueName, EXCHANGE_NAME, &quot;warning&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot; 接 收 绑 定 键 :&quot; + delivery.getEnvelope().getRoutingKey() + &quot;, 消息:&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; Topics(主题交换机)在上一个小节中，我们改进了日志记录系统。我们没有使用只能进行随意广播的 fanout 交换机，而是使用了 direct 交换机，从而有能实现有选择性地接收日志。尽管使用 direct 交换机改进了我们的系统，但是它仍然存在局限性-比方说我们想接收的日志类型有info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候 direct 就办不到了。这个时候就只能使用 topic 类型。 Topic 要求发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词，比如说：”stock.usd.nyse”, “nyse.vmw”,”quick.orange.rabbit”.这种类型的。当然这个单词列表最多不能超过 255 个字节。在这个规则列表中，其中有两个替换符是大家需要注意的 *(星号)可以代替一个单词 #(井号)可以替代零个或多个单词 Topic 匹配案例下图绑定关系如下： Q1–&gt;绑定的是：中间带 orange 带 3 个单词的字符串(.orange.) Q2–&gt;绑定的是：最后一个单词是 rabbit 的 3 个单词(..rabbit) 第一个单词是 lazy 的多个单词(lazy.#) 上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的quick.orange.rabbit ———— 被队列 Q1Q2 接收到lazy.orange.elephant ———— 被队列 Q1Q2 接收到quick.orange.fox ———— 被队列 Q1 接收到lazy.brown.fox ———— 被队列 Q2 接收到lazy.pink.rabbit ———— 虽然满足两个绑定但只被队列 Q2 接收一次quick.brown.fox ———— 不匹配任何绑定不会被任何队列接收到会被丢弃quick.orange.male.rabbit ———— 是四个单词不匹配任何绑定会被丢弃lazy.orange.male.rabbit ———— 是四个单词但匹配 Q2 当队列绑定关系是下列这种情况时需要引起注意 当一个队列绑定键是#,那么这个队列将接收所有数据，就有点像 fanout 了，如果队列绑定键当中没有#和*出现，那么该队列绑定类型就是 direct 了。 死信队列死信的概念先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理 解，一般来说，producer 将消息投递到 broker 或者直接到 queue 里了，consumer 从 queue 取出消息 进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有 后续的处理，就变成了死信，有死信自然就有了死信队列。 应用场景:为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息 消费发生异常时，将消息投入死信队列中.还有比如说: 用户在商城下单成功并点击去支付后在指定时 间未支付时自动失效 死信的来源 消息 TTL 过期 队列达到最大长度(队列满了，无法再添加数据到 mq 中) 消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false. 代码架构图 消息TTL过期代码死信生产者123456789101112131415161718public class Producer &#123; private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); // 设置消息的 TTL 时间 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(&quot;10000&quot;).build(); // 该信息是用作演示队列个数限制 for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; channel.basicPublish(NORMAL_EXCHANGE, &quot;zhangsan&quot;, properties, message.getBytes()); System.out.println(&quot; 生产者发送消息:&quot; + message); &#125; &#125; &#125;&#125; 死信消费者C1消费者 C1 ( 启动之后关闭该消费者 模拟其接收不到消息) 12345678910111213141516171819202122232425262728293031323334public class Consumer01 &#123; // 普通交换机名称 private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; // 死信交换机名称 private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 声明死信和普通交换机 类型为 direct channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); // 声明死信队列 String deadQueue = &quot;dead-queue&quot;; channel.queueDeclare(deadQueue, false, false, false, null); // 死信队列绑定死信交换机与 routingkey channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;); // 正常队列绑定死信队列信息 Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); // 正常队列设置死信交换机 参数 key 是固定值 params.put(&quot;x-dead-letter-exchange&quot;, DEAD_EXCHANGE); // 正常队列设置死信 routing-key 参数 key 是固定值 params.put(&quot;x-dead-letter-routing-key&quot;, &quot;lisi&quot;); String normalQueue = &quot;normal-queue&quot;; channel.queueDeclare(normalQueue, false, false, false, params); channel.queueBind(normalQueue, NORMAL_EXCHANGE, &quot;zhangsan&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot;Consumer01 接收到消息&quot; + message); &#125;; channel.basicConsume(normalQueue, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 死信队列消费者消费者 C2 ( 以上步骤完成后 启动 C2 消费者它消费死信队列里面的消息) 123456789101112131415161718public class Consumer02 &#123; private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); String deadQueue = &quot;dead-queue&quot;; channel.queueDeclare(deadQueue, false, false, false, null); channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;); System.out.println(&quot; 等待接收死信队列消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot;Consumer02 接收死信队列的消息&quot; + message); &#125;; channel.basicConsume(deadQueue, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 队列达到最大长度生产者消息生产者代码去掉 TTL 属性 123456789101112131415public class TooLongProducer &#123; private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); // 该信息是用作演示队列个数限制 for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; channel.basicPublish(NORMAL_EXCHANGE, &quot;zhangsan&quot;, null, message.getBytes()); System.out.println(&quot; 生产者发送消息:&quot; + message); &#125; &#125; &#125;&#125; 消费者C1 消费者修改以下代码 ( 启动之后关闭该消费者 模拟其接收不到消息) 注意此时需要把原先队列删除 因为参数改变了 ,C2 消费者代码不变( 启动 C2 消费者) 消息被拒进入死信代码略 延迟队列延时队列,队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。 延迟队列使用场景 订单在十分钟之内未支付则自动取消 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 用户注册成功后，如果三天内没有登陆则进行短信提醒。 用户发起退款，如果三天内没有得到处理则通知相关运营人员。 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议 RabbitMQ 中的 TTLTTL 是什么呢？TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者进入了设置 TTL 属性的队列，那么这条消息如果在 TTL 设置的时间内没有被消费，则会成为”死信”。如果同时配置了队列的 TTL 和消息的TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。 消息设置 TTL另一种方式便是针对每条消息设置 TTL 队列设置 TTL第一种是在创建队列的时候设置队列的“x-message-ttl”属性 两者的区别如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队列中)，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。 前一小节我们介绍了死信队列，刚刚又介绍了 TTL，至此利用 RabbitMQ 实现延时队列的两大要素已经集齐，接下来只需要将它们进行融合，再加入一点点调味料，延时队列就可以新鲜出炉了。想想看，延时队列，不就是想要消息延迟多久被处理吗，TTL 则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就完事了，因为里面的消息都是希望被立即处理的消息。 整合SpringBoot添加依赖123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;!--RabbitMQ 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--RabbitMQ 测试依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 修改配置文件1234spring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=123 死信队列实现延迟MQ创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是 direct，创建一个死信队列 QD，它们的绑定关系如下： 配置文件类代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class TtlQueueConfig &#123; public static final String X_EXCHANGE = &quot;X&quot;; public static final String QUEUE_A = &quot;QA&quot;; public static final String QUEUE_B = &quot;QB&quot;; public static final String Y_DEAD_LETTER_EXCHANGE = &quot;Y&quot;; public static final String DEAD_LETTER_QUEUE = &quot;QD&quot;; // 声明 xExchange @Bean(&quot;xExchange&quot;) public DirectExchange xExchange() &#123; return new DirectExchange(X_EXCHANGE); &#125; // 声明 xExchange @Bean(&quot;yExchange&quot;) public DirectExchange yExchange() &#123; return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); &#125; // 声明队列 A ttl 为 10s 并绑定到对应的死信交换机 @Bean(&quot;queueA&quot;) public Queue queueA() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); // 声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE); // 声明当前队列的死信路由 key args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;); // 声明队列的 TTL args.put(&quot;x-message-ttl&quot;, 10000); return QueueBuilder.durable(QUEUE_A).withArguments(args).build(); &#125; // 声明队列 A 绑定 X 交换机 @Bean public Binding queueaBindingX(@Qualifier(&quot;queueA&quot;) Queue queueA, @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123; return BindingBuilder.bind(queueA).to(xExchange).with(&quot;XA&quot;); &#125; // 声明队列 B ttl 为 40s 并绑定到对应的死信交换机 @Bean(&quot;queueB&quot;) public Queue queueB() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); // 声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE); // 声明当前队列的死信路由 key args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;); // 声明队列的 TTL args.put(&quot;x-message-ttl&quot;, 40000); return QueueBuilder.durable(QUEUE_B).withArguments(args).build(); &#125; // 声明队列 B 绑定 X 交换机 @Bean public Binding queuebBindingX(@Qualifier(&quot;queueB&quot;) Queue queue1B, @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123; return BindingBuilder.bind(queue1B).to(xExchange).with(&quot;XB&quot;); &#125; // 声明死信队列 QD @Bean(&quot;queueD&quot;) public Queue queueD() &#123; return new Queue(DEAD_LETTER_QUEUE); &#125; // 声明死信队列 QD 绑定关系 @Bean public Binding deadLetterBindingQAD(@Qualifier(&quot;queueD&quot;) Queue queueD, @Qualifier(&quot;yExchange&quot;) DirectExchange yExchange) &#123; return BindingBuilder.bind(queueD).to(yExchange).with(&quot;YD&quot;); &#125;&#125; 生产者代码1234567891011121314@Slf4j@RequestMapping(&quot;ttl&quot;)@RestControllerpublic class SendMsgController &#123; @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(&quot;sendMsg/&#123;message&#125;&quot;) public void sendMsg(@PathVariable String message) &#123; log.info(&quot; 当前时间：&#123;&#125;, 发送一条信息给两个 TTL 队列:&#123;&#125;&quot;, new Date(), message); rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XA&quot;, &quot; 消息来自 ttl 为 为 10S 的队列: &quot; + message); rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XB&quot;, &quot; 消息来自 ttl 为 为 40S 的队列: &quot; + message); &#125;&#125; 消费者代码123456789@Slf4j@Componentpublic class DeadLetterQueueConsumer &#123; @RabbitListener(queues = &quot;QD&quot;) public void receiveD(Message message, Channel channel) throws IOException &#123; String msg = new String(message.getBody()); log.info(&quot; 当前时间：&#123;&#125;, 收到死信队列信息&#123;&#125;&quot;, new Date().toString(), msg); &#125;&#125; 第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息，然后被消费掉，这样一个延时队列就打造完成了。不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？ 延时队列优化在这里新增了一个队列 QC,绑定关系如下,该队列不设置 TTL 时间 看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时“死亡“，因为 RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列，如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。 Rabbitmq插件实现延迟队列参考文章 SpringBoot+RabbitMQ用死信队列和插件形式实现延迟队列 Docker安装Rabbitmq及其延时队列插件 安装延时队列插件在官网 ，下载rabbitmq_delayed_message_exchange插件，然后解压放置到 RabbitMQ 的插件目录。进入 RabbitMQ 的安装目录下的 plgins 目录，执行下面命令让该插件生效，然后重启 RabbitMQ /usr/lib/rabbitmq/lib/rabbitmq_server-3.8.8/plugins rabbitmq-plugins enable rabbitmq_delayed_message_exchange 发布确认高级姿势在生产环境中由于一些不明原因，导致 rabbitmq 重启，在 RabbitMQ 重启期间生产者消息投递失败，导致消息丢失，需要手动处理和恢复。于是，我们开始思考，如何才能进行 RabbitMQ 的消息可靠投递呢？特别是在这样比较极端的情况，RabbitMQ 集群不可用的时候，无法投递的消息该如何处理呢: 发布确认 springboot 版本确认机制方案 代码架构图 配置文件12# 在配置文件当中需要添加spring.rabbitmq.publisher-confirm-type=correlated NONE：禁用发布确认模式，是默认值 CORRELATED：发布消息成功到交换器后会触发回调方法 SIMPLE：经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker，注：此配置同步确认消息，生产不建议使用 交换机发布确认代码1234567891011121314151617181920212223242526272829public class MessageConfirmCallBack&lt;T&gt; implements RabbitTemplate.ConfirmCallback &#123; @Resource private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setConfirmCallback(this); &#125; /** * 交换机确认回调方法 (发布者发送消息是否到交换机触发回调) * 1. 发消息 交换机接收到消息，回调 * 1.1 correlationData 保存毁掉消息的id及相关信息 * 1.2 交换机接收到消息 true * 1.3 失败原因-null * 2. 发消息 交换机接收失败 回调 * 2.1 correlationData 保存毁掉消息的id及相关信息 * 2.2 false * 2.3 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if (ack) &#123; log.info(&quot;发布确认:交换机收到消息id：&#123;&#125;&quot;, correlationData.getId()); &#125; else &#123; log.info(&quot;发布确认:交换机未收到消息，id为：&#123;&#125;,原因：&#123;&#125;&quot;, correlationData.getId(), cause); // TODO 保存数据库重新发送等逻辑保证消息重新发送给交换机 &#125; &#125;&#125; 回退消息在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的。那么如何让无法被路由的消息帮我想办法处理一下？最起码通知我一声，我好自己处理啊。通过设置 mandatory 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者。 添加配置12# 消息回退配置，如果消息无法路由，则回退给生产者spring.rabbitmq.publisher-returns=true 回退代码演示1234567891011121314151617181920212223public class MessageReturnCallBack&lt;T&gt; implements RabbitTemplate.ReturnCallback &#123; @Resource private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setReturnCallback(this); &#125; /** * 可以将消息传递过程中不可达到目的地(队列)的消息返回给生产者 * 只有不可达 才会回退消息 * 请注意!!!如果你使用了延迟队列插件，那么一定会调用该callback方法，因为数据并没有提交上去， * 而是提交在交换器中，过期时间到了才提交上去，并非是bug！你可以用if进行判断交换机名称来捕捉该报错 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; if(exchange.equals(delayedQueueProperties.getDelayedExchangeName()))&#123; return; &#125; log.info(&quot;消息&#123;&#125;，被交换机&#123;&#125;退回，退回原因：&#123;&#125;，路由Key：&#123;&#125;&quot;, new String(message.getBody()), exchange, replyText, routingKey); &#125;&#125; 备份交换机有了 mandatory 参数和回退消息，我们获得了对无法投递消息的感知能力，有机会在生产者的消息无法被投递时发现并处理。但有时候，我们并不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更加麻烦而且容易出错。而且设置 mandatory 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，该怎么做呢？前面在设置死信队列的文章中，我们提到，可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。在 RabbitMQ 中，有一种备份交换机的机制存在，可以很好的应对这个问题。什么是备份交换机呢？备份交换机可以理解为 RabbitMQ 中交换机的“备胎”，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 Fanout ，这样就能把所有消息都投递到与其绑定的队列中，然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。 备份交换机代码声明在原来的代码上面多声明一个交换机和两个队列，还有一个报警消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// @Configurationpublic class ConfirmConfig &#123; public static final String CONFIRM_EXCHANGE_NAME = &quot;confirm.exchange&quot;; public static final String CONFIRM_QUEUE_NAME = &quot;confirm.queue&quot;; public static final String BACKUP_EXCHANGE_NAME = &quot;backup.exchange&quot;; public static final String BACKUP_QUEUE_NAME = &quot;backup.queue&quot;; public static final String WARNING_QUEUE_NAME = &quot;warning.queue&quot;; // 声明确认队列 @Bean(&quot;confirmQueue&quot;) public Queue confirmQueue() &#123; return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); &#125; // 声明确认队列绑定关系 @Bean public Binding queueBinding(@Qualifier(&quot;confirmQueue&quot;) Queue queue, @Qualifier(&quot;confirmExchange&quot;) DirectExchange exchange) &#123; return BindingBuilder.bind(queue).to(exchange).with(&quot;key1&quot;); &#125; // 声明备份 Exchange @Bean(&quot;backupExchange&quot;) public FanoutExchange backupExchange() &#123; return new FanoutExchange(BACKUP_EXCHANGE_NAME); &#125; // 声明确认 Exchange 交换机的备份交换机 @Bean(&quot;confirmExchange&quot;) public DirectExchange confirmExchange() &#123; ExchangeBuilder exchangeBuilder = ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME) .durable(true) // 设置该交换机的备份交换机 .withArgument(&quot;alternate-exchange&quot;, BACKUP_EXCHANGE_NAME); return (DirectExchange) exchangeBuilder.build(); &#125; // 声明警告队列 @Bean(&quot;warningQueue&quot;) public Queue warningQueue() &#123; return QueueBuilder.durable(WARNING_QUEUE_NAME).build(); &#125; // 声明报警队列绑定关系 @Bean public Binding warningBinding(@Qualifier(&quot;warningQueue&quot;) Queue queue, @Qualifier(&quot;backupExchange&quot;) FanoutExchange backupExchange) &#123; return BindingBuilder.bind(queue).to(backupExchange); &#125; // 声明备份队列 @Bean(&quot;backQueue&quot;) public Queue backQueue() &#123; return QueueBuilder.durable(BACKUP_QUEUE_NAME).build(); &#125; // 声明备份队列绑定关系 @Bean public Binding backupBinding(@Qualifier(&quot;backQueue&quot;) Queue queue, @Qualifier(&quot;backupExchange&quot;) FanoutExchange backupExchange) &#123; return BindingBuilder.bind(queue).to(backupExchange); &#125;&#125; 报警消费者1234567891011@Component@Slf4jpublic class WarningConsumer &#123; public static final String WARNING_QUEUE_NAME = &quot;warning.queue&quot;; @RabbitListener(queues = WARNING_QUEUE_NAME) public void receiveWarningMsg(Message message) &#123; String msg = new String(message.getBody()); log.error(&quot; 报警发现不可路由消息：&#123;&#125;&quot;, msg); &#125;&#125; 测试注意事项 重新启动项目的时候需要把原来的 confirm.exchange 删除因为我们修改了其绑定属性，不然报错。 备份交换机和回退优先级mandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，消息究竟何去何从？谁优先级高，经过上面结果显示答案是备份交换机优先级高。 RabbitMQ其他知识点幂等性用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等 消息重复消费消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断，故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。 解决思路MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识比如时间戳 或者 UUID 或者订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。 消费端的幂等性保障在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性，这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。业界主流的幂等性有两种操作:a.唯一 ID+指纹码机制,利用数据库主键去重, b.利用 redis 的原子性去实现 唯一ID+ 指纹码机制指纹码:我们的一些规则或者时间戳加别的服务给到的唯一信息码,它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中,优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。 Redis原子性利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费，此方式为目前用的最多的方案。 优先级队列使用场景在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单,淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧，但是，tmall商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果，小米这样大商家一年起码能给我们创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化,如果发现是大客户的订单给一个相对比较高的优先级，否则就是默认优先级。 如何添加a.控制台页面添加 b.队列中代码添加优先级 123Map&lt;String, Object&gt; params = new HashMap();params.put(&quot;x-max-priority&quot;, 10);channel.queueDeclare(&quot;hello&quot;, true, false, false, params); c.消息中代码添加优先级 1AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); d.注意事项 要让队列实现优先级需要做的事情有如下事情:队列需要设置为优先级队列，消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息进行排序 实战生产者1234567891011121314151617181920public class Producer &#123; private static final String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel();) &#123; // 给消息赋予一个 priority 属性 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; if (i == 5) &#123; channel.basicPublish(&quot;&quot;, QUEUE_NAME, properties, message.getBytes()); &#125; else &#123; channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes()); &#125; System.out.println(&quot; 发送消息完成:&quot; + message); &#125; &#125; &#125;&#125; 消费者12345678910111213141516171819public class Consumer &#123; private static final String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 设置队列的最大优先级 最大可以设置到 255 官网推荐 1-10 如果设置太高比较吃内存和 CPU Map&lt;String, Object&gt; params = new HashMap(); params.put(&quot;x-max-priority&quot;, 10); channel.queueDeclare(QUEUE_NAME, true, false, false, params); System.out.println(&quot; 消费者启动等待消费......&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String receivedMessage = new String(delivery.getBody()); System.out.println(&quot; 接收到消息:&quot; + receivedMessage); &#125;; channel.basicConsume(QUEUE_NAME, true, deliverCallback, (consumerTag) -&gt; &#123; System.out.println(&quot; 消费者无法消费 消息时调用，如队列被删除&quot;); &#125;); &#125;&#125; 惰性队列RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因(比如消费者下线、宕机亦或者是由于维护而关闭等)而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中，这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法，但是效果始终不太理想，尤其是在消息量特别大的时候。 两种模式队列具备两种模式：default 和 lazy。默认的为 default 模式，在 3.6.0 之前的版本无需做任何变更。lazy模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。在队列声明的时候可以通过“x-queue-mode”参数来设置队列的模式，取值为“default”和“lazy”。下面示例中演示了一个惰性队列的声明细节： 123Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-queue-mode&quot;, &quot;lazy&quot;);channel.queueDeclare(&quot;myqueue&quot;, false, false, false, args); 内存开销对比 在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅占用 1.5MB RabbitMQ 集群clustering集群模式使用集群的原因最开始我们介绍了如何安装及运行 RabbitMQ 服务，不过这些是单机版的，无法满足目前真实应用的要求。如果 RabbitMQ 服务器遇到内存崩溃、机器掉电或者主板故障等情况，该怎么办？单台 RabbitMQ服务器可以满足每秒 1000 条消息的吞吐量，那么如果应用需要 RabbitMQ 服务满足每秒 10 万条消息的吞吐量呢？购买昂贵的服务器来增强单机 RabbitMQ 务的性能显得捉襟见肘，搭建一个 RabbitMQ 集群才是解决实际问题的关键。 搭建步骤1.修改 3 台机器的主机名称 vim /etc/hostname 2.配置各个节点的 hosts 文件，让各个节点都能互相识别对方 vim /etc/hosts10.211.55.74 node110.211.55.75 node210.211.55.76 node3 3.以确保各个节点的 cookie 文件使用的是同一个值 在 node1 上执行远程操作命令scp /var/lib/rabbitmq/.erlang.cookie root@node2:/var/lib/rabbitmq/.erlang.cookiescp /var/lib/rabbitmq/.erlang.cookie root@node3:/var/lib/rabbitmq/.erlang.cookie 4.启动 RabbitMQ 服务,顺带启动 Erlang 虚拟机和 RbbitMQ 应用服务(在三台节点上分别执行以下命令) rabbitmq-server -detached 5.在节点 2 执行 1234rabbitmqctl stop_app (rabbitmqctl stop 会将 Erlang 虚拟机关闭，rabbitmqctl stop_app 只关闭 RabbitMQ 服务)rabbitmqctl resetrabbitmqctl join_cluster rabbit@node1rabbitmqctl start_app(只启动应用服务) 6.在节点 3 执行 1234rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster rabbit@node2rabbitmqctl start_app 7.集群状态 rabbitmqctl cluster_status 8.需要重新设置用户 创建账号rabbitmqctl add_user admin 123设置用户角色rabbitmqctl set_user_tags admin administrator设置用户权限rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 9.解除集群节点(node2 和 node3 机器分别执行) 12345rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_apprabbitmqctl cluster_statusrabbitmqctl forget_cluster_node rabbit@node2(node1 机器上执行) 镜像队列使用镜像的原因如果 RabbitMQ 集群中只有一个 Broker 节点，那么该节点的失效将导致整体服务的临时性不可用，并且也可能会导致消息的丢失。可以将所有消息都设置为持久化，并且对应队列的durable属性也设置为true，但是这样仍然无法避免由于缓存导致的问题：因为消息在发送之后和被写入磁盘井执行刷盘动作之间存在一个短暂却会产生问题的时间窗。通过 publisherconfirm 机制能够确保客户端知道哪些消息己经存入磁盘，尽管如此，一般不希望遇到因单点故障导致的服务不可用。引入镜像队列(Mirror Queue)的机制，可以将队列镜像到集群中的其他 Broker 节点之上，如果集群中的一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性。 搭建步骤1.启动三台集群节点 2.随便找一个节点添加 policy 3.在 node1 上创建一个队列发送一条消息，队列存在镜像队列 4.停掉 node1 之后发现 node2 成为镜像队列 5.就算整个集群只剩下一台机器了 依然能消费队列里面的消息 说明队列里面的消息被镜像队列传递到相应机器里面了 实现高可用负载均衡整体架构图 Haproxy 实现负载均衡HAProxy 提供高可用性、负载均衡及基于 TCPHTTP 应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案，包括 Twitter,Reddit,StackOverflow,GitHub 在内的多家知名互联网公司在使用。HAProxy 实现了一种事件驱动、单一进程模型，此模型支持非常大的井发连接数。 扩展 nginx,lvs,haproxy 之间的区别: http://www.ha97.com/5646.html Keepalived实现双机试想如果前面配置的 HAProxy 主机突然宕机或者网卡失效，那么虽然 RbbitMQ 集群没有任何故障但是对于外界的客户端来说所有的连接都会被断开结果将是灾难性的为了确保负载均衡服务的可靠性同样显得十分重要，这里就要引入 Keepalived 它能够通过自身健康检查、资源接管功能做高可用(双机热备)，实现故障转移。 Federation Exchange​ (broker 北京)，(broker 深圳)彼此之间相距甚远，网络延迟是一个不得不面对的问题。有一个在北京的业务(Client 北京) 需要连接(broker 北京)，向其中的交换器 exchangeA 发送消息，此时的网络延迟很小，(Client 北京)可以迅速将消息发送至 exchangeA 中，就算在开启了 publisherconfirm 机制或者事务机制的情况下，也可以迅速收到确认信息。此时又有个在深圳的业务(Client 深圳)需要向 exchangeA 发送消息，那么(Client 深圳) (broker 北京)之间有很大的网络延迟，(Client 深圳) 将发送消息至 exchangeA 会经历一定的延迟，尤其是在开启了 publisherconfirm 机制或者事务机制的情况下，(Client 深圳) 会等待很长的延迟时间来接收(broker 北京)的确认信息，进而必然造成这条发送线程的性能降低，甚至造成一定程度上的阻塞。​ 将业务(Client 深圳)部署到北京的机房可以解决这个问题，但是如果(Client 深圳)调用的另些服务都部署在深圳，那么又会引发新的时延问题，总不见得将所有业务全部部署在一个机房，那么容灾又何以实现？这里使用 Federation 插件就可以很好地解决这个问题. 搭建步骤1.需要保证每台节点单独运行 2.在每台机器上开启 federation 相关插件 12rabbitmq-plugins enable rabbitmq_federationrabbitmq-plugins enable rabbitmq_federation_management 3.原理图(先运行 consumer 在 node2 创建 fed_exchange) 4.在 downstream(node2)配置 upstream(node1) 5.添加 policy 6.成功的前提 Federation Queue联邦队列可以在多个 Broker 节点(或者集群)之间为单个队列提供均衡负载的功能。一个联邦队列可以连接一个或者多个上游队列(upstream queue)，并从这些上游队列中获取消息以满足本地消费者消费消息的需求。 搭建步骤1.原理图 2.添加 upstream(同上) 3.添加 policy ShovelFederation 具备的数据转发功能类似，Shovel 够可靠、持续地从一个 Broker 中的队列(作为源端，即source)拉取数据并转发至另一个 Broker 中的交换器(作为目的端，即 destination)。作为源端的队列和作为目的端的交换器可以同时位于同一个 Broker，也可以位于不同的 Broker 上。Shovel 可以翻译为”铲子”，是一种比较形象的比喻，这个”铲子”可以将消息从一方”铲子”另一方。Shovel 行为就像优秀的客户端应用程序能够负责连接源和目的地、负责消息的读写及负责连接失败问题的处理。 搭建步骤1.开启插件(需要的机器都开启) 12rabbitmq-plugins enable rabbitmq_shovelrabbitmq-plugins enable rabbitmq_shovel_management 2.原理图在源头发送的消息直接回进入到目的地队列 3.添加 shovel 源和目的地 RabbitMQ工具类在企业开发过程中，直接使用SpringBoot提供的RabbitTemplate还是略显复杂，通常我们一个系统发送消息基本上也是只依赖于一个交换机和一个队列（延迟消息需单独依赖于延迟交换机），基于此，我们可以把交换机、队列以及路由key等声明直接放在配置文件中，然后封装发送普通消息的工具类，和发送延迟消息的工具类，发送的消息体内容我们可以增加交易码这个概念，消费者通过不同交易码，处理不同的业务。消息体通过泛型，在发消息时声明消息体类型，通过json序列化传输。 工具类使用延迟消息发送项目启动时，直接声明好延迟交换机，延迟队列以及路由key，发送延迟消息只需要一句代码 12345public void sendDelayMsg(@PathVariable String message, @PathVariable Integer delayTime) &#123; log.info(&quot;当前时间：&#123;&#125;,发送一条时长&#123;&#125;毫秒TTL信息给队列QC:&#123;&#125;&quot;, new Date(), delayTime, message); MsgData&lt;String&gt; msgData = new MsgData&lt;&gt;(&quot;0001&quot;, message, &quot;这是我的测试延迟消息！&quot;); EventDispatcherUtil.eventDispatch(msgData, delayTime);&#125; 普通消息发送普通消息通过发布订阅模式实现，其他系统若要接收次消息，只需要声明一个队列然后添加监听，绑定到此交换机上即可，发送普通消息也只需要一句代码实现 12345public void sendFanoutMsg(@PathVariable String message) &#123; log.info(&quot;当前时间：&#123;&#125;,发送一条信息给队列QC:&#123;&#125;&quot;, new Date(), message); MsgData&lt;String&gt; msgData = new MsgData&lt;&gt;(&quot;0001&quot;, message, &quot;这是我的测订阅消息！&quot;); EventDispatcherUtil.eventDispatch(msgData);&#125; RabbitMQ相关面试题如何保证消息不丢失？ 队列和消息持久化：保证MQ宕机了消息不丢失，必须保证在磁盘上才能（3.4.2、3.4.3） 消息发布确认：开启消息发布确认，MQ将消息发送到交换机并且保存在磁盘上之后返回一个确认，此时可以保证生产者发送的消息绝对不丢失。见：9.1 消息回退处理：当消息到达交换机无法路由到队列时，交换机把消息回退给生产者，也可以通过备份交换机实现。见：9.2 消息应答机制：设置为手动应答，保证消费者正确处理完消息，如果处理失败，消息重新入队 集群环境下，添加镜像队列。见：11.2 消息的类型主要是交换机的类型，包括： 直接(direct)：路由类型 主题(topic) 标题(headers) ：已经不用了 扇出(fanout)：发布订阅类型","categories":[{"name":"中间件","slug":"中间件","permalink":"https://zhangyong3214.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"}]}],"categories":[{"name":"算法刷题","slug":"算法刷题","permalink":"https://zhangyong3214.github.io/categories/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98/"},{"name":"软件分享","slug":"软件分享","permalink":"https://zhangyong3214.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/"},{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"笔记","slug":"笔记","permalink":"https://zhangyong3214.github.io/categories/%E7%AC%94%E8%AE%B0/"},{"name":"面试知识","slug":"面试知识","permalink":"https://zhangyong3214.github.io/categories/%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86/"},{"name":"基础知识","slug":"基础知识","permalink":"https://zhangyong3214.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"框架","slug":"框架","permalink":"https://zhangyong3214.github.io/categories/%E6%A1%86%E6%9E%B6/"},{"name":"中间件","slug":"中间件","permalink":"https://zhangyong3214.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://zhangyong3214.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"},{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"},{"name":"开发","slug":"开发","permalink":"https://zhangyong3214.github.io/tags/%E5%BC%80%E5%8F%91/"}]}