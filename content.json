{"meta":{"title":"李苟蛋の家","subtitle":"热爱生活，喜欢软件","description":"欢迎来到苟蛋博客の家","author":"李苟蛋","url":"https://zhangyong3214.github.io","root":"/"},"pages":[{"title":"留言板","date":"2022-01-27T08:31:13.242Z","updated":"2022-01-27T08:31:13.242Z","comments":true,"path":"message/index.html","permalink":"https://zhangyong3214.github.io/message/index.html","excerpt":"","text":"本页面还在开发中……"},{"title":"","date":"2022-01-27T08:31:13.242Z","updated":"2022-01-27T08:31:13.242Z","comments":true,"path":"js/chocolate.js","permalink":"https://zhangyong3214.github.io/js/chocolate.js","excerpt":"","text":"/* * @Author: tzy1997 * @Date: 2020-12-15 20:55:25 * @LastEditors: tzy1997 * @LastEditTime: 2021-01-12 19:02:25 */ // 友情链接页面 头像找不到时 替换图片 if (location.href.indexOf(\"link\") !== -1) { var imgObj = document.getElementsByTagName(\"img\"); for (i = 0; i < imgObj.length; i++) { imgObj[i].onerror = function() { this.src = \"https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/theme_f/friend_404.gif\" } } } $(function() { // 气泡 function bubble() { $('#page-header').circleMagic({ radius: 10, density: .2, color: 'rgba(255,255,255,.4)', clearOffset: 0.99 }); }! function(p) { p.fn.circleMagic = function(t) { var o, a, n, r, e = !0, i = [], d = p.extend({ color: \"rgba(255,0,0,.5)\", radius: 10, density: .3, clearOffset: .2 }, t), l = this[0]; function c() { e = !(document.body.scrollTop > a) } function s() { o = l.clientWidth, a = l.clientHeight, l.height = a + \"px\", n.width = o, n.height = a } function h() { if (e) for (var t in r.clearRect(0, 0, o, a), i) i[t].draw(); requestAnimationFrame(h) } function f() { var t = this; function e() { t.pos.x = Math.random() * o, t.pos.y = a + 100 * Math.random(), t.alpha = .1 + Math.random() * d.clearOffset, t.scale = .1 + .3 * Math.random(), t.speed = Math.random(), \"random\" === d.color ? t.color = \"rgba(\" + Math.floor(255 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.random().toPrecision(2) + \")\" : t.color = d.color } t.pos = {}, e(), this.draw = function() { t.alpha"},{"title":"标签","date":"2022-01-27T08:31:13.242Z","updated":"2022-01-27T08:31:13.242Z","comments":true,"path":"tags/index.html","permalink":"https://zhangyong3214.github.io/tags/index.html","excerpt":"","text":""},{"title":"技术笔记","date":"2022-01-27T08:31:13.243Z","updated":"2022-01-27T08:31:13.243Z","comments":true,"path":"技术笔记/index.html","permalink":"https://zhangyong3214.github.io/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/index.html","excerpt":"","text":"我是技术笔记"},{"title":"关于我","date":"2022-01-27T08:31:13.242Z","updated":"2022-01-27T08:31:13.242Z","comments":true,"path":"关于我/index.html","permalink":"https://zhangyong3214.github.io/%E5%85%B3%E4%BA%8E%E6%88%91/index.html","excerpt":"","text":"关于我十年生死两茫茫,写程序，到天亮。千行代码，Bug何处藏。纵使上线又怎样，朝令改，夕断肠。领导每天新想法，天天改，日日忙。 相顾无言，惟有泪千行。每晚灯火阑珊处，程序员，又加班，工作狂~ 来一张楼主无美颜生活照，见笑了！🤣🤣🤣 基本信息 类别 信息 出生年月 1990年2月 现居地 北京市朝阳区 籍贯 辽宁省锦州市 邮箱 &#x38;&#51;&#x34;&#x36;&#x31;&#51;&#x32;&#64;&#113;&#x71;&#x2e;&#x63;&#111;&#x6d; 教育经历 时间 学校 专业 备注 2009.09~2013.07 沈阳化工大学 电子科学与技术 统招本科 2006.09~2009.07 辽宁省北镇市高级中学 高级基础教育 市重点 工作经历 时间 公司 职位 2021.04~至今 龙湖集团 Java 开发工程师 2017.05~2021.04 包头市包银消费金融股份有限公司 Java 开发工程师 2016.09~2017.04 大连灵动科技发展有限公司 Java 开发工程师 2013.07~2016.08 大连安吉尼尔科技有限公司 Java 开发工程师 专业技能 Java 基础扎实、掌握 JVM 原理、多线程、网络原理、设计模式、常用的数据结构和算法 熟悉 Windows、Mac、Linux 操作系统，熟练使用 linux 常用操作指令 熟练使用 IntelliJ IDEA 开发工具(及各种插件)、熟练使用 Git 版本同步工具 阅读过 Spring、SpringMVC、等开源框架源码，理解其设计原理及底层架构，具备框架定制开发能力 理解 Redis 线程模型，Netty 线程模型，掌握基于响应式的异步非阻塞模型的基本原理，了解 Webflux 熟练掌握分布式缓存 Redis、Elaticsearch，对分布式锁，幂等等常见问题有深入研究及多年实战经验 熟悉常见消息中间件的使用，有多年 RabbitMQ 的实战开发经验，对高级消息队列有深入理解 熟练掌握 Mysql 事务，索引，锁，SQL 优化相关知识，可根据业务场景给出详细及高性能设计方案 熟练使用数据库操作框架 Mybatis、Mybatsi-plus 进行高效业务功能开发 掌握 springCloud 相关框架，对 SpringBoot、SpringCloud 原理有一定了解，有成熟项目经验 熟悉定时任务及延迟任务等业务相关设计，如 xxl-job，延迟消息等相关技术有多年开发经验 熟悉微服务思想，MVC 分层，DDD 理论，服务拆分，治理，监控，服务熔断，降级等相关能力 熟悉 jvm 原理，熟悉垃圾回收以 jvm 性能调优技术，有过线上服务器性能监测及调优经验 熟悉多线程及线程池使用，有多年多线程业务处理经验，封装过多线程批处理工具类等公用组建 了解 Mysql 分库分表相关原理，如 Sardingsphere、Mycat 等框架有相关使用经验 了解操作系统底层原理以及 C、C++程序开发，对计算机底层原理有初步了解 了解前端开发，了解 html，css，js，vue 等前端技术，对前端开发有一定的了解 研究过单片机等硬件开发，喜欢科技产品，喜欢软件，喜欢折腾各种电子产品以及软件 项目经验​ 项目经验只写了在北京之后参与过的相关项目，在大连做的项目偏向于传统，项目也都是单点部署，主要用的框架都是spring、mybatis、Hibernate、springMVC等相互结合使用，即：SSM，SSH，相比于springBoot来说不值一提，现在应该没有几个公司还没用springBoot了吧(#^.^#)，值得一提的是，刚毕业那会，做了半年的C语言嵌入式开发，外包到大连东软做对日的佳能相机系统，虽然目前我已经做了多年的java开发，但是那毕竟是我第一次参加开发项目，人都是有初恋情节的嘛，对自己的第一次念念不忘(我指得是工作🤭)，那半年让我对硬件底层有了一些理解，也算是最大的收获了吧。 —— 包银消费金融(现名：蒙商消费) ——​ 包头市包银消费金融股份有限公司是经中国银监会批准成立的持牌消费金融公司，由包商银行发起设立，包银消费金融为个人消费者提供消费信贷服务。其主要合作渠道有：证大财富，京东金条，微粒贷，去哪儿，京东借贷平台，分期乐，小米等多家放款渠道。目前，已累计完成 1200 多万客户注册和 320 多亿放款规模。 acs：核心交易系统主要包含信贷核算业务和虚拟账户业务，信贷核算主要负责借还款、核销减免交易、利息、罚息计提、各种费用等业务的计算和落地，日终生成交易流水文件供会计核算系统生成会计分录；虚拟账户部分主要为清结算人员提供交易产生的不同资金账户金额的变化及资金流向，为清结算人员对账提供数据支持；系统可以处理每分钟峰值 640 多笔授信申请，每小时峰值 2 万笔授信申请，贷后支持每小时 17 万客户数据。核心日终处理量达 152 万笔(借据数量)。 gls：财务核算系统对核心交易系统日终生成的交易流水解析之后按照分录借贷规则生成财务分录文件交给金蝶系统，17 年财务核算系统是买来的系统，19 年由我重新开发出属于公司自己的财务核算系统，并增加了财务对账功能(核心交易系统和财务分录对账)，不但及时发现线上交易的错误数据，及时解决问题，更提升了月终对账，年结的效率，实现了财务对账自动化，解决了年结人工对账的痛点。 ecif：渠道系统要负责对接第三方引流渠道，客户通过第三方渠道授信、借款，渠道引流到包银，由于不同渠道的授信、放款业务逻辑不同，针对不同渠道提供不同的功能开发。其中部分渠道积累一天客户授信请求指定时间统一发送授信申请到包银，系统可处理每分钟 800 笔授信请求。 css：清结算系统此系统是公司内部清结算人员使用的内部业务系统，主要功能有个人溢缴款账户管理、对公付款、对私付款、退款以及清结算同事转账业务的发起和审核功能 联合贷款系统主要功能有联合贷款协议，路由配置，路由规则，借据还款计划拆分，资方授信，借据、交易流水文件，联合贷款授信影音资料推送 监管报送系统按照监管报送需求，对借据(每月报送全量数据)，还款计划，还款流水，客户，产品，核销，借款申请，资产证券化，五级分类等信息进行加工之后推送给监管报送系统 自我评价业精于勤，荒于嬉 、行成于思，毁于随。 性格乐观开朗，话痨，热爱生活，喜欢拍视频记录生活，喜欢分享知识，分享技术，分享生活中的点点滴滴，脾气好，怕老婆 个人爱好 电子科技产品 软件 —— 喜欢win、Mac、Android 好用无广告软件研究及分享 足球 —— 喜欢但是没机会玩，怀念高中时代呀…. 三国杀 —— 基本已经被凉企逼到退游了….而且生活中也很难找到一起玩这个游戏的朋友了🤣 逛B站 —— 生活区和科技区一个不知名阿婆主😂，佛系更新视频 👉 点击打开我的B站个人空间 记得三连 👍👍👍 看电影 —— 喜欢科幻、漫威粉、追斗罗大陆….."},{"title":"","date":"2022-01-27T08:31:13.129Z","updated":"2022-01-27T08:31:13.129Z","comments":true,"path":"css/custom.css","permalink":"https://zhangyong3214.github.io/css/custom.css","excerpt":"","text":"/* 文章页H1-H6图标样式效果 */ h1::before, h2::before, h3::before, h4::before, h5::before, h6::before { -webkit-animation: ccc 1.6s linear infinite ; animation: ccc 1.6s linear infinite ; } @-webkit-keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } @keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } #content-inner.layout h1::before { color: #ef50a8 ; margin-left: -1.55rem; font-size: 1.3rem; margin-top: -0.23rem; } #content-inner.layout h2::before { color: #fb7061 ; margin-left: -1.35rem; font-size: 1.1rem; margin-top: -0.12rem; } #content-inner.layout h3::before { color: #ffbf00 ; margin-left: -1.22rem; font-size: 0.95rem; margin-top: -0.09rem; } #content-inner.layout h4::before { color: #a9e000 ; margin-left: -1.05rem; font-size: 0.8rem; margin-top: -0.09rem; } #content-inner.layout h5::before { color: #57c850 ; margin-left: -0.9rem; font-size: 0.7rem; margin-top: 0.0rem; } #content-inner.layout h6::before { color: #5ec1e0 ; margin-left: -0.9rem; font-size: 0.66rem; margin-top: 0.0rem; } #content-inner.layout h1:hover, #content-inner.layout h2:hover, #content-inner.layout h3:hover, #content-inner.layout h4:hover, #content-inner.layout h5:hover, #content-inner.layout h6:hover { color: #49b1f5 ; } #content-inner.layout h1:hover::before, #content-inner.layout h2:hover::before, #content-inner.layout h3:hover::before, #content-inner.layout h4:hover::before, #content-inner.layout h5:hover::before, #content-inner.layout h6:hover::before { color: #49b1f5 ; -webkit-animation: ccc 3.2s linear infinite ; animation: ccc 3.2s linear infinite ; } /* 页面设置icon转动速度调整 */ #rightside_config i.fas.fa-cog.fa-spin { animation: fa-spin 5s linear infinite ; } /*--------更换字体------------*/ @font-face { font-family: 'tzy'; /* 字体名自定义即可 */ src: url('https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/font/ZhuZiAWan.woff2'); /* 字体文件路径 */ font-display: swap; } body, .gitcalendar { font-family: tzy !important; } .categoryBar-list { max-height: 400px; } .clock-row { overflow: hidden; text-overflow: ellipsis; } /*3s为加载动画的时间，1为加载动画的次数，ease-in-out为动画效果*/ #page-header, #web_bg { -webkit-animation: imgblur 2s 1 ease-in-out; animation: imgblur 2s 1 ease-in-out; } @keyframes imgblur { 0% { filter: blur(5px); } 100% { filter: blur(0px); } } /*适配使用-webkit内核的浏览器 */ @-webkit-keyframes imgblur { 0% { -webkit-filter: blur(5px); } 100% { -webkit-filter: blur(0px); } } .table-wrap img { margin: .6rem auto .1rem !important; } /* 标签外挂 网站卡片 start */ .site-card-group img { margin: 0 auto .1rem !important; } .site-card-group .info a img { margin-right: 10px !important; } [data-theme='dark'] .site-card-group .site-card .info .title { color: #f0f0f0 !important; } [data-theme='dark'] .site-card-group .site-card .info .desc { color: rgba(255, 255, 255, .7) !important; } .site-card-group .info .desc { margin-top: 4px !important; } /* 代码块颜色 */ figure.highlight pre .addition { color: #00bf03 !important; }"},{"title":"分类","date":"2022-01-27T08:31:13.129Z","updated":"2022-01-27T08:31:13.129Z","comments":true,"path":"categories/index.html","permalink":"https://zhangyong3214.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"数据结构和算法","slug":"面试基地/数据结构和算法","date":"2022-01-27T08:31:13.129Z","updated":"2022-01-27T08:31:13.129Z","comments":true,"path":"2022/01/27/面试基地/数据结构和算法/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E9%9D%A2%E8%AF%95%E5%9F%BA%E5%9C%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/","excerpt":"","text":"排序算法高效交换算法(异或^)概念 0^N = N ; N^N = 0 相同为0，不同为1，也可以叫做无进位相加，这么做的前提：需要交换的两个数指向的内存是两位位置 异或运算满足交换律和结合律 不用额外变量交换两个数 123456// 交换arr的i和j位置上的值public static void swap(int[] arr, int i, int j) &#123; arr[i] = arr[i] ^ arr[j]; arr[j] = arr[i] ^ arr[j]; arr[i] = arr[i] ^ arr[j];&#125; 一种数出现奇数次一个数组中有一个数出现奇数次，其他数都出现偶数次，怎么找到这一个数？ 1234567public static void printOddTimesNum1(int[] arr) &#123; int eor = 0; for (int i = 0; i &lt; arr.length; i++) &#123; eor ^= arr[i]; &#125; System.out.println(eor);&#125; 两种数出现奇数次一个数组中有两个数出现奇数次，其他数都出现了偶数次，怎么找到这两个数？ 123456789101112131415161718192021public static void printOddTimesNum2(int[] arr) &#123; int eor = 0; for (int i = 0; i &lt; arr.length; i++) &#123; eor ^= arr[i]; &#125; // a 和 b是两种数 // eor != 0 // eor最右侧的1，提取出来 // eor : 00110010110111000 // rightOne :00000000000001000 int rightOne = eor &amp; (-eor); // 提取出最右的1 int onlyOne = 0; // eor&#x27; for (int i = 0 ; i &lt; arr.length;i++) &#123; // arr[1] = 111100011110000 // rightOne= 000000000010000 if ((arr[i] &amp; rightOne) != 0) &#123; onlyOne ^= arr[i]; &#125; &#125; System.out.println(onlyOne + &quot; &quot; + (eor ^ onlyOne));&#125; 冒泡排序 基本冒泡排序算法 123456789101112131415public static void bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; // 0 ~ N-1 // 0 ~ N-2 // 0 ~ N-3 for (int e = arr.length - 1; e &gt; 0; e--) &#123; // 0 ~ e for (int i = 0; i &lt; e; i++) &#123; if (arr[i] &gt; arr[i + 1]) &#123; swap(arr, i, i + 1); &#125; &#125; &#125; &#125; 冒泡排序算法优化 在一趟排序过程中如果一次都没有交换过，那说明后续的数都是有序的，不需要在进行后续的排序了，如果元素本来就是有序的，就只比较一次就结束了。 12345678910111213141516171819202122232425public static void bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; // 标识变量，表示是否进行过交换 boolean flag = false; for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; // 如果前面的数比后面的数大，则交换 if (arr[j] &gt; arr[j + 1]) &#123; flag = true; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; // 在一趟排序中，一次交换都没有发生过 if (!flag) &#123; break; &#125; else &#123; // 重置flag!!!, 进行下次判断 flag = false; &#125; &#125;&#125; 选择排序 0 ~ N-1 找到最小值，在哪，放到0位置上 1 ~ n-1 找到最小值，在哪，放到1 位置上 2 ~ n-1 找到最小值，在哪，放到2 位置上 123456789101112public static void selectionSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; for (int i = 0; i &lt; arr.length - 1; i++) &#123; int minIndex = i; for (int j = i + 1; j &lt; arr.length; j++) &#123; // i ~ N-1 上找最小值的下标 minIndex = arr[j] &lt; arr[minIndex] ? j : minIndex; &#125; swap(arr, i, minIndex); &#125;&#125; 插入排序 0~1单范围有序 0~2范围有序 0~3范围有序 0~N范围有序 1234567891011public static void insertionSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; // 不只1个数 for (int i = 1; i &lt; arr.length; i++) &#123; // 0 ~ i 做到有序 for (int j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; arr[j + 1]; j--) &#123; swap(arr, j, j + 1); &#125; &#125;&#125; 查找算法二分查找二分法的详解与扩展 在一个有序数组中，查找某个数是否存在 在一个有序数组中，找&gt;=某个数最左侧的位置 局部最小值问题 1234567891011121314151617181920public static boolean exist(int[] sortedArr, int num) &#123; if (sortedArr == null || sortedArr.length == 0) &#123; return false; &#125; int L = 0; int R = sortedArr.length - 1; int mid = 0; // L..R while (L &lt; R) &#123; // L..R 至少两个数的时候 mid = L + ((R - L) &gt;&gt; 1); if (sortedArr[mid] == num) &#123; return true; &#125; else if (sortedArr[mid] &gt; num) &#123; R = mid - 1; &#125; else &#123; L = mid + 1; &#125; &#125; return sortedArr[L] == num;&#125; 数组范围上求最大值递归解法 123456789101112public static int process(int[] arr, int L, int R) &#123; // arr[L..R]范围上只有一个数，直接返回，base case if (L == R) &#123; return arr[L]; &#125; // L...R 不只一个数 // mid = (L + R) / 2 int mid = L + ((R - L) &gt;&gt; 1); // 中点 int leftMax = process(arr, L, mid); int rightMax = process(arr, mid + 1, R); return Math.max(leftMax, rightMax);&#125; 对数器的概念 有一个你想要测试的方法a 实现复杂度不好但是容易实现的方法b 实现一个随机样本产生器 把方法a和方法b跑相同的随机样本，看看得到的结果是否一样 如果有一个随机样本时的比对结果不一致，打印样本进行人工干预，改对方法a或者方法b 当样本数量很多时比对测试依然正确，可以确定方法a已经正确 数组ab数组合并到a 题目：给出两个有序的整数数组A和B，请将数组B合并到数组A中，变成一个有序的数组。注意：可以假设A数组有足够的空间存放B数组的元素，A和B中初始的元素数目分别为m和n。 题解：最优解：从后往前处理,不需要开辟额外空间。从后往前，这样不需要进行冗余处理。 12345678910111213141516171819202122/** * @param a 数组a，有足够的空间合并数组b * @param m 数组a里面的元素个数 * @param b 数组b * @param n 数组b里面的元素个数 */public static void merge(int[] a, int m, int[] b, int n) &#123; int i = m - 1; int j = n - 1; int index = m + n - 1; while (i &gt;= 0 &amp;&amp; j &gt;= 0) &#123; if(a[i] &gt; b[j] )&#123; a[index--] = a[i--]; &#125; else &#123; a[index--] = b[j--]; &#125; &#125; //如果A的数字比B多，则不会进入后续处理；如果B的数字比A多，则进入后续处理，将B剩余数字添加到数组A中。 while (j &gt;= 0) &#123; a[index--] = b[j--]; &#125;&#125; ab数组合并到c 题目： 合并两个有序整型数据（入参两个需要合并的数组，返回值合并好的新数组） 123456789101112131415161718192021222324252627private static int[] margeArr(int[] a, int[] b) &#123; int[] c = new int[a.length + b.length]; int i = 0, j = 0; int index = 0; //比较指针i,j指向的值，小的值存入指针index指向的结果数组中，当有一个指针（i或j）先到达数组末尾时，比较结束； while (i &lt; a.length &amp;&amp; j &lt; b.length) &#123; if (a[i] &lt; b[j]) &#123; c[index++] = a[i++]; &#125; else &#123; c[index++] = b[j++]; &#125; &#125; int l; //将指针（i或j）没有到达数组末尾的数组复制到指针index指向的结果数组中 if (i &lt; a.length) &#123; for (l = i; l &lt; a.length; l++) &#123; c[index++] = a[l]; &#125; &#125; //将指针（i或j）没有到达数组末尾的数组复制到指针index指向的结果数组中 if (j &lt; b.length) &#123; for (l = j; l &lt; b.length; l++) &#123; c[index++] = b[l]; &#125; &#125; return c;&#125; 查找两数之和等于目标数 题目：给定一个数组和一个目标数，从数组中找到两个数，是这两个数之和等于目标数。返回其在数组中的编号 12345678910public static int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; if (map.containsKey(target - nums[i])) &#123; return new int[]&#123;map.get(target - nums[i]), i&#125;; &#125; map.put(nums[i], i); &#125; return null;&#125; 螺旋打印二维数组1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public static void printEdge(int[][] m, int tR, int tC, int dR, int dC) &#123; if (tR == dR) &#123; for (int i = tC; i &lt;= dC; i++) &#123; System.out.print(m[tR][i] + &quot; &quot;); &#125; &#125; else if (tC == dC) &#123; for (int i = tR; i &lt;= dR; i++) &#123; System.out.print(m[i][tC] + &quot; &quot;); &#125; &#125; else &#123; int curC = tC; int curR = tR; while (curC != dC) &#123; System.out.print(m[tR][curC] + &quot; &quot;); curC++; &#125; while (curR != dR) &#123; System.out.print(m[curR][dC] + &quot; &quot;); curR++; &#125; while (curC != tC) &#123; System.out.print(m[dR][curC] + &quot; &quot;); curC--; &#125; while (curR != tR) &#123; System.out.print(m[curR][tC] + &quot; &quot;); curR--; &#125; &#125;&#125;public static void spiralOrderPrint(int[][] matrix) &#123; int tR = 0; int tC = 0; int dR = matrix.length - 1; int dC = matrix[0].length - 1; while (tR &lt;= dR &amp;&amp; tC &lt;= dC) &#123; printEdge(matrix, tR++, tC++, dR--, dC--); &#125;&#125;public static void main(String[] args) &#123; int[][] matrix = &#123; &#123; 1, 2, 3, 4 &#125;, &#123; 5, 6, 7, 8 &#125;, &#123; 9, 10, 11, 12 &#125;, &#123; 13, 14, 15, 16 &#125; &#125;; spiralOrderPrint(matrix);&#125; 链表 对于笔试，不用太在乎空间复杂度，一切为了时间复杂度 对于面试，时间复杂度依然放在第一位，但是一定要找到空间最省的方法 重要技巧 额外数据结构记录（哈希表等） 快慢指针 链表反转单向链表反转123456789// 单向链表节点public static class Node &#123; public int value; public Node next; public Node(int data) &#123; value = data; &#125;&#125; 1234567891011121314// head 单向链表反转算法// a -&gt; b -&gt; c -&gt; null// c -&gt; b -&gt; a -&gt; nullpublic static Node reverseLinkedList(Node head) &#123; Node pre = null; Node next = null; while (head != null) &#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre;&#125; 123456789101112/** * 递归反转方式 */private Node reverseLinkedList(Node head) &#123; if (head == null || head.next == null) &#123; return head; &#125; Node newHead = reverseLinkedList(head.next); head.next.next = head; head.next = null; return newHead;&#125; 双向链表反转12345678910// 双向链表节点public static class DoubleNode &#123; public int value; public DoubleNode last; public DoubleNode next; public DoubleNode(int data) &#123; value = data; &#125;&#125; 12345678910111213// 双向链表反转算法public static DoubleNode reverseDoubleList(DoubleNode head) &#123; DoubleNode pre = null; DoubleNode next = null; while (head != null) &#123; next = head.next; head.next = pre; head.last = next; pre = head; head = next; &#125; return pre;&#125; 查找链表中点快慢指针应用 查找链表中点或中点上一个1234567891011121314// head 头 解：查找链表中点或者中点前一个节点public static Node midOrUpMidNode(Node head) &#123; if (head == null || head.next == null || head.next.next == null) &#123; return head; &#125; // 链表有3个点或以上 Node slow = head.next; Node fast = head.next.next; while (fast.next != null &amp;&amp; fast.next.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; return slow;&#125; 查找链表中点或中点下一个12345678910111213// 查找链表中点或者中点下一个节点public static Node midOrDownMidNode(Node head) &#123; if (head == null || head.next == null) &#123; return head; &#125; Node slow = head.next; Node fast = head.next; while (fast.next != null &amp;&amp; fast.next.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; return slow;&#125; 判断一个链表是否是回文结构【题目】给定一个单向链表的头节点head，请判断该链表是否为回文结构。【例子】1-&gt;2-&gt;1,返回true;1-&gt;2-&gt;2-&gt;1,返回true；15-&gt;6-&gt;15，返回true；1-&gt;2-&gt;3，返回false。如果链表长度为N，时间复杂度达到O(N)，额外空间复杂度达到O(1)。 解题思路1： 1：遍历链表，把每个元素放到栈里面；2：从栈里面依次弹出元素和原来链表挨个元素比对。 解题思路2： 1：通过快慢指针找到中点和结束点，只把右侧部分放到栈里面去；2：从栈里面依次弹出元素和原来链表挨个元素比对。 12345678910111213141516// 1：遍历链表，把每个元素放到栈里面；2：从栈里面依次弹出元素和原来链表挨个元素比对public static boolean isPalindrome1(Node head) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); Node cur = head; while (cur != null) &#123; stack.push(cur); cur = cur.next; &#125; while (head != null) &#123; if (head.value != stack.pop().value) &#123; return false; &#125; head = head.next; &#125; return true;&#125; 123456789101112131415161718192021222324// 1：通过快慢指针找到中点和结束点，只把右侧部分放到栈里面去；2：从栈里面依次弹出元素和原来链表挨个元素比对public static boolean isPalindrome2(Node head) &#123; if (head == null || head.next == null) &#123; return true; &#125; Node right = head.next; Node cur = head; while (cur.next != null &amp;&amp; cur.next.next != null) &#123; right = right.next; cur = cur.next.next; &#125; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); while (right != null) &#123; stack.push(right); right = right.next; &#125; while (!stack.isEmpty()) &#123; if (head.value != stack.pop().value) &#123; return false; &#125; head = head.next; &#125; return true;&#125; 链表排序单向链表分左中右【题目】 将单向链表按照某值划分成左边小，中间相等，右边大的形式：给定一个单链表头节点head，节点的值类型是整型，再给定一个整数pivot。实现一个调整链表的函数，将链表调整为做部分都是值小于pivot的节点，中间部分都是值等于piovt的节点，有部分都是值大于piovt的节点。【进阶】在实现原问题功能的基础上增加要求：小于，等于，大于pivot节点之间顺序和之前一样，时间复杂度O(N)，额外空间复杂度O(1)。 解题思路1： 将链表放入数组，排序，再转成链表 解题思路2： 左中右分别准备两个指针(共6个变量)，然后遍历原链表，排序之后分别插入相应位置(考虑边界问题) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 将链表放入数组，排序，再转成链表public static Node listPartition1(Node head, int pivot) &#123; if (head == null) &#123; return head; &#125; Node cur = head; int i = 0; while (cur != null) &#123; i++; cur = cur.next; &#125; Node[] nodeArr = new Node[i]; i = 0; cur = head; for (i = 0; i != nodeArr.length; i++) &#123; nodeArr[i] = cur; cur = cur.next; &#125; arrPartition(nodeArr, pivot); for (i = 1; i != nodeArr.length; i++) &#123; nodeArr[i - 1].next = nodeArr[i]; &#125; nodeArr[i - 1].next = null; return nodeArr[0];&#125;public static void arrPartition(Node[] nodeArr, int pivot) &#123; int small = -1; int big = nodeArr.length; int index = 0; while (index != big) &#123; if (nodeArr[index].value &lt; pivot) &#123; swap(nodeArr, ++small, index++); &#125; else if (nodeArr[index].value == pivot) &#123; index++; &#125; else &#123; swap(nodeArr, --big, index); &#125; &#125;&#125;public static void swap(Node[] nodeArr, int a, int b) &#123; Node tmp = nodeArr[a]; nodeArr[a] = nodeArr[b]; nodeArr[b] = tmp;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 左中右分别准备两个指针(共6个变量)，然后遍历原链表，排序之后分别插入相应位置(考虑边界问题)public static Node listPartition2(Node head, int pivot) &#123; Node sH = null; // small head Node sT = null; // small tail Node eH = null; // equal head Node eT = null; // equal tail Node mH = null; // big head Node mT = null; // big tail Node next = null; // save next node // every node distributed to three lists while (head != null) &#123; next = head.next; head.next = null; if (head.value &lt; pivot) &#123; if (sH == null) &#123; sH = head; sT = head; &#125; else &#123; sT.next = head; sT = head; &#125; &#125; else if (head.value == pivot) &#123; if (eH == null) &#123; eH = head; eT = head; &#125; else &#123; eT.next = head; eT = head; &#125; &#125; else &#123; if (mH == null) &#123; mH = head; mT = head; &#125; else &#123; mT.next = head; mT = head; &#125; &#125; head = next; &#125; // 小于区域的尾巴，连等于区域的头，等于区域的尾巴连大于区域的头 if (sT != null) &#123; // 如果有小于区域 sT.next = eH; eT = eT == null ? sT : eT; // 下一步，谁去连大于区域的头，谁就变成eT &#125; // 下一步，一定是需要用eT 去接 大于区域的头 // 有等于区域，eT -&gt; 等于区域的尾结点 // 无等于区域，eT -&gt; 小于区域的尾结点 // eT 尽量不为空的尾巴节点 if (eT != null) &#123; // 如果小于区域和等于区域，不是都没有 eT.next = mH; &#125; return sH != null ? sH : (eH != null ? eH : mH);&#125; 链表闭环及相交问题单链表查找闭环位置注：单链表闭环只能有一个环，如果产生环，必然会出现闭环 解法1：额外空间解决 申请一个set集合，从头节点遍历链表，每遍历一个元素就查询该节点是否在集合中，如果没有就把该节点放进去，如果有，该节点就是环位置 1.... 解法2：有限几个变量解决 快慢指针从单链表头节点开始走，直至两个节点相遇，说明有环，最后指向null，说明无环 相遇之后快指针回到头节点，之后一次走一步，慢指针停在原地，再次相遇的位置即是环节点位置(记住结论，不要问为什么) 123456789101112131415161718192021222324252627282930public static class Node &#123; public int value; public Node next; public Node(int data) &#123; this.value = data; &#125;&#125;// 找到链表第一个入环节点，如果无环，返回nullpublic static Node getLoopNode(Node head) &#123; if (head == null || head.next == null || head.next.next == null) &#123; return null; &#125; // n1 慢 n2 快 Node slow = head.next; // n1 -&gt; slow Node fast = head.next.next; // n2 -&gt; fast while (slow != fast) &#123; if (fast.next == null || fast.next.next == null) &#123; return null; &#125; fast = fast.next.next; slow = slow.next; &#125; // slow fast 相遇 fast = head; // n2 -&gt; walk again from head while (slow != fast) &#123; slow = slow.next; fast = fast.next; &#125; return slow;&#125; 两个无环链表交点位置注： 如果两个单向链表相交，相交后面的部分必然是共有的，那么两个链表最后的那个节点必然是同一个节点 长链表先走两个链表差值的步数，然后短链表在开始走，他俩一定会在第一个相交的位置相遇 123456789101112131415161718192021222324252627282930313233// 如果两个链表都无环，返回第一个相交节点，如果不想交，返回nullpublic static Node noLoop(Node head1, Node head2) &#123; if (head1 == null || head2 == null) &#123; return null; &#125; Node cur1 = head1; Node cur2 = head2; int n = 0; while (cur1.next != null) &#123; n++; cur1 = cur1.next; &#125; while (cur2.next != null) &#123; n--; cur2 = cur2.next; &#125; if (cur1 != cur2) &#123; return null; &#125; // n : 链表1长度减去链表2长度的值 cur1 = n &gt; 0 ? head1 : head2; // 谁长，谁的头变成cur1 cur2 = cur1 == head1 ? head2 : head1; // 谁短，谁的头变成cur2 n = Math.abs(n); while (n != 0) &#123; n--; cur1 = cur1.next; &#125; while (cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1;&#125; 两条有环链表查找交点分为两种情况：入环节点可能是同一个节点，也可能不是同一个节点，如图 情况1：入环节点可能是同一个节点，就是求单链表的第一个环节点问题，只不过从相交位置开始走 情况2：如果链表1在转回到自己的过程中没有遇到链表2，就说明是各自成环的，相交节点返回空就醒来，如果遇到，就是情况2，返回两个节点，都对，都属于第一个相交的节点 123456789101112131415161718192021222324252627282930313233343536373839// 两个有环链表，返回第一个相交节点，如果不想交返回nullpublic static Node bothLoop(Node head1, Node loop1, Node head2, Node loop2) &#123; Node cur1 = null; Node cur2 = null; if (loop1 == loop2) &#123; cur1 = head1; cur2 = head2; int n = 0; while (cur1 != loop1) &#123; n++; cur1 = cur1.next; &#125; while (cur2 != loop2) &#123; n--; cur2 = cur2.next; &#125; cur1 = n &gt; 0 ? head1 : head2; cur2 = cur1 == head1 ? head2 : head1; n = Math.abs(n); while (n != 0) &#123; n--; cur1 = cur1.next; &#125; while (cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1; &#125; else &#123; cur1 = loop1.next; while (cur1 != loop1) &#123; if (cur1 == loop2) &#123; return loop1; &#125; cur1 = cur1.next; &#125; return null; &#125;&#125; 查找两个链表相交节点注：难点为考虑是否有环，有环链表相交以及无环链表相交问题，没有用到额外数据结构，只用到有限几个变量 1234567891011121314151617public static Node getIntersectNode(Node head1, Node head2) &#123; if (head1 == null || head2 == null) &#123; return null; &#125; // 分别找到两个链表的环位置 Node loop1 = getLoopNode(head1); Node loop2 = getLoopNode(head2); if (loop1 == null &amp;&amp; loop2 == null) &#123; // 无环链表相交问题 return noLoop(head1, head2); &#125; if (loop1 != null &amp;&amp; loop2 != null) &#123; // 两条有环链表相交问题 return bothLoop(head1, loop1, head2, loop2); &#125; return null;&#125; 二叉树数据结构 12345678public static class Node &#123; public int value; public Node left; public Node right; public Node(int v) &#123; value = v; &#125;&#125; 二叉树遍历 先序遍历：头-&gt;左-&gt;右 中序遍历：左-&gt;头-&gt;右 后序遍历：左-&gt;右-&gt;头 递归遍历二叉树遍历说明 递归通过打印时机不同，实现先，中，后序遍历 12345678910public static void f(Node head) &#123; if (head == null) &#123; return; &#125; // 1 前序 f(head.left); // 2 中序 f(head.right); // 3 后序&#125; 非递归遍历二叉树 先序遍历(深度性遍历) 准备一个栈，根节点入栈弹出，打印，然后先压右，再压左 弹出打印，先压右再压左，周而复始 123456789101112131415161718public static void pre(Node head) &#123; System.out.print(&quot;pre-order: &quot;); if (head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); stack.add(head); while (!stack.isEmpty()) &#123; head = stack.pop(); System.out.print(head.value + &quot; &quot;); if (head.right != null) &#123; stack.push(head.right); &#125; if (head.left != null) &#123; stack.push(head.left); &#125; &#125; &#125; System.out.println();&#125; 后序遍历 在先序遍历的基础之上，增加一个收集栈，弹出来就放到收集栈中(不打印)，然后先压左，再压右 把收集栈中的元素依次出栈，打印 1234567891011121314151617181920212223public static void pos1(Node head) &#123; System.out.print(&quot;pos-order: &quot;); if (head != null) &#123; Stack&lt;Node&gt; s1 = new Stack&lt;Node&gt;(); Stack&lt;Node&gt; s2 = new Stack&lt;Node&gt;(); s1.push(head); while (!s1.isEmpty()) &#123; head = s1.pop(); // 头 右 左 s2.push(head); if (head.left != null) &#123; s1.push(head.left); &#125; if (head.right != null) &#123; s1.push(head.right); &#125; &#125; // 左 右 头 while (!s2.isEmpty()) &#123; System.out.print(s2.pop().value + &quot; &quot;); &#125; &#125; System.out.println();&#125; 中序遍历 整棵树左边界进栈，依次弹出的过程中，打印，对弹出节点的右树周而复始 为什么？ 因为整个树都会被他的左边界分解掉，我们把头和左边界压栈，然后再右，出栈的时候就是左，头，右 1234567891011121314151617public static void in(Node cur) &#123; System.out.print(&quot;in-order: &quot;); if (cur != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); while (!stack.isEmpty() || cur != null) &#123; if (cur != null) &#123; stack.push(cur); cur = cur.left; &#125; else &#123; cur = stack.pop(); System.out.print(cur.value + &quot; &quot;); cur = cur.right; &#125; &#125; &#125; System.out.println();&#125; 宽度遍历宽度遍历就是横着遍历，也是层次遍历 用队列，头节点放队列，每一次弹出就打印，然后先放左再放右，每一个元素出队列都是先放左再放右 123456789101112131415161718// 从node出发，进行宽度优先遍历public static void width(Node head) &#123; if (head == null) &#123; return; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(head); while (!queue.isEmpty()) &#123; Node cur = queue.poll(); System.out.println(cur.value); if (cur.left != null) &#123; queue.add(cur.left); &#125; if (cur.right != null) &#123; queue.add(cur.right); &#125; &#125;&#125; 求二叉树的最大宽度(难)分析：宽度性遍历的时候要知道每一层的节点个数 解：遍历每个节点的时候，知道他在第几层 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// 用hash表的解法public static int maxWidthUseMap(Node head) &#123; if (head == null) &#123; return 0; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(head); // key 在 哪一层，value HashMap&lt;Node, Integer&gt; levelMap = new HashMap&lt;&gt;(); levelMap.put(head, 1); int curLevel = 1; // 当前你正在统计哪一层的宽度 int curLevelNodes = 0; // 当前层curLevel层，宽度目前是多少 int max = 0; while (!queue.isEmpty()) &#123; Node cur = queue.poll(); int curNodeLevel = levelMap.get(cur); if (cur.left != null) &#123; levelMap.put(cur.left, curNodeLevel + 1); queue.add(cur.left); &#125; if (cur.right != null) &#123; levelMap.put(cur.right, curNodeLevel + 1); queue.add(cur.right); &#125; if (curNodeLevel == curLevel) &#123; curLevelNodes++; &#125; else &#123; max = Math.max(max, curLevelNodes); curLevel++; curLevelNodes = 1; &#125; &#125; max = Math.max(max, curLevelNodes); return max;&#125;// 不用hash表的方法 (难度高)public static int maxWidthNoMap(Node head) &#123; if (head == null) &#123; return 0; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(head); Node curEnd = head; // 当前层，最右节点是谁 Node nextEnd = null; // 下一层，最右节点是谁 int max = 0; int curLevelNodes = 0; // 当前层的节点数 while (!queue.isEmpty()) &#123; Node cur = queue.poll(); if (cur.left != null) &#123; queue.add(cur.left); nextEnd = cur.left; &#125; if (cur.right != null) &#123; queue.add(cur.right); nextEnd = cur.right; &#125; curLevelNodes++; if (cur == curEnd) &#123; max = Math.max(max, curLevelNodes); curLevelNodes = 0; curEnd = nextEnd; &#125; &#125; return max;&#125; 折纸问题 结果可看做头节点是凹，所有的左子树头节点都是凹，所有右子树头肩点都是凸的二叉树 中序遍历即可打印出从上到下的所有结构 12345678910111213141516public static void main(String[] args) &#123; int N = 4; process(1, N, true);&#125;// 这个节点在第i层，一共有N层，N固定不变的// 这个节点如果是凹的话，down = T// 这个节点如果是凸的话，down = F// 函数的功能：中序打印以你想象的节点为头的整棵树！public static void process(int i, int N, boolean down) &#123; if (i &gt; N) &#123; return; &#125; process(i + 1, N, true); System.out.print(down ? &quot;凹 &quot; : &quot;凸 &quot;); process(i + 1, N, false);&#125; 搜索二叉树(递归套路) 题目：如何判断一颗二叉树是搜索二叉树？ 搜索二叉树的特点：任何一个节点，左子树的节点一定比它小，右子树的节点一定比它大 解题： 中序遍历一定是升序，如果某个位置有降序，一定不是搜索二叉树 递归套路题解 :向我左树要信息，右树要信息，左树必须是搜索二叉树且左树最大值小于我，右树是搜索二叉树并且最小值大于我；左树信息：1.是否是搜索二叉树，2.最大值，3.最小值；右树也是 注意：递归套路，可以解决一切树形DP 问题，无非是可能性的罗列有难度 12345678910111213141516171819202122232425262728293031323334// 解法1： 额外引入数组// 节点public static class Node &#123; public int value; public Node left; public Node right; public Node(int data) &#123; this.value = data; &#125;&#125;// 中序遍历到一个数组中，然后判断数组是不是升序public static boolean isBST1(Node head) &#123; if (head == null) &#123; return true; &#125; ArrayList&lt;Node&gt; arr = new ArrayList&lt;&gt;(); in(head, arr); for (int i = 1; i &lt; arr.size(); i++) &#123; if (arr.get(i).value &lt;= arr.get(i - 1).value) &#123; return false; &#125; &#125; return true;&#125;// 中序遍历public static void in(Node head, ArrayList&lt;Node&gt; arr) &#123; if (head == null) &#123; return; &#125; in(head.left, arr); arr.add(head); in(head.right, arr);&#125; 12345678910111213141516171819// 解法2：递归方式public static int preValue = Integer.MIN_VALUE;public static boolean checkBST(Node head) &#123; if (head == null) &#123; return true; &#125; boolean checkLeft = checkBST(head.left); if (!checkLeft) &#123; return false; &#125; // 中序打印的时机，换成了中序比较的时机 if (head.value &lt;= preValue) &#123; return false; &#125; else &#123; preValue = head.value; &#125; return checkBST(head.right);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 解法3：递归套路/** * 递归返回值 */public static class Info &#123; public boolean isBST; // 是否是搜索二叉树 public int max; // 最大值 public int min; // 最小值 public Info(boolean i, int ma, int mi) &#123; isBST = i; max = ma; min = mi; &#125;&#125;public static Info process(Node x) &#123; if (x == null) &#123; return null; &#125; Info leftInfo = process(x.left); Info rightInfo = process(x.right); int min = x.value; int max = x.value; // 最小值和最大值就是我当前节点的值和它比较得出的最小值和最大值 if (leftInfo != null) &#123; min = Math.min(min, leftInfo.min); max = Math.max(max, leftInfo.max); &#125; if (rightInfo != null) &#123; min = Math.min(min, rightInfo.min); max = Math.max(max, rightInfo.max); &#125; // 是否是搜索二叉树 boolean isBST = true; // 左边有信息并且左边不是搜索二叉树 if (leftInfo != null &amp;&amp; !leftInfo.isBST) &#123; isBST = false; &#125; if (rightInfo != null &amp;&amp; !rightInfo.isBST) &#123; isBST = false; &#125; // 左边有信息，但是左边的最大值大于等于我的值 if (leftInfo != null &amp;&amp; leftInfo.max &gt;= x.value) &#123; isBST = false; &#125; // 右边有信息，右边的最小值小于等于我当前值 if (rightInfo != null &amp;&amp; rightInfo.min &lt;= x.value) &#123; isBST = false; &#125; return new Info(isBST, max, min);&#125; 完全二叉树 如何判断一个二叉树是完全二叉树 完全二叉树：一颗二叉树从左到右是依次变满的，即使不满，也是变满的样子 解题：二叉树宽度遍历，1.任何一个节点如果有有节点，没左节点，false；2.在第一个条件不违规情况，如果遇到第一个左右两个节点不双全情况，接下来遇到的所有节点，必须是叶子节点 1234567891011121314151617181920212223242526272829303132public static boolean isCBT(Node head) &#123; if (head == null) &#123; return true; &#125; LinkedList&lt;Node&gt; queue = new LinkedList&lt;&gt;(); // 是否遇到过左右两个孩子不双全的节点 boolean leaf = false; Node l = null; Node r = null; queue.add(head); while (!queue.isEmpty()) &#123; head = queue.poll(); l = head.left; r = head.right; // 如果遇到了不双全的节点之后，又发现当前节点不是叶节点 if ((leaf &amp;&amp; (l != null || r != null)) || (l == null &amp;&amp; r != null)) &#123; return false; &#125; if (l != null) &#123; queue.add(l); &#125; if (r != null) &#123; queue.add(r); &#125; // 遇到左右两个节点不双全的情况，修改标记 if (l == null || r == null) &#123; leaf = true; &#125; &#125; return true;&#125; 平衡二叉树 如何判断一棵树是平衡二叉树 平衡二叉树特性：对于任何一个子树来说，左树的高度和右树的高度差，都不超过1 解决思路：假设我可以向我的左树要信息，可以向右树要信息，如果我整棵树是平衡二叉树，我左树得是平的，右树得是平的，对于X节点来说，左树-右树高度差&lt;=1；我向左树要信息：1.是否是平的；2.高度是多少，右树要信息：1.是否是平的；2.高度是多少 12345678910111213141516171819202122232425262728293031323334/** * 返回值信息 */public static class Info &#123; public boolean isBalanced; public int height; public Info(boolean i, int h) &#123; isBalanced = i; height = h; &#125;&#125;public static Info process(Node x) &#123; if (x == null) &#123; return new Info(true, 0); &#125; Info leftInfo = process(x.left); Info rightInfo = process(x.right); // x为头的节点的高度：左树和右树较大的那个高度再加上我自己(+1) int height = Math.max(leftInfo.height, rightInfo.height) + 1; // 是否是平衡树：我左树得是平衡，右树得是平衡树，并且我左树和右树的高度差的绝对值得小于2 boolean isBalanced = true; if (!leftInfo.isBalanced) &#123; isBalanced = false; &#125; if (!rightInfo.isBalanced) &#123; isBalanced = false; &#125; if (Math.abs(leftInfo.height - rightInfo.height) &gt; 1) &#123; isBalanced = false; &#125; return new Info(isBalanced, height);&#125; 满二叉树 如何判断一棵树是满二叉树 树最大深度L，节点个数N，满足N=2(L次方)-1 解法(递归套路)：先求二叉树最大深度L，再求节点个数N，满足N=2(L次方)-1 12345678910111213141516171819202122232425262728293031323334// 满二叉树解法：递归套路/** * 返回值信息 */public static class Info &#123; public int height; public int nodes; public Info(int h, int n) &#123; height = h; nodes = n; &#125;&#125;public static boolean isFull(Node head) &#123; if (head == null) &#123; return true; &#125; Info all = process(head); // N=2(L次方)-1 return (1 &lt;&lt; all.height) - 1 == all.nodes;&#125;public static Info process(Node head) &#123; if (head == null) &#123; return new Info(0, 0); &#125; Info leftInfo = process(head.left); Info rightInfo = process(head.right); // 高度等于左树和右树最高的高度+1 int height = Math.max(leftInfo.height, rightInfo.height) + 1; // 总个数等于左边的个数加上右边的个数加1 int nodes = leftInfo.nodes + rightInfo.nodes + 1; return new Info(height, nodes);&#125; 二叉树最低公共祖先 给定两个二叉树节点node1和node2，找到他们的最低公共祖先节点 解法1：遍历整棵树，把所有节点的父节点都维护到一个Map中，然后找到node1的所有父节点维护到set中，再遍历node2的所有的父，第一个在set中遇到的节点就是最低公共祖先 1234567891011121314151617181920212223242526272829303132333435// 解法1public static Node lca(Node head, Node o1, Node o2) &#123; if (head == null) &#123; return null; &#125; HashMap&lt;Node, Node&gt; parentMap = new HashMap&lt;&gt;(); parentMap.put(head, null); fillParentMap(head, parentMap); HashSet&lt;Node&gt; set = new HashSet&lt;&gt;(); Node cur = o1; set.add(cur); // 只有头节点才等于自己的父，如果当前节点不等于自己的父，就可以往上走 while (null != parentMap.get(cur)) &#123; cur = parentMap.get(cur); set.add(cur); &#125; // o1往上所有节点都在这个set里面，只有最初的head不在里面 cur = o2; while (!set.contains(cur)) &#123; cur = parentMap.get(cur); &#125; return cur;&#125;// 维护整棵树的所有父节点到Map中private static void fillParentMap(Node head, HashMap&lt;Node, Node&gt; fatherMap) &#123; if (head.left != null) &#123; fatherMap.put(head.left, head); fillParentMap(head.left, fatherMap); &#125; if (head.right != null) &#123; fatherMap.put(head.right, head); fillParentMap(head.right, fatherMap); &#125;&#125; 解法2(非常抽象)：可能的情况有1：node1和node2互为公共祖先；2：node1和node2不互为公共祖先； 1234567891011121314/** * 解法2：可能的情况有1：node1和node2互为公共祖先；2：node1和node2不互为公共祖先； */public static Node lowestCommonAncestor(Node head, Node o1, Node o2) &#123; if (head == null || head == o1 || head == o2) &#123; return head; &#125; Node left = lowestCommonAncestor(head.left, o1, o2); Node right = lowestCommonAncestor(head.right, o1, o2); if (left != null &amp;&amp; right != null) &#123; return head; &#125; return left != null ? left : right;&#125; 图 常见的表示图的方法：临接表法，和临接矩阵法，数组等 做模板，然后把所有的图的问题转化为自己熟悉的数据结构，带着模板上考场 图的宽度优先遍历约瑟夫圆环问题逆波兰计算器 实现一个计算器，只有加减乘除法，没有括号，输入是一个字符串如10+2+3*5 解题：表达式转化为后缀表达式（逆波兰表达式） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125// 解题public static void main(String[] args) &#123; String str = &quot;10+2+3*5&quot;; // 表达式转换为操作数和操作符的中缀表达式数组 String[] strArr = changeStrArr(str); // 中缀表达式转化为后缀表达式 List&lt;String&gt; polandList = polandNotation(strArr); System.out.println(polandList); // 后缀表达式计算 System.out.println(calculate(polandList));&#125;/** * 字符串转成中缀的数组 * 只有加减乘除，没有扩号 */private static String[] changeStrArr(String str) &#123; StringBuilder stringBuilder = new StringBuilder(); for (char c : str.toCharArray()) &#123; if (&quot;+-*/&quot;.contains(String.valueOf(c))) &#123; stringBuilder.append(&quot;;&quot;); stringBuilder.append(c); stringBuilder.append(&quot;;&quot;); &#125; else &#123; stringBuilder.append(c); &#125; &#125; return stringBuilder.toString().split(&quot;;&quot;);&#125;/** * 中缀表达式转化为后缀表达式 * 1.初始化两个栈，运算符栈s1和储存中间结果的栈s2 * 2.从左到右扫描中缀表达式 * 3.遇到操作数，入栈s2 * 4.遇到运算符，比较其与s1栈顶运算符的优先级： * (1).如果s1为空，或者栈顶运算符为左括号&quot;(&quot;,直接将运算符入栈； * (2).否则，若优先级比栈顶运算符高，也将运算符入栈s1; * (3).否则，将s1栈顶运算符弹出入栈s2中，再次转到(4-1) 与s1中新的栈顶运算符比较； * 本方法只考虑到加减乘除操作，不考虑扩号 */private static List&lt;String&gt; polandNotation(String[] str) &#123; List&lt;String&gt; s2 = new ArrayList&lt;&gt;(); Stack&lt;String&gt; s1 = new Stack&lt;&gt;(); for (String itm : str) &#123; // 遇到操作数，直接入栈s2 if (itm.matches(&quot;\\\\d+&quot;)) &#123; s2.add(itm); &#125; else &#123; // 如果栈不为空，并且栈顶优先级比我目前运算符优先级高，就把栈顶运算符如s2，然后吧当前运算符如s1 while (!s1.isEmpty() &amp;&amp; Operation.getValue(s1.peek()) &gt;= Operation.getValue(itm)) &#123; s2.add(s1.pop()); &#125; s1.push(itm); &#125; &#125; while (!s1.isEmpty()) &#123; s2.add(s1.pop()); &#125; return s2;&#125;/** * 运算符比较 */private static class Operation &#123; private static int ADD = 1; private static int SUB = 1; private static int MUL = 2; private static int DIV = 2; public static int getValue(String operation) &#123; int result = 0; switch (operation) &#123; case &quot;+&quot;: result = ADD; break; case &quot;-&quot;: result = SUB; break; case &quot;*&quot;: result = MUL; break; case &quot;/&quot;: result = DIV; break; default: break; &#125; return result; &#125;&#125;/** * 逆波兰表达式计算 * 1.定义一个栈，匹配到非运算符就入栈 * 2.遇到运算符就把栈顶两个数字出栈，用后出栈的数和先出栈的数做运算，把运算结果再入栈 * 3.直到最后，栈顶结果即为计算结果 */private static int calculate(List&lt;String&gt; polandList) &#123; Stack&lt;String&gt; stack = new Stack&lt;&gt;(); for (String itm : polandList) &#123; // 匹配的是多位数 if (itm.matches(&quot;\\\\d+&quot;)) &#123; stack.push(itm); &#125; else &#123; // 弹出两个数，并运算，再入栈 int num2 = Integer.parseInt(stack.pop()); int num1 = Integer.parseInt(stack.pop()); int res = 0; if (itm.equals(&quot;+&quot;)) &#123; res = num1 + num2; &#125; else if (itm.equals(&quot;-&quot;)) &#123; res = num1 - num2; &#125; else if (itm.equals(&quot;*&quot;)) &#123; res = num1 * num2; &#125; else if (itm.equals(&quot;/&quot;)) &#123; res = num1 / num2; &#125; else &#123; throw new RuntimeException(&quot;运算符有误&quot;); &#125; stack.push(String.valueOf(res)); &#125; &#125; return Integer.parseInt(stack.pop());&#125; 前缀树1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495// 前缀树数据结构public static class Node1 &#123; public int pass; public int end; public Node1[] nexts; // char tmp = &#x27;b&#x27; (tmp - &#x27;a&#x27;) public Node1() &#123; pass = 0; end = 0; // 0 a // 1 b // 2 c // .. .. // 25 z // nexts[i] == null i方向的路不存在 // nexts[i] != null i方向的路存在 nexts = new Node1[26]; &#125;&#125;// 添加元素public void insert(String word) &#123; if (word == null) &#123; return; &#125; char[] str = word.toCharArray(); Node1 node = root; node.pass++; int path = 0; for (int i = 0; i &lt; str.length; i++) &#123; // 从左往右遍历字符 path = str[i] - &#x27;a&#x27;; // 由字符，对应成走向哪条路 if (node.nexts[path] == null) &#123; node.nexts[path] = new Node1(); &#125; node = node.nexts[path]; node.pass++; &#125; node.end++;&#125;// word这个单词之前加入过几次public int search(String word) &#123; if (word == null) &#123; return 0; &#125; char[] chs = word.toCharArray(); Node1 node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - &#x27;a&#x27;; if (node.nexts[index] == null) &#123; return 0; &#125; node = node.nexts[index]; &#125; return node.end;&#125;// 所有加入的字符串中，有几个是以pre这个字符串作为前缀的public int prefixNumber(String pre) &#123; if (pre == null) &#123; return 0; &#125; char[] chs = pre.toCharArray(); Node1 node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - &#x27;a&#x27;; if (node.nexts[index] == null) &#123; return 0; &#125; node = node.nexts[index]; &#125; return node.pass;&#125;// 删除public void delete(String word) &#123; if (search(word) != 0) &#123; char[] chs = word.toCharArray(); Node1 node = root; node.pass--; int path = 0; for (int i = 0; i &lt; chs.length; i++) &#123; path = chs[i] - &#x27;a&#x27;; if (--node.nexts[path].pass == 0) &#123; node.nexts[path] = null; return; &#125; node = node.nexts[path]; &#125; node.end--; &#125;&#125; 贪心算法在某一个标准下，优先考虑最满足标准的样本，最后考虑最不满足标准的样本，最终得到一个答案的算法，叫做贪心算法。也就是说，不从整体最优上加以考虑，所做出的是某种意义上的局部最优解。 会议室占用问题问题：只有一个会议室，多个会议占用会议室的时间有冲突，如何让会议室进行的会议最多，返回最多的会议场次 解：哪个会议结束时间早，就优先安排，然后接下来继续找下一个会议结束时间早的会议 1234567891011121314151617181920212223242526272829303132// 会议开始时间和结束时间public static class Program &#123; public int start; public int end; public Program(int start, int end) &#123; this.start = start; this.end = end; &#125;&#125;// 比较器public static class ProgramComparator implements Comparator&lt;Program&gt; &#123; @Override public int compare(Program o1, Program o2) &#123; return o1.end - o2.end; &#125;&#125;// 会议的开始时间和结束时间，都是数值，不会 &lt; 0public static int bestArrange2(Program[] programs) &#123; Arrays.sort(programs, new ProgramComparator()); int timeLine = 0; int result = 0; // 依次遍历每一个会议，结束时间早的会议先遍历 for (int i = 0; i &lt; programs.length; i++) &#123; if (timeLine &lt;= programs[i].start) &#123; result++; timeLine = programs[i].end; &#125; &#125; return result;&#125; 八皇后问题多线程相关三个线程交替打印 三个线程交替打印，1线程打印1；2线程打印2；3线程打印3；1线程打印4……一直打印到100 解题方式由很多，无非就是涉及到线程通信问题以及修改共享变量问题 题解1：不加锁，利用线程可见性 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class ThreadPrint &#123; private static volatile int i = 0; private static volatile int flag = 0; public static void main(String[] args) &#123; Thread thread1 = new Thread(new Thread1()); Thread thread2 = new Thread(new Thread2()); Thread thread3 = new Thread(new Thread3()); thread1.start(); thread2.start(); thread3.start(); &#125; public static class Thread1 implements Runnable &#123; public void run() &#123; while (i &lt;= 100) &#123; if (flag == 0) &#123; System.out.println(&quot;t1=&quot; + i); i++; flag = 1; &#125; &#125; &#125; &#125; public static class Thread2 implements Runnable &#123; public void run() &#123; while (i &lt;= 100) &#123; if (flag == 1) &#123; System.out.println(&quot;t2=&quot; + i); i++; flag = 2; &#125; &#125; &#125; &#125; public static class Thread3 implements Runnable &#123; public void run() &#123; while (i &lt;= 100) &#123; if (flag == 2) &#123; System.out.println(&quot;t3=&quot; + i); i++; flag = 0; &#125; &#125; &#125; &#125;&#125; 题解2：LockSupport 实现 123456789101112131415161718192021222324252627282930313233343536373839404142public class ThreadPrint2 &#123; private static int number = 1; private static Thread thread1, thread2,thread3; public static void main(String[] args) &#123; thread1 = new Thread(ThreadPrint2::thread1, &quot;thread1&quot;); thread2 = new Thread(ThreadPrint2::thread2, &quot;thread2&quot;); thread3 = new Thread(ThreadPrint2::thread3, &quot;thread3&quot;); thread1.start(); thread2.start(); thread3.start(); &#125; public static void thread1() &#123; while (ThreadPrint2.number &lt;= 100) &#123; System.out.println(&quot;thread1:&quot; + ThreadPrint2.number); ThreadPrint2.number++; LockSupport.unpark(thread2); LockSupport.park(); &#125; &#125; public static void thread2() &#123; while (ThreadPrint2.number &lt;= 100) &#123; LockSupport.park(); System.out.println(&quot;thread2:&quot; + ThreadPrint2.number); ThreadPrint2.number++; LockSupport.unpark(thread3); &#125; &#125; public static void thread3() &#123; while (ThreadPrint2.number &lt;= 100) &#123; LockSupport.park(); System.out.println(&quot;thread3:&quot; + ThreadPrint2.number); ThreadPrint2.number++; LockSupport.unpark(thread1); &#125; &#125;&#125; 题解3：经典实现 实现wait-&gt;notifyAll 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ThreadPrint3 &#123; private static int count = 1; public static void main(String[] args) &#123; Object lock = new Object(); new Thread(() -&gt; &#123; try &#123; synchronized (lock) &#123; while (count &lt;= 100) &#123; if (count % 3 == 1) &#123; System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + count); count++; &#125; lock.notifyAll(); lock.wait(); &#125; lock.notifyAll(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, &quot;T1&quot;).start(); new Thread(() -&gt; &#123; try &#123; synchronized (lock) &#123; while (count &lt;= 100) &#123; if (count % 3 == 2) &#123; System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + count); count++; &#125; lock.notifyAll(); lock.wait(); &#125; lock.notifyAll(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, &quot;T2&quot;).start(); new Thread(() -&gt; &#123; try &#123; synchronized (lock) &#123; while (count &lt;= 100) &#123; if (count % 3 == 0) &#123; System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + count); count++; &#125; lock.notifyAll(); lock.wait(); &#125; lock.notifyAll(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, &quot;T3&quot;).start(); &#125;&#125; 题解4：Lock实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ThreadPrint4 &#123; private static int cnt = 0; public static void main(String[] args) &#123; Lock lock = new ReentrantLock(); Condition c1 = lock.newCondition(); Condition c2 = lock.newCondition(); Condition c3 = lock.newCondition(); new Thread(() -&gt; &#123; lock.lock(); try &#123; while (cnt &lt;= 100 &amp;&amp; cnt % 3 == 0) &#123; System.out.println(Thread.currentThread().getName() + &quot;----&gt;&quot; + cnt); cnt++; c2.signal(); c1.await(); &#125; c3.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;, &quot;T1&quot;).start(); new Thread(() -&gt; &#123; lock.lock(); try &#123; while (cnt &lt;= 100 &amp;&amp; cnt % 3 == 1) &#123; System.out.println(Thread.currentThread().getName() + &quot;----&gt;&quot; + cnt); cnt++; c3.signal(); c2.await(); &#125; c1.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;, &quot;T2&quot;).start(); new Thread(() -&gt; &#123; lock.lock(); try &#123; while (cnt &lt;= 100 &amp;&amp; cnt % 3 == 2) &#123; System.out.println(Thread.currentThread().getName() + &quot;----&gt;&quot; + cnt); cnt++; c1.signal(); c3.await(); &#125; c2.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;, &quot;T3&quot;).start(); &#125;&#125; 其他算法题","categories":[{"name":"面试","slug":"面试","permalink":"https://zhangyong3214.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"}]},{"title":"Docker操作笔记-从小白到入门","slug":"软件工具/Docker操作笔记-从小白到入门","date":"2022-01-27T08:31:13.128Z","updated":"2022-01-27T08:31:13.128Z","comments":true,"path":"2022/01/27/软件工具/Docker操作笔记-从小白到入门/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/Docker%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0-%E4%BB%8E%E5%B0%8F%E7%99%BD%E5%88%B0%E5%85%A5%E9%97%A8/","excerpt":"1、Docker安装centos 为例：查看版本：cat /etc/redhat-release 参考网址 121.先安装gcc：yum -y install gcc 2.查看版本：gcc -v 安装需要的软件包","text":"1、Docker安装centos 为例：查看版本：cat /etc/redhat-release 参考网址 121.先安装gcc：yum -y install gcc 2.查看版本：gcc -v 安装需要的软件包 1yum install -y yum-utils device-mapper-persistent-data lvm2 1.1、阿里加速：1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 查看配置： vi /etc/yum.repos.d/docker-ce.repo 更新软件包： yum makecache fast 安装docker： yum install docker-ce docker-ce-cli containerd.io 配置文件位置： /etc/sysconfig/docker 启动docker： systemctl start docker 设置开机启动： systemctl enable docker 查看docker启动进程： ps -ef|grep docker 查看docker版本： docker version docker info 1.2、下载镜像1234docker pull mysql:5.7 docker pull rabbitmq:management （带管理台的MQ）docker pull zookeeper:latest docker pull redis:rc-buster 镜像搜索地址 镜像加速地址 1.3、权限问题解决docker守护进程启动的时候，会默认赋予名字为docker的用户组读写Unix socket的权限，因此只要创建docker用户组，并将当前用户加入到docker用户组中，那么当前用户就有权限访问Unix socket了，进而也就可以执行docker相关命令 添加docker用户组 sudo groupadd docker 将登陆用户加入到docker用户组中 sudo gpasswd -a $USER docker 更新用户组 newgrp docker 测试docker命令是否可以使用sudo正常使用 docker ps 2、镜像操作 查看镜像：docker images 展示所有所有镜像（包含中间镜像层）：docker images -a 查询镜像：docker search 镜像名字 删除镜像：docker rmi 镜像id 3、容器操作 启动mysql： docker run -p 3306:3306 --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 启动rabitmq： docker run -d -p 5672:5672 -p 15672:15672 --name myrabitmq 镜像id 启动redis： docker run -d -p 6379:6379 --name myredis 镜像id 启动zookeeper： docker run --name zk01 -p 2181:2181 --restart always -d 镜像id 启动nacos： docker run --name nacos-2.0.1 -e MODE=standalone -p 8849:8848 -d nacos/nacos-server:2.0.1 启动kibana： docker run -d --name kibana7.7.1 --net mynet -p 5601:5601 kibana:7.7.1 Kibana 在Doker中启动相关配置 123docker exec -it kibana7.7.1 bashcd config vi kibana.yml 查看日志： docker logs -f -t –tail 100 kibana7.7.1 更新启动参数： docker update –restart=always xxx 查看所有容器： docker ps -a 查看启动容器： docker ps 启动已停止的容器： docker start 容器id或名字 关闭容器 ： docker stop 容器id 取消容器开机启动： docker update --restart=no 容器ID 强制关闭： docker kill 容器id 删除已停止容器 ： docker rm 容器id 删除没有停止容器： docker rm -f 容器id 进入容器内部： docker exec -it 程序id /bin/bash exit 关闭容器退出(自测不会退出)： ctrl+p+q 查看日志： docker logs -f (追加) -t (加入时间戳) --tail 3 (显示最后3行) 容器id 查看容器结构细节： docker inspect 容器id 拷贝容器中的文件： docker cp 容器id:文件路径 要拷贝到的路径 提交自己的docker镜像： docker commit -a=&quot;lgd&quot; -m=&quot;mysql-lgd&quot; 243baa0ea2a7 ligoudan/lgd-mysql:1.0","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"Git笔记-常用命令以及日常操作技巧汇总","slug":"软件工具/git笔记","date":"2022-01-27T08:31:13.128Z","updated":"2022-01-27T08:31:13.128Z","comments":true,"path":"2022/01/27/软件工具/git笔记/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/git%E7%AC%94%E8%AE%B0/","excerpt":"1、为Git配置代理（解决国内连接git慢问题）相关文章：解决git无法clone提示443以及配置git代理方法 12345678# 添加当前仓库配置：git config --local http.proxy &quot;127.0.0.1:1087&quot; # 删除当前仓库配置：git config --unset --local http.proxy# 添加全局配置：git config --global http.proxy &quot;127.0.0.1:1087&quot; # 删除全局配置：git config --unset --global http.proxy","text":"1、为Git配置代理（解决国内连接git慢问题）相关文章：解决git无法clone提示443以及配置git代理方法 12345678# 添加当前仓库配置：git config --local http.proxy &quot;127.0.0.1:1087&quot; # 删除当前仓库配置：git config --unset --local http.proxy# 添加全局配置：git config --global http.proxy &quot;127.0.0.1:1087&quot; # 删除全局配置：git config --unset --global http.proxy 注：添加相关配置也可以到本地仓库对应的目录，修改.git文件夹里面的config文件，如下图，我的本地的1087端口是我的科学上网地址 config 配置有system级别 global（用户级别） 和local（当前仓库）三个 设置先从system-》global-》local 底层配置会覆盖顶层配置 分别使用–system/global/local 可以定位到配置文件 查看系统config 1git config --system --list 查看当前用户（global）配置 1git config --global --list 查看当前仓库配置信息 1git config --local --list","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"IDEA常用快捷键(Mac版)","slug":"软件工具/IDEA常用快捷键","date":"2022-01-27T08:31:13.128Z","updated":"2022-01-27T08:31:13.128Z","comments":true,"path":"2022/01/27/软件工具/IDEA常用快捷键/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/IDEA%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"Mac键盘符号和修饰键说明 ⌘ Command ⇧ Shift ⌥ Option ⌃ Control ↩︎ Return/Enter ⌫ Delete ⌦ 向前删除键（Fn+Delete） ↑ 上箭头 ↓ 下箭头 ← 左箭头 → 右箭头 ⇞ Page Up（Fn+↑） ⇟ Page Down（Fn+↓） Home Fn + ← End Fn + → ⇥ 右制表符（Tab键） ⇤ 左制表符（Shift+Tab） ⎋ Escape (Esc) Editing（编辑） ⌃Space 基本的代码补全（补全任何类、方法、变量） ⌃⇧Space 智能代码补全（过滤器方法列表和变量的预期类型） ⌘⇧↩ 自动结束代码，行末自动添加分号 ⌘P 显示方法的参数信息 ⌃J, Mid. button click 快速查看文档 ⇧F1 查看外部文档（在某些代码上会触发打开浏览器显示相关文档） ⌘+鼠标放在代码上 显示代码简要信息 ⌘F1 在错误或警告处显示具体描述信息 ⌘N, ⌃↩, ⌃N 生成代码（getter、setter、构造函数、hashCode/equals,toString） ⌃O 覆盖方法（重写父类方法） ⌃I 实现方法（实现接口中的方法） ⌘⌥T 包围代码（使用if..else, try..catch, for, synchronized等包围 选中的代码） ⌘/ 注释/取消注释与行注释 ⌘⌥/ 注释/取消注释与块注释 ⌥↑ 连续选中代码块fa ⌥↓ 减少当前选中的代码块 ⌃⇧Q 显示上下文信息 ⌥↩ 显示意向动作和快速修复代码 ⌘⌥L 格式化代码 ⌃⌥O 优化import ⌃⌥I 自动缩进线 ⇥ / ⇧⇥ 缩进代码 / 反缩进代码 ⌘X 剪切当前行或选定的块到剪贴板 ⌘C 复制当前行或选定的块到剪贴板 ⌘V 从剪贴板粘贴 ⌘⇧V 从最近的缓冲区粘贴 ⌘D 复制当前行或选定的块 ⌘⌫ 删除当前行或选定的块的行 ⌃⇧J 智能的将代码拼接成一行 ⌘↩ 智能的拆分拼接的行 ⇧↩ 开始新的一行 ⌘⇧U 大小写切换 ⌘⇧] / ⌘⇧[ 选择直到代码块结束/开始 ⌥⌦ 删除到单词的末尾（⌦键为Fn+Delete） ⌥⌫ 删除到单词的开头 ⌘+ / ⌘- 展开 / 折叠代码块 ⌘⇧+ 展开所以代码块 ⌘⇧- 折叠所有代码块 ⌘W 关闭活动的编辑器选项卡 Search/Replace（查询/替换） Double ⇧ 查询任何东西 ⌘F 文件内查找 ⌘G 查找模式下，向下查找 ⌘⇧G 查找模式下，向上查找 ⌘R 文件内替换 ⌘⇧F 全局查找（根据路径） ⌘⇧R 全局替换（根据路径） ⌘⇧S 查询结构（Ultimate Edition 版专用，需要在Keymap中设置） ⌘⇧M 替换结构（Ultimate Edition 版专用，需要在Keymap中设置） Usage Search（使用查询） ⌥F7 / ⌘F7 在文件中查找用法 / 在类中查找用法 ⌘⇧F7 在文件中突出显示的用法 ⌘⌥F7 显示用法 Compile and Run（编译和运行） ⌘F9 编译Project ⌘⇧F9 编译选择的文件、包或模块 ⌃⌥R 弹出 Run 的可选择菜单 ⌃⌥D 弹出 Debug 的可选择菜单 ⌃R 运行 ⌃D 调试 ⌃⇧R, ⌃⇧D 从编辑器运行上下文环境配置 Debugging（调试） F8 进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F7 进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该 方法体还有方法，则不会进入该内嵌的方法中 ⇧F7 智能步入，断点所在行上有多个方法调用，会弹出进入哪个方法 ⇧F8 跳出 ⌥F9 运行到光标处，如果光标前有其他断点会进入到该断点 ⌥F8 计算表达式（可以更改变量值使其生效） ⌘⌥R 恢复程序运行，如果该断点下面代码还有断点则停在下一个断点上 ⌘F8 切换断点（若光标当前行有断点则取消断点，没有则加上断点） ⌘⇧F8 查看断点信息 Navigation（导航） ⌘O 查找类文件 ⌘⇧O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ ⌘⌥O 前往指定的变量 / 方法 ⌃← / ⌃→ 左右切换打开的编辑tab页 F12 返回到前一个工具窗口 ⎋ 从工具窗口进入代码文件窗口 ⇧⎋ 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 ⌘⇧F4 关闭活动run/messages/find/… tab ⌘L 在当前文件跳转到某一行的指定处 ⌘E 显示最近打开的文件记录列表 ⌘⌥← / ⌘⌥→ 退回 / 前进到上一个操作的地方 ⌘⇧⌫ 跳转到最后一个编辑的地方 ⌥F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在 代码编辑窗口可以选择显示该文件的Finder) ⌘B / ⌘ 鼠标点击 进入光标所在的方法/变量的接口或是定义处 ⌘⌥B 跳转到实现处，在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 ⌥ Space, ⌘Y 快速打开光标所在方法、类的定义 ⌃⇧B 跳转到类型声明处 ⌘U 前往当前光标所在方法的父类的方法 / 接口定义 ⌃↓ / ⌃↑ 当前光标跳转到当前文件的前一个/后一个方法名位置 ⌘] / ⌘[ 移动光标到当前所在代码的花括号开始/结束位置 ⌘F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） ⌃H 显示当前类的层次结构 ⌘⇧H 显示方法层次结构 ⌃⌥H 显示调用层次结构 F2 / ⇧F2 跳转到下一个/上一个突出错误或警告的位置 F4 / ⌘↓ 编辑/查看代码源 ⌥ Home 显示到当前文件的导航条 F3选中文件/文件夹/代码行，添加/取消书签 ⌥F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 ⌃0…⌃9 定位到对应数值的书签位置 ⌘F3 显示所有书签 Refactoring（重构） F5 复制文件到指定目录 F6 移动文件到指定目录 ⌘⌫ 在文件上为安全删除文件，弹出确认框 ⇧F6 重命名文件 ⌘F6 更改签名 ⌘⌥N 一致性 ⌘⌥M 将选中的代码提取为方法 ⌘⌥V 提取变量 ⌘⌥F 提取字段 ⌘⌥C 提取常量 ⌘⌥P 提取参数 VCS/Local History（版本控制/本地历史记录） ⌘K 提交代码到版本控制器 ⌘T 从版本控制器更新代码 ⌥⇧C 查看最近的变更记录 ⌃C 快速弹出版本控制器操作面板 Live Templates（动态代码模板） ⌘⌥J 弹出模板选择窗口，将选定的代码使用动态模板包住 ⌘J 插入自定义动态代码模板 General（通用） ⌘1…⌘9 打开相应编号的工具窗口 ⌘S 保存所有 ⌘⌥Y 同步、刷新 ⌃⌘F 切换全屏模式 ⌘⇧F12 切换最大化编辑器 ⌥⇧F 添加到收藏夹 ⌥⇧I 检查当前文件与当前的配置文件 `§⌃, ⌃``快速切换当前的scheme（切换主题、代码样式等） ⌘, 打开IDEA系统设置 ⌘; 打开项目结构对话框 ⇧⌘A 查找动作（可设置相关选项） ⌃⇥ 编辑窗口标签和工具窗口之间切换（如果在切换的过程加按上delete，则是关闭对应选中的窗口） Other（一些官方文档上没有体现的快捷键） ⌘⇧8 竖编辑模式 导航 ⌘O 查找类文件 Ctrl + N ⌘⌥O 前往指定的变量 / 方法 Ctrl + Shift + Alt + N ⌃← / ⌃→ 左右切换打开的编辑tab页 Alt← / Alt→ ⎋ 从工具窗口进入代码文件窗口 ESC ⌘L 在当前文件跳转到某一行的指定处 Ctrl + G ⌘E 显示最近打开的文件记录列表 Ctrl + E ⌘⌥← / ⌘⌥→ 退回 / 前进到上一个操作的地方 Ctrl + Alt + ← Ctrl + Alt + → ⌘⇧⌫ 跳转到最后一个编辑的地方 ⌃H 显示当前类的层次结构 Ctrl + H ⌘⇧H 显示方法层次结构 ⌃⌥H 显示调用层次结构 F4 / ⌘↓ 编辑/查看代码源 ⌘⌥U 显示类UML图 ⌃J 查看注释 编辑 ⌥⌦ 删除到单词的末尾（⌦键为Fn+Delete） ⌥⌫ 删除到单词的开头 ⌘+ / ⌘- 展开 / 折叠代码块 ⌘F1 在错误或警告处显示具体描述信息 ⌘⌥L 格式化代码 ⌃⌥O 优化import ⇧↩ 开始新的一行 ⌘⇧↩ 自动结束代码，行末自动添加分号 ⌃I 实现方法（实现接口中的方法） ⇧F6 重命名文件或者变量 ⌘N, ⌃↩, ⌃N 生成代码（getter、setter、构造函数、hashCode/equals,toString） ⌘P 显示方法的参数信息 查找 Double⇧ 查找任何东西 ⌘⇧F 全局查找（根据路径） ⌘F 文件内查找 ⌘G 查找模式下，向下查找 ⌘⇧G 查找模式下，向上查找 ⌘⌥B 跳转到接口的实现 ⌘U 查看接口定义 ⌘⌥← / ⌘⌥→ 退回 / 前进到上一个操作的地方 ⌘B / ⌘ 鼠标点击 进入光标所在的方法/变量的接口或是定义处 ⌃⇧B 跳转到类型声明处 ⌥ Space, ⌘Y 快速打开光标所在方法、类的定义 ⌘O 查找类文件 ⌘⇧O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ F12 返回到前一个工具窗口 ⎋ 从工具窗口进入代码文件窗口 ⇧⎋ 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 F3选中文件/文件夹/代码行，添加/取消书签 ⌥F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 ⌃0…⌃9 定位到对应数值的书签位置 ⌘F3 显示所有书签 ⌥F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在代码编辑窗口可以选择显示该文件的Finder) ⌘F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） 通用 ⌃⌘F 切换全屏模式","categories":[{"name":"笔记","slug":"笔记","permalink":"https://zhangyong3214.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"为MacOS打造自己炫酷终端-Iterm2+oh-my-zsh","slug":"软件工具/为MacOS打造自己炫酷终端-","date":"2022-01-27T08:31:13.128Z","updated":"2022-01-27T08:31:13.128Z","comments":true,"path":"2022/01/27/软件工具/为MacOS打造自己炫酷终端-/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E4%B8%BAMacOS%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%82%AB%E9%85%B7%E7%BB%88%E7%AB%AF-/","excerpt":"1、iTerm2 iTerm2 是一款完全免费，专为 Mac OS 用户打造多命令行应用。 安装完成后，在/bin目录下会多出一个zsh的文件。 Mac系统默认使用dash作为终端，可以使用命令修改默认使用zsh：chsh -s /bin/zsh 如果想修改回默认dash，同样使用chsh命令即可：chsh -s /bin/bash Zsh 是一款强大的虚拟终端，既是一个系统的虚拟终端，也可以作为一个脚本语言的交互解析器。","text":"1、iTerm2 iTerm2 是一款完全免费，专为 Mac OS 用户打造多命令行应用。 安装完成后，在/bin目录下会多出一个zsh的文件。 Mac系统默认使用dash作为终端，可以使用命令修改默认使用zsh：chsh -s /bin/zsh 如果想修改回默认dash，同样使用chsh命令即可：chsh -s /bin/bash Zsh 是一款强大的虚拟终端，既是一个系统的虚拟终端，也可以作为一个脚本语言的交互解析器。 1.1、iterm2 安装下载地址 1.2、iTerm操作快捷键 command + t：新建窗口 command + d：垂直分屏， command + shift + d：水平分屏。 command + ] 和command + [ 在最近使用的分屏直接切换. command + alt + 方向键：切换到指定位置的分屏。 command + 数字：切换标签页。 command + 方向键：按方向切换标签页。 shift + command + s：保存当前窗口快照。 command + alt + b：快照回放。很有意思的功能，你可以对你的操作根据时间轴进行回放。可以拖动下方的时间轴，也可以按左右方向键 1.3、创建一键登录服务器1.3.1、第一步：新建配置文件，内容：12345678set user 用户名set host IP地址set password 密码spawn ssh $user@$hostexpect &quot;*assword:*&quot;send &quot;$password\\r&quot;interactexpect eof 1.3.2、第二步：iTerm2配置添加1expect ~/.ssh/SIT02-10.231.143.184 2、Oh My ZshOh My Zsh 官网 Oh My Zsh 是一款社区驱动的命令行工具，它基于 zsh 命令行，提供了主题配置，插件机制，已经内置的便捷操作。给我们一种全新的方式使用命令行。 2.1、oh my zsh 安装2.1.1、方式11sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 2.1.2、方式21`sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot;` 2.1.3、方式3（国内推荐使用）1sh -c &quot;$(curl -fsSL https://gitee.com/pocmon/ohmyzsh/raw/master/tools/install.sh)&quot; 2.2、卸载oh my zsh1uninstall_on_my_zsh 2.3、更换主题12vi ~/.zshrcZSH_THEME=&quot;macovsky-ruby&quot; &quot;steeef&quot; 2.4、安装语法高亮插件1234# 进入文件夹cd ~/.oh-my-zsh/custom/plugins# 下载插件git clone https://github.com/zsh-users/zsh-syntax-highlighting.git 2.5、自动补全插件1git clone https://github.com/zsh-users/zsh-autosuggestions.git 2.5.1、启用插件12345vi ~/.zshrcplugins=( git zsh-autosuggestions zsh-syntax-highlighting )source ~/.zshrc","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"军事级别安全强度，免费密码管理工具KeePass，永远滴神","slug":"软件工具/免费密码管理工具KeePass永远的神","date":"2022-01-27T08:31:13.128Z","updated":"2022-01-27T08:31:13.128Z","comments":true,"path":"2022/01/27/软件工具/免费密码管理工具KeePass永远的神/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E5%85%8D%E8%B4%B9%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7KeePass%E6%B0%B8%E8%BF%9C%E7%9A%84%E7%A5%9E/","excerpt":"","text":"前言​ 欢迎大家收看本篇文章对应B站视频解说：👉 点此跳转B站视频解说教程 👈 ​ 大家好，我是喜欢科技，喜欢分享，喜欢软件，喜欢折腾，有洁癖又有强迫症的科技农名工—李苟蛋，今天我来给大家分享一款密码管理软件：KeePass。你是否有过这种经历：平均每半个月或者一个月，我们再登录某些网站或者登录某些账号的时候，发现我们的密码记不住了，用常用的密码试过几次之后，发现还是不对，干脆直接点击忘记密码，用手机验证码或者邮箱验证码找回密码更改成为我们常用的密码，如果这个网站或者这个账号我们好久没登录过，绑定的手机号还是我之前用过的手机号，可能就得通过申诉提供各种资料找回密码，那等待你的将是噩梦级别的操作，如果这个账号不太重要，我不要了也就算了，如果这个账号很重要，那此时此刻你的内心应该已经万马(羊驼)崩腾了。有些人可能喜欢把密码记录在一个特定的笔记本上面，但是如果这个笔记本丢了….丢在家里找不到还好说，万一丢在外面，那你担心的应该不是你有很多网站登录不上了，而是你的密码很可能被别人知道了；还有人喜欢把密码记录在电脑的本地记事本，或者手机的记事本里面，但是这只存在于你电脑本地或者手机本地，万一电脑重装系统，或者换手机……又是个难题，此时此刻聪明的你可能会想，那我把密码放在云笔记里面，我把这个笔记在加个打开密码，那不就好了吗？没错，我在认识KeePass之前，我就是这么做的，但是你放在云笔记里面，在加个笔记的开启密码，这种情况，你的密码就依赖了云笔记服务商的服务器，而且你把密码都放到人家的服务器上，你觉得这是安全的吗？难道你真的认为你加了一个开启密码，就没有人能看到了吗？你的开启密码的加密算法可都是人家云笔记运营商给你提供的….. ​ 现在我就来给大家隆重介绍一下今天的主角，KeePass，并详细说明它是如何解决我们上述的这些问题的。目前主流的密码管理工具主要有：KeePass（免费 开源 兼容性强），LastPass（最大的优势是跨浏览器平台，收费），1Password（跨平台管理 用户认可度高），Enpass（支持平台多 20条密码免费）。可以看出，除了KeePass，其他都是收费的，所以我们毫无悬念的选择了它，KeePass从2003年至今具有近20年的时间，而且开源免费，开源的好处就是民间大神都可以看他的源代码，只要发现安全漏洞就可以去提交评论做修复，所以安全级别是可以放心的，如果你担心有安全问题想阅读源码也可以去官方查看。 接下来就让我介绍一下如何用KeePass搭建一个可以实现云同步的密码管理工具吧。 KeePass下载及使用Keepa介绍​ KeePass不会上传你的账号密码，你的账号密码保存在你本地(数据库)，你只需要创建一个开启这个数据库的钥匙，这个钥匙非常重要，它是你能否打开软件的关键，这个钥匙可以是一串密码，也可以是一个文件，文件可以是任何文件，一部电影，一个word文档，一个txt文本，一首歌等，都可以当做开启数据库的密钥文件，或者是密码加文件的组合的方式来设置你的开启钥匙，还可以是一个实体密钥(类似于U盾)，本人推荐使用密码加文件的方式作为数据库的开启钥匙，这样，开启密码我们就不用设置的太复杂，也不用担心开启密码泄露导致我们的数据库文件被别人拿到之后被别人打开，别人能同时拿到密码和文件简直太难了。 PC端客户端KeePassXC​ KeePass官网，提供了KeePass软件的下载，官方只提供了PC端下载，不过还好，很多民间大神也做了很多支持KeePass的客户端供我们使用，官方也有推荐列表。电脑端（windows和Mac平台），我推荐使用KeePassXC，这也是支持KeePass的由非官方开发的一款软件，KeePass官方推荐列表里面有，之所以推荐它，是因为他界面美观，还有对应的浏览器插件，可以实现密码自动填充。安卓端我推荐使用KeePass2Android，这款软件下载需要上谷歌商店，可能得需要科学上网，这里我给大家提供了蓝奏云下载，方便大家下载安装，由于本人没有苹果手机，所以IPhone用户就需要小伙伴自己去官方推荐的软件里面寻找适合苹果手机的客户端了(#^.^#)~ KeePassXC使用介绍下图为我的KeePass的客户端安装配置之后的效果，怎么样，还不错吧~ 下载安装KeePass之后，我们需要设置一下我们数据库存放的本地位置，然后设置数据库开启密码，开启密钥文件，这里我推荐手动创建一个文件，后缀名随意，然后用记事本打开，在里面输入一些文章，例如你喜欢的诗词之类的，字书不要太多，尽量控制在1千字以内就行，避免文件过大，然后吧这个密钥文件好好保存起来，我建议用你常用的邮箱给自己发个邮件然后以附件的方式保存在你的邮件里面，这样他就永远不会丢了，或者放到你的云盘，NAS上面，不要把它和数据库放在一起！！！如果是Mac本支持指纹识别，输入一次密码和密钥文件之后，下次就可以通过指纹打开你的数据库了，但是这不代表你的密码和密钥文件就没用了，指纹打开数据库的原理其实就是通过指纹映射到你的密码和密钥文件，所以说，数据库开启密码和密钥文件很重要，这个一定不能丢~ 进入之后，我们就可以添加分类，然后添加账号密码等等，具体的使用方法我会出视频讲解，欢迎朋友来B站关注我。 浏览器插件使用(谷歌为例)本地软件开启相应功能​ 在KeePassXC打开设置-浏览器集成-启用浏览器集成-然后为你用的浏览器开启集成（见下图），这里墙裂建议使用谷歌浏览器，这是浏览器中的神。当然，想成为神，需要科学上网安装必要的插件才能够给谷歌浏览器注入神之灵魂，不要下载下来之后连个插件都没装就说浏览器不行，行不行得看用的人会不会用。总之，科技农民工里面应该没有几个人不用谷歌吧~ 浏览器插件下载使用​ 打开谷歌应用商店（注：这里可能需要科学上网），找到KeePassXC这个插件，安装之…. 安装之后用浏览器插件链接本地KeePassXC软件，链接之后，就可以实现网站账号密码自动填充了，需要注意的是，自动填充的时候，一定要是你本地数据库打开的情况下，这样你就可以吧浏览器的记住密码功能关闭了，不过这个自动填充功能并不一定所有网站都可以，大概百分之80的网站都没问题，还有就是想要能关联到填充项目，需要你在你添加密码的时候，把对应的URL填写成为网站的登录地址或者网站的官网。 实现数据库云同步我们的数据库只存在于我们本地肯定是不行的，这跟我直接在本地搞一个记事本保存密码也差不了多少，重装系统之后，数据库丢了，就直接回到解放前了，这里我建议使用两种工具实现数据库云同步功能，第一款是微软出品的OneDrive，这款云盘可以实现云盘映射到本地指定路径，路径中的文件发生改变，会自动同步到云端，这样我们添加或者修改了账号密码之后，数据库都会自动同步到微软的OneDrive云盘，这样我们就实现了电脑端的数据库云同步，手机端Keepass2Android，也是支持读取OneDrive云盘文件的功能的；第二款同步工具是坚果云，原理和OneDrive一样，不过坚果云要实现手机同步，需要通过WebDav功能实现，坚果云是支持云文件设置成为WebDav服务的，而且坚果云号称是国内最安全的云盘，军工级的加密方案，你的数据库放在坚果云是安全的，就算有人能拿到你的数据库，没有密码和密钥文件，也是打不开的… 尾声​ 无论使用哪种同步方案，这种同步的思路明白了，也可以试试其他的KeePass 的客户端软件，文章中介绍的都是本人认为最好的方案，也是爱折腾的我在工作之余肝了好几个晚上定下的最终方案，也请大家多多关注我的个人博客和B站，有什么问题可以加我QQ或者B站留言私信给我…谢谢大家！","categories":[{"name":"软件分享","slug":"软件分享","permalink":"https://zhangyong3214.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"吐血整理IDEA必备插件(๑•̀ㅂ•́)و✧，让撸码效率提升1000%","slug":"软件工具/吐血整理IDEA必备插件","date":"2022-01-27T08:31:13.128Z","updated":"2022-01-27T08:31:13.128Z","comments":true,"path":"2022/01/27/软件工具/吐血整理IDEA必备插件/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E5%90%90%E8%A1%80%E6%95%B4%E7%90%86IDEA%E5%BF%85%E5%A4%87%E6%8F%92%E4%BB%B6/","excerpt":"","text":"俗话说：“工欲善其事，必先利其器”，好的开发工具能让我们的工作效率翻倍，而好的开发工具加上优秀的插件，能让我们的工作效率提升十倍（(@^_^@)我要打十个），这也是我们区别于其他程序猿的必备工具，下面就是我从十余年工作中总结出来的好用的idea插件（好像工作的前五年我用的都是eclipse，哈哈(╯&gt;д&lt;)╯⁽˙³˙⁾，这不重要！）。插件主要分为：代码生成类，日常开发类，主题美化类，以下插件大都可以通过 IDEA 自带的插件管理中心安装，如果搜不到可以去 IDEA 插件官网下载本地导入。星号代表我个人的推荐指数 。 代码生成Lombok 推荐指数：★★★★★ 自动生成get、set方法 EasyCode 推荐指数：★★ 数据库逆向工程 GsonFormat 推荐指数：★★★★ 通过json生成实体类 Codota 推荐指数：★★★★★ 代码提示 该插件的强大之处在于： 支持智能代码自动提示，该功能可以增强 IDEA 的代码提示功能； 支持 JDK 和知名第三方库的函数的使用方法搜索，可以看到其他知名开源项目对该函数的用法。 当我们第一次使用某个类，对某个函数不够熟悉时，可以通过该插件搜索相关用法，快速模仿学习，使用方法：右键要搜索的类，选择 Get relevant exanples GenerateAllSetter 推荐指数：★★★★★ 变量自动生成set方法 插件官网地址 。我们定义好从 A 类转换到 B 类的函数转换函数后，使用这两个插件可以自动调用 Getter 和 Setter 函数实行自动转换。实际开发中还有一个非常常见的场景：我们创建一个对象后，想依次调用 Setter 函数对属性赋值，如果属性较多很容易遗漏或者重复。可以使用GenerateAllSetter 提供的功能，自动调用所有 Setter 函数（可填充默认值），然后自己再跟进实际需求设置属性值。 .ignore 推荐指数：★★★★ git提交时过滤掉不需要提交的文件，很方便，有些本地文件是不需要提交到Git上的，插件：ProjectView涵盖了此功能 CamelCase 推荐指数：★★★★ 将不是驼峰格式的名称，快速转成驼峰格式，安装好后，选中要修改的名称，按快捷键shift+alt+u。 代码规范Alibaba Java Coding Guidelines 推荐指数：★★★ 插件功能：代码规范插件 jclasslib bytecode viewer 推荐指数：★★★ 插件功能：可视化的字节码查看插件 使用方法： 在 IDEA 打开想研究的类； 编译该类或者直接编译整个项目（ 如果想研究的类在 jar 包中，此步可略过）； 打开“view” 菜单，选择“Show Bytecode With jclasslib” 选项； 选择上述菜单项后 IDEA 中会弹出 jclasslib 工具窗口。 那么有自带的强大的反汇编工具 javap 还有必要用这个插件吗？ 这个插件的强大之处在于： 不需要敲命令，简单直接，在右侧方便和源代码进行对比学习； 字节码命令支持超链接，点击其中的虚拟机指令即可跳转到 jvms 相关章节，超级方便。 该插件对我们学习虚拟机指令有极大的帮助。 FindBugs 推荐指数：★★ 插件功能：查找代码bug 程序员总是想尽可能地避免写 BUG， FindBugs 作为静态代码检查插件，可以检查你代码中的隐患，并给出原因。 SonarLine 推荐指数：★★ 插件功能：代码质量管理工具 日常开发Translation 推荐指数：★★★★ 插件功能：翻译 Jrebel 推荐指数：★★★ 插件功能：热部署 Key Promoter X 推荐指数：★★ 插件功能：快捷键提示 MyBatis Log Plugin 推荐指数：★★★★★ 插件功能：打印sql MyBatisX 推荐指数：★★★★★ 插件功能：Mapper跳转Dao Maven Search 推荐指数：★★★★ 插件功能：查询maven Maven Helper 推荐指数：★★★★★ 插件功能：依赖关系图 安装后 IDEA 中打开 pom.xml 文件时，就会多出一个 “Dependency Analyzer” 选项卡。 SequenceDiagram 推荐指数：★★★★ 插件功能：时序图 SequenceDiagram 可以根据代码调用链路自动生成时序图，超级赞，超级推荐！这对研究源码，梳理工作中的业务代码有极大的帮助，堪称神器。安装完成后，在某个类的某个函数中，右键 –&gt; Sequence Diagaram 即可调出。 主题美化Active power mode 推荐指数：★★ 插件功能：打字特效 Rainbow Branckets 推荐指数：★★★ 插件功能：彩虹扩号 插件github地址 。由于很多人没有养成好的编码风格，没有随手 format 代码的习惯，甚至有些同事会写代码超过几百行，阅读起来将非常痛苦。痛苦的原因之一就是找到上下文，由于括号太多，不确定当前代码行是否属于某个代码块，此时这个插件就会帮上大忙。双击顶部的类名可以跳转到对应类的源码中，双击调用的函数名可以直接调入某个函数的源码，总之非常强大。 CodeGlance 推荐指数：★★★ 插件功能：代码迷你小地图 类似于sublime的右侧代码小地图，CodeGlance2为原版加强 Xcode Drak theme 推荐指数：★ 插件功能：主题 Material Theme UI 推荐指数：★ 插件功能：多种主题 对于很多人而言，写代码时略显枯燥的，如果能够安装自己喜欢的主题将为开发工作带来些许乐趣。IDEA 支持各种主题插件，其中最出名的当属 Material Theme UI。安装后，可以从该插件内置的各种风格个选择自己最喜欢的一种。","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}]},{"title":"面试知识点总结","slug":"面试基地/常见面试题","date":"2022-01-27T08:31:13.128Z","updated":"2022-01-27T08:31:13.129Z","comments":true,"path":"2022/01/27/面试基地/常见面试题/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E9%9D%A2%E8%AF%95%E5%9F%BA%E5%9C%B0/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"基础知识面向对象的特征?面向对象的特征:封装、继承、多态、抽象。 封装:就是把对象的属性和行为(数据)结合为一个独立的整体，并尽可能隐藏对象的内 部实现细节，就是把不想告诉或者不该告诉别人的东西隐藏起来，把可以告诉别人的公开，别人只能用我提供的功能实现需求，而不知道是如何实现的。增加安全性。 继承:子类继承父类的数据属性和行为，并能根据自己的需求扩展出新的行为，提高了代 码的复用性。 多态:指允许不同的对象对同一消息做出相应。即同一消息可以根据发送对象的不同而采 用多种不同的行为方式(发送消息就是函数调用)。封装和继承几乎都是为多态而准备 的，在执行期间判断引用对象的实际类型，根据其实际的类型调用其相应的方法。 抽象:表示对问题领域进行分析、设计中得出的抽象的概念，是对一系列看上去不同，但是本质上相同的具体概念的抽象。在 Java 中抽象用 abstract 关键字来修饰，用abstract修饰类时，此类就不能被实例化，从这里可以看出，抽象类(接口)就是为了继承而存在的。 常见的RuntimeException java.lang.NullPointerException 空指针异常;出现原因:调用了未经初始化的对象或者是不存在 的对象。 java.lang.ClassNotFoundException 指定的类找不到;出现原因:类的名称和路径加载错误;通常 都是程序试图通过字符串来加载某个类时可能引发异常。 java.lang.NumberFormatException 字符串转换为数字异常;出现原因:字符型数据中包含非数 字型字符。 java.lang.IndexOutOfBoundsException 数组角标越界异常，常见于操作数组对象时发生。 java.lang.IllegalArgumentException 方法传递参数错误。 java.lang.ClassCastException 数据类型转换异常。 java.lang.NoClassDefFoundException 未找到类定义错误。 SQLException SQL 异常，常见于操作数据库时的 SQL 语句错误。 java.lang.InstantiationException实例化异常。 java.lang.NoSuchMethodException方法不存在异常。 常见的引用类型java的引用类型一般分为四种：强引用、软引用、弱引用、虚引用 强引用：普通的变量引用 软引用：将对象用SoftReference软引用类型的对象包裹，正常情况不会被回收，但是GC做完后发现释放不出空间存放新的对象，则会把这些软引用的对象回收掉。软引用可用来实现内存敏感的高速缓存。 弱引用：将对象用WeakReference软引用类型的对象包裹，弱引用跟没引用差不多，GC会直接回收掉，很少用 虚引用：虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系，几乎不用 JVMjvm内存模型 对象创建过程 类加载检查：虚拟机遇到一条new指令时，首先将去检查这个类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程：类加载过程中会通过jvm自带的三个类加载器按照双亲委派机制进行类加载过程，我们常见的ClassNotFoundException就是在这里发生的，我们代码中的静态代码块里面的内容也是在这个过程中执行的。 分配内存：在类加载检查通过后，虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把 一块确定大小的内存从Java堆中划分出来。 初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 设置对象头：初始化零值之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息(即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例)、对象的哈希码（HashCode）、对象的GC分代年龄、锁状态标志等信息。这些信息存放在对象的对象头Object Header之中。 执行方法：执行方法，即对象按照程序员的意愿进行初始化。对应到语言层面上讲，就是为属性赋值（注意，这与上面的赋零值不同，这是由程序员赋的值），和执行构造方法。 垃圾回收算法 引用计数法 可达性分析法 对于可达性分析法，我们知道需要存在一个GC Root的对象作为起点，从这个节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（就是从GC Roots到对象不可达）时，则证明此对象是不可用的。 GC Root有哪些？ 虚拟机栈中的引用对象 方法区中类静态属性引用的对象 方法区中常量引用对象 本地方法栈中JNI引用对象 垃圾回收器有哪些？ Serial收集器(-XX:+UseSerialGC -XX:+UseSerialOldGC)：Serial（串行）收集器是一个单线程收集器，新生代采用复制算法，老年代采用标记-整理算法。 Parallel Scavenge收集器(-XX:+UseParallelGC(年轻代),-XX:+UseParallelOldGC(老年代)) ：Parallel收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器类似。默认的收集线程数跟cpu核数相同 ParNew收集器(-XX:+UseParNewGC)：只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作 CMS收集器(-XX:+UseConcMarkSweepGC(old))：收集器是一种以获取最短回收停顿时间为目标的收集器CMS收集器是一种 “标记-清除”算法实现的。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 G1收集器(-XX:+UseG1GC)：G1 (Garbage-First)是一款面向服务器的垃圾收集器，主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。G1将Java堆划分为多个大小相等的独立区域（Region），JVM最多可以有2048个Region。一般Region大小等于堆大小除以2048，比如堆大小为4096M，则Region大小为2M Shenandoah：可以看成是G1升级版 ZGC收集器：ZGC是一款JDK 11中新加入的具有实验性质的低延迟垃圾收集器。1、支持TB量级的堆；2、最大GC停顿时间不超10ms；3、奠定未来GC特性的基础；4、最糟糕的情况下吞吐量会降低15% CMS运行过程，缺点？整个过程分为四个步骤 初始标记(STW)： 暂停所有的其他线程(STW)，并记录下gc roots直接能引用的对象，速度很快 并发标记： 并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程， 这个过程耗时较长但是不需要停顿用户线程，因为用户程序继续运行，可能会有导致已经标记过的对象状态发生改变。 重新标记(STW)： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。 并发清理： 开启用户线程，同时GC线程开始对未标记的区域做清扫。 并发重置：重置本次GC过程中的标记数据。 缺点： 对CPU资源敏感（会和服务抢资源） 无法处理浮动垃圾(在并发标记和并发清理阶段又产生垃圾，这种浮动垃圾只能等到下一次gc再清理了)； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生，当然通过参数-XX:+UseCMSCompactAtFullCollection可以让jvm在执行完标记清除后再做整理 并发模式失败(最大问题)，执行过程中的不确定性，会存在上一次垃圾回收还没执行完，然后垃圾回收又被触发的情况，特别是在并发标记和并发清理阶段会出现，一边回收，系统一边运行，也许没回收完就再次触发full gc，也就是”concurrent mode failure”，此时会进入stop the world，用serial old垃圾收集器来回收 G1运行过程G1收集器一次GC的运作过程大致分为以下几个步骤： 初始标记（initial mark，STW）：暂停所有的其他线程，并记录下gc roots直接能引用的对象，速度很快 ； 并发标记（Concurrent Marking）：同CMS的并发标记 最终标记（Remark，STW）：同CMS的重新标记 筛选回收（Cleanup，STW）：G1采用复制算法回收几乎不会有太多内存碎片 G1适合什么场景 50%以上的堆被存活对象占用 对象分配和晋升的速度变化非常大 垃圾回收时间特别长，超过1秒 8GB以上的堆内存(建议值) 停顿时间是500ms以内 判断元空间是无用的类法区（元空间）主要回收的是无用的类，那么如何判断一个类是无用的类呢？类需要同时满足下面3个条件才能算是 “无用的类” ： 该类所有的对象实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。（条件苛刻，自定义类加载器会被回收掉） 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 安全点和安全区域安全点：就是指代码中一些特定的位置,当线程运行到这些位置时它的状态是确定的,这样JVM就可以安全的进行一些操作,比如GC等，所以GC不是想什么时候做就立即触发的，是需要等待所有线程运行到安全点后才能触发。这些特定的安全点位置主要有以下几种: 方法返回之前 调用某个方法之后 抛出异常的位置 循环的末尾 安全区域：如果一个线程处于 Sleep 或中断状态，它就不能响应 JVM 的中断请求，引用关系不会发生变化。在这个区域内的任意地方开始 GC 都是安全的。 类加载器？双亲委派，好处？JDK自带有三个类加载器：bootstrapClassLoader(引导类加载器)、ExtClassLoader(扩展类加载器)、AppClassLoader(系统类加载器)，bootstrapClassLoader是ExtClassLoader的父类加载器(并不是集成关系，是属性关系)默认加载%JAVA_HOME%/lib下的jar包和class文件ExtClassLoader是AppClassLoader的父类加载器，默认加载%JAVA_HOME%/lib/ext文件夹下的jar包和class文件AppClassLoader是自定义类加载器，负责加载classpath下的类文件 双亲委派：分为向上委派和向下查找，每一个类加载器都有各自的缓存，都会记录自己加载过的类，当一个类需要加载，AppClassLoader先查找自己的缓存有没有加载过这个类，没有加载过就会调用ExtClassLoader去查找，ExtClassLoader没有加载过，就会调用bootstrapClassLoader类去加载，如果bootstrapClassLoader没有加载过，就会去他的类加载路径查找，如果没有找到ExtClassLoader就会查找他的类加载路径，向上委派就是查找缓存，查找到bootstrapClassLoader位置，向下查找就是查找类加载路径，查找到发起的类加载器为止。 好处：1、安全性，避免自己写的类替换掉java核心类；2、避免类重复加载，相同class文件不同的类加载器加载的也是两个类。 YGC和FGC发生的场景YGC：对新生代堆进行gc。频率比较高，因为大部分对象的存活寿命较短，在新生代里被回收。性能耗费较小。edn空间不足,执行 FGC：全堆范围的gc。默认堆空间使用到达80%(可调整)的时候会触发fgc。生产环境，一般比较少会触发fgc，有时10天或一周左右会有一次。 老年代空间不足，永久区空间不足，调用方法System.gc() ，ygc时的悲观策略, dump live的内存信息时(jmap –dump:live)，都会执行full gc jstack，jmap，Jstat作用jmap：可以用来查看内存信息，实例个数以及占用内存大小 jmap -heap 进程号：查看堆内存信息 jmap ‐dump:format=b,file=eureka.hprof 进程号： 堆内存的快照信息，添加jvm参数也可以设置内存溢出自动导出dump文件 jstack: 可以获得java线程的运行情况，可以查看死锁，阻塞，等待 Jstack -l PID &gt;&gt; 123.txt 打印某个java进程的堆栈信息 Jstat：jstat命令可以查看堆内存各部分的使用量，以及加载类的数量 jstat -gc pid 最常用，可以评估程序内存使用及GC压力整体情况 多线程死锁 死锁：是指一组互相竞争资源的线程，因为互相等待，导致永久阻塞的现象。 原因：必须同时满足以下四个条件 共享互斥条件：共享资源x和y只能被一个线程占用 占有且等待：线程t1已经占有共享资源x，在等待共享资源y的时候不释放共享资源x 不可抢占：其他线程不能强行抢占线程t1占有的资源 循环等待：线程t1等待线程t2占有的资源，线程t2等待线程t1占有的资源 如何避免死锁： 既然产生死锁必然满足四个条件，那我们只要打破四个条件中的一个就可以避免，第一个互斥条件是无法被破坏的，因为锁本身就是通过互斥来解决线程安全的 针对后三个条件，我们逐一分析，占有且等待这个条件我们可以一次性申请所有资源，不存在等待； 不可抢占这个条件：占有部分资源的线程进一步申请其他资源的时候如果申请不到，可以主动释放已占有的资源，这样不可抢占这条件就破坏了； 循环等待这个条件：可以按照顺序去申请资源进行预防，就是说资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，线性化之后，就不存在循环等待了 sleep和wait区别 sleep 是 Thread 类的静态本地方法，wait 则是 Object 类的本地方法 sleep方法不会释放锁，但是wait会释放，而且会加入到等待队列中 sleep方法不依赖于同步器synchronized，但是wait需要依赖synchronized关键字 sleep不需要被唤醒（休眠之后推出阻塞），但是wait需要（不指定时间需要被别人中断） sleep 一般用于当前线程休眠，或者轮循暂停操作，wait 则多用于多线程之间的通信 sleep 会让出 CPU 执行时间且强制上下文切换，而 wait 则不一定，wait 后可能还是有机会重新竞争到锁继续执行的。 sleep就是把cpu的执行资格和执行权释放出去，不再运行此线程，当定时时间结束再取回cpu资源，参与cpu的调度，获取到cpu资源后就可以继续运行了。而如果sleep时该线程有锁，那么sleep不会释放这个锁，而是把锁带着进入了冻结状态，也就是说其他需要这个锁的线程根本不可能获取到这个锁。也就是说无法执行程序。如果在睡眠期间其他线程调用了这个线程的interrupt方法，那么这个线程也会抛出interruptexception异常返回，这点和wait是一样的。 当我们调用wait（）方法后，线程会放到等待池当中，等待池的线程是不会去竞争同步锁。只有调用了notify（）或notifyAll()后等待池的线程才会开始去竞争锁，notify（）是随机从等待池选出一个线程放到锁池，而notifyAll()是将等待池的所有线程放到锁池当中 Volitile作用 可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。内存屏障-&gt;汇编Lock关键字-&gt;缓存一致性协议 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性 有序性：对volatile修饰的变量的读写操作前后加上各种特定的内存屏障来禁止指令重排序来保障有序性 Volitile如何保证可见性 缓存一致性：在共享内存多处理器系统中，每个处理器都有一个单独的缓存内存，共享数据在主内存和各处理器私有缓存同时存在。当数据的一个副本发生更改，其他副本需要感知到最新修改数据。缓存一致性的手段主要有： 总线锁定：总线锁定就是使用处理器提供的一个 LOCK＃信号，当其中一个处理器在总线上输出此信号时，其它处理器的请求将被阻塞，那么该处理器可以独占共享内存。 总线窥探(Bus snooping)：是缓存中的一致性控制器窥探总线事务的一种方案（该方案由Ravishankar和Goodman于1983年提出）当数据被多个缓存共享时，一个处理器修改了共享数据的值，可以是刷新缓存块或使缓存块失效还可以通过缓存块状态的改变，来达到缓存一致性的目的，主要取决于窥探协议类型： 写失效（Write-invalidate） ：当一个处理器写入共享缓存时，其他缓存中的所有共享副本都会通过总线窥探失效。确保处理器只能读写一个数据副本，其他缓存中的所有其他副本都无效。这是最常用的窥探协议。MSI、MESI、MOSI、MOESI和MESIF协议属于该类型。 写更新（Write-update）：当处理器写入一个共享缓存块时，其他缓存的所有共享副本都会通过总线窥探更新。这个方法将写数据广播到总线上的所有缓存中。它比写失效协议引起更大的总线流量，因此这种方法不常见。Dragon和firefly协议属于此类别。 指令重排序Java语言规范规定JVM线程内部维持顺序化语义，即只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。指令重排序的意义：：JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性能。 Java线程的生命周期 NEW（初始化状态） RUNNABLE（可运行状态+运行状态） BLOCKED（阻塞状态） WAITING（无时限等待） TIMED_WAITING（有时限等待） TERMINATED（终止状态） 在操作系统层面，有五种状态，Java 线程中的 BLOCKED、WAITING、TIMED_WAITING 是一种状态，即前面我们提到的休眠状态。也就是说只要 Java 线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权。 linux查看线程命令 ps - fe 查看所有进程 ps - fT - p 查看某个进程（ PID ）的所有线程 kill 杀死进程 top 按大写 H 切换是否显示线程 top - H - p 查看某个进程（ PID ）的所有线程 jps 命令查看所有 Java 进程 jstack 查看某个 Java 进程（ PID ）的所有线程状态 jconsole 来查看某个 Java 进程中线程的运行情况（图形界面） Java线程的实现方式 方式1：使用 Thread类或继承Thread类 实现 Runnable 接口配合Thread 使用有返回值的 Callable，借助线程池使用 使用 lambda 本质上Java中实现线程只有一种方式，都是通过new Thread()创建线程，调用Thread#start启动线程最终都会调用Thread#run方法 Thread常用方法sleep方法 调用 sleep 会让当前线程从 Running 进入TIMED_WAITING状态，不会释放对象锁 其它线程可以使用 interrupt 方法打断正在睡眠的线程，这时 sleep 方法会抛出InterruptedException，并且会清除中断标志 睡眠结束后的线程未必会立刻得到执行 sleep当传入参数为0时，和yield相同 yield方法 yield会释放CPU资源，让当前线程从 Running 进入 Runnable状态，让优先级更高（至少是相同）的线程获得执行机会，不会释放对象锁； 假设当前进程只有main线程，当调用yield之后，main线程会继续运行，因为没有比它优先级更高的线程； 具体的实现依赖于操作系统的任务调度器 ThreadLocal的实现原理ThreadLocal的实现原理，每一个Thread维护一个ThreadLocalMap，key为使用弱引用的ThreadLocal实例，value为线程变量的副本 ThreadLocal应用场景 在进行对象跨层传递的时候，使用ThreadLocal可以避免多次传递，打破层次间的约束。 线程间数据隔离 进行事务操作，用于存储线程事务信息。 数据库连接，Session会话管理。 Spring框架在事务开始时会给当前线程绑定一个Jdbc Connection,在整个事务过程都是使用该线程绑定的connection来执行数据库操作，实现了事务的隔离性。Spring框架里面就是用的ThreadLocal来实现这种隔离 ThreadLocal内存泄露原因，如何避免 强引用：使用最普遍的引用(new)，一个对象具有强引用，不会被垃圾回收器回收。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不回收这种对象。 弱引用：JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。在java中，用java.lang.ref.WeakReference类来表示。可以在缓存中使用弱引用。 ThreadLocal正确的使用方法 每次使用完ThreadLocal都调用它的remove()方法清除数据 将ThreadLocal变量定义成private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉 。 synchronized和ReentranLock区别？synchronized是jvm层面的关键字，底层是通过monitor对象来完成，monitor对象底层依赖于操作系统的Mutex互斥量，底层调用的是操作系统的Pthread库，是由操作系统来维护的，而操作系统分为用户空间和内核空间的，JVM运行在用户空间，调用底层操作系统cpu会进行一轮状态切换，这个状态切换是比较重型操作，wait/notify等方法也依赖monitor对象只有在同步块或方法中才能调wait/notify等方法。 Lock是具体类（java.util.concurrent.Locks.Lock)是api层面的锁，是从jdk1.5开始引入的，那个时候synchronized性能还比较差，ReentranLock的出现是为了解决当时性能差的问题 使用方法：synchronized不需要手动释放锁，ReentranLock则需要用户手动释放锁(需要lock()和unlock()配合try/finally使用) 等待是否可中断：synchronized不可中断，除非抛出异常或者执行完成，ReentranLock可中断 设置超时方法tryLock(long timeout, timeUnit unit) lockInterruptibly()放代码块忠，调用interrupt()方法可中断 加锁是否公平：synchronized非公平锁；ReentranLock 两者都可以，默认非公平锁，构造方法传入true为公平锁，false为非公平锁 锁绑定多个条件Condition：synchronized 没有；ReentranLock 用来实现分组唤醒需要唤醒的线程，可以精确唤醒，不像synchronized要么随机唤醒一个线程，要么全部唤醒 线程池参数有，核心线程配置，原因？ corePoolSize：线程池中的核心线程数 maximumPoolSize：线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务 keepAliveTime：核心线程外的线程存活超时时间 unit：时间单位 workQueue：用来保存等待被执行的任务的阻塞队列，且任务必须实现Runable接口 threadFactory：用来创建新线程 线程池的饱和策略：( AbortPolicy：直接抛出异常，默认策略；CallerRunsPolicy：用调用者所在的线程来执行任务；DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；DiscardPolicy：直接丢弃任务) CPU密集型（CPU-bound） CPU密集型也叫计算密集型，在多重程序系统中，大部份时间用来做计算、逻辑判断等CPU动作的程序称之CPU bound。例如一个计算圆周率至小数点一千位以下的程序，在执行的过程当中绝大部份时间用在三角函数和开根号的计算，便是属于CPU bound的程序。 线程数 = CPU核数+1 (现代CPU支持超线程) IO密集型（I/O bound） IO密集型指的是系统的CPU性能相对硬盘、内存要好很多，此时，系统运作，大部分的状况是CPU在等I/O (硬盘/内存) 的读/写操作 线程数 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目 集合Set,List,Map有什么区别 结构特点 List 和 Set 是存储单列数据的集合， Map 是存储键和值这样的双列数据的集合; List中存储的数据是有顺序，并且允许重复; Map 中存储的数据是没有顺序的，其键是不能重复的，它的值是可以有重复的， Set 中存储的数据是无序的，且不允许有重复，但元素在集合中的位置由元素的hashcode决定，位置是固定的(Set集合根据 hashcode 来进行数据的存储，所以位置是固定的，但是位置不是用户可以控制的，所以对于用户来说 set 中的元素还是无序的); HashMap和HashTable有什么区别？区别： HashMap方法没有synchronized修饰，线程非安全，HashTable线程安全； HashMap允许key和value为null，而HashTable不允许 HashMap底层实现 jdk1.7底层采用的是数组+链表实现；jdk1.8底层采用数组+链表+红黑树实现，相对于1.7提升了查询的性能 链表过度到红黑树的阈值为8，红黑树退化为链表的阈值是6，原因在源码中332行给了明确解释(Poisson distribution)泊松分布，这是数学里面类似于正态分布的一个问题，这是统计学里面的一些东西 HashMap初始化的数组长度为16(算法导论中的除法散列法讲到 K取模m得到一个对应的位置，根据具体位置插入一个数据值，假如长度是16，长度范围就是015，取模之后我的余数为015之间，而算法导论中指出，一个不太接近2的整数幂的素数（质数：只能被1和它本身整出的数），常常是m的最好选择。但是hashMap中未采用素数，而是采用2的n次方(合数)作为数组长度)，原因为：1、更便于位置计算；2、方便做数据迁移。 为了保证存入的数据均匀的散列分布在数组中，需要设计良好的hash散列算法(hashMap中采用扰动函数来做的：移位和异或相关操作ConcurrentHashMap源码中684行spread方法，即：让int的高16位异或它本身)，尽可能的避免hash冲突(概率问题)，具体落到数组哪个节点并非是通过取模运算得出，而是通过与上数组长度-1即可(只需要int类型数32位的后四位参与运算)，即可得到0~15之间的数，因为取模运算效率远低于位运算，所以这也是hashMap要求底层数组长度必须为2的n次方的原因之一（ConcurrentHashMap源码中514行规定）。 HashMap put流程 HashMap/ConcurrentHashMap 并不是通过构造函数创建默认空间的，而是通过put数据的时候获取到对应的数据空间的，如果数组长度是0，则通过CAS操作后初始化数组，如果有线程正在做初始化数组操作，其他线程则让出时间片 HashMap扩容流程 hashMap规定了当我的数组快放满的时候就要开始扩容了，什么时候算是快放满？HashMap是通过扩容因子来规定的 HashMap规定扩容因子是0.75，如果默认长度是16，也就是说当HashMap底层数组的容量达到12的时候进行扩容操作。0.75则是根据统计学得来的。private static final float LOAD_FACTOR = 0.75f; 扩容首先要创建新的数组（原来大小左移1位）ConcurrentHaspMap源码2367行开始扩容操作 转移旧数据到新的数组中去（怎么计算扩容后数据下标位置？）原来：h&amp;(n-1)计算下标位置，扩容后 h$(31)，原来占用4个二进制位，扩容后占用5个二进制位，所以只需要看第五位即可，如果第五位是0，扩容后的的下标跟原位置一样，如果是1，新下标位置在原数组的位置的基础上加上原来数组长度即可，这也是数组长度采用2的N次方扩容的第二个原因 假设原来长度是128，扩容后是256，整体扩容方式是通过多线程方式运行的，但是要保证数据不能乱，将原来数组分段，规定每个线程最少负责16个桶的迁移工作，8个线程可以并行执行，如果小于16个桶，直接单线程执行 为什么选择用红黑树二叉树在极端情况下会退化为链表，查询时间复杂度跟链表相似，而AVL树，SB树，红黑树，都属于平衡二叉树，尽量保持左子树和右子树的高度差不要相差太大，而这三种树的差别就在于左树和右树的高度规则不同。 AVL树：严格意义平衡树，的要求左子树和右子树的高度差不能超过1，损失了部分插入性能，带来了高效的查询 SB树： 红黑树：要求最长子树不能超过最短子树的2倍即可，损失了部分查询性能，使得查询效率高于链表的同时，相比于其他树提升了插入性能，尽量做到了插入和查询的一个平衡点，而HashMap则是查多，插入少(这里的插入指的是产生Hash冲突下的插入)，所以红黑树更适合HashMap来做底层的存储结构。 ConcurrentHaspMap ConcurrentHaspMap是线程安全的HashMap，它底层采用大量的CAS操作 springspring是一个框架，更像是一个生态环境，在我们的开发流程中，所有的框架基本上都依赖于spring，spring起到了一个IOC容器的作用，用来承载我们整体的bean对象，它帮我们处理了bean对象从创建到销毁的整个生命周期的管理，我们在使用spring的时候，可以使用配置文件，也可以使用注解的方式进行相关开发。spring框架的工作主要流程是，当我们程序开始启动之后，spring把注解或者配置文件定义好的bean对象转化成为BeanDefinitionran，然后通BeanFactoryPostProcessor完成整个的BeanDefinitionran的解析和加载过程，然后根据BeanDefinitionran通过反射的方式创建bean对象，然后进行对象初始化，包括：aware接口相关操作，BeanPostProcessor操作，Init-methord操作完成整个bean的创建过程，之后我们就可以使用了。 Bean的初始化过程 Bean的生命周期 循环依赖AOP的顺序 spring4和spring5是不一样的 springMVC处理请求流程 spring事务的传播机制 TransactionDefinition.PROPAGATION_REQUIRED：支持当前事务，如果没有事务会创建一个新的事务 TransactionDefinition.PROPAGATION_SUPPORTS：支持当前事务，如果没有事务的话以非事务方式执行 TransactionDefinition.PROPAGATION_MANDATORY：支持当前事务，如果没有事务抛出异常 TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务并挂起当前事务 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式执行，如果当前存在事务则将当前事务挂起 TransactionDefinition.PROPAGATION_NEVER：以非事务方式进行，如果存在事务则抛出异常 TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 RPC框架你知道的json序列化方式？ 谷歌的Gson json-smart：号称是速度最快的JSON解析器 Common Lang3(3.1)的SerializationUtils 阿里巴巴的 FastJson、以及 Jackson 两个系统之间怎么交互的？ 套接字（socket）：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。 可以通过RPC框架（dubbo、feign等）进行远程调用 也可以引入消息队列等消息中间件作为系统之间信息交互的桥梁 共享内存（shared memory）：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更 dubbo的序列化？dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。 hessian 是其默认的序列化协议 网络网络七层模型 第一层：物理层 第二层：数据链路层 802.2、802.3ATM、HDLC、FRAME RELAY 第三层：网络层 IP、IPX、ARP、APPLETALK、ICMP 第四层：传输层 TCP、UDP、SPX 第五层：会话层 RPC、SQL、NFS 、X WINDOWS、ASP 第六层：表示层 ASCLL、PICT、TIFF、JPEG、 MIDI、MPEG 第七层：应用层 HTTP,FTP,SNMP等 物理层：物理层负责最后将信息编码成电流脉冲或其它信号用于网上传输； 数据链路层：数据链路层通过物理网络链路􏰁供数据传输。不同的数据链路层定义了不同的网络和协 议特征,其中包括物理编址、网络拓扑结构、错误校验、数据帧序列以及流控。可以简单的理解为：规定了0和1的分包形式，确定了网络数据包的形式； 网络层：网络层负责在源和终点之间建立连接。可以理解为，此处需要确定计算机的位置，怎么确定？IPv4，IPv6！ 传输层：传输层向高层提供可靠的端到端的网络数据流服务。可以理解为：每一个应用程序都会在网卡注册一个端口号，该层就是端口与端口的通信！常用的（TCP／IP）协议； 会话层：会话层建立、管理和终止表示层与实体之间的通信会话；建立一个连接（自动的手机信息、自动的网络寻址）; 表示层：表示层提供多种功能用于应用层数据编码和转化,以确保以一个系统应用层发送的信息 可以被另一个系统应用层识别;可以理解为：解决不同系统之间的通信，eg：Linux下的QQ和Windows下的QQ可以通信； 应用层：OSI 的应用层协议包括文件的传输、访问及管理协议(FTAM) ,以及文件虚拟终端协议(VIP)和公用管理系统信息(CMIP)等; http1.0和http1.1区别HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在： 缓存处理，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 错误通知的管理，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 Host头处理，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。 长连接，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。 HTTPS与HTTP的一些区别 HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。 HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。 HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。 http三次握手四次挥手其实这么说是不太准确的，应该说是tcp协议建立连接要3次握手，断开连接要4次挥手，而http是基于tcp协议的，所以通常我们也这么说，tcp可以提供全双工的数据流传输服务 三次握手 TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了LISTEN（监听）状态； TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。 TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。 TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。 四次挥手Dubbo 提供者(Provider)启动时，会向注册中心写入自己的元数据信息(调用方式)。 消费者(Consumer)启动时，也会在注册中心写入自己的元数据信息，并且订阅服务提供者，路由和配置元数据的信息。 服务治理中心(duubo-admin)启动时，会同时订阅所有消费者，提供者，路由和配置元数据的信息。 当提供者离开或者新提供者加入时，注册中心发现变化会通知消费者和服务治理中心。 NettyNIO三大核心组件 Channel(通道)， Buffer(缓冲区)，Selector(多路复用器) channel 类似于流，每个 channel 对应一个 buffer缓冲区，buffer 底层就是个数组 channel 会注册到 selector 上，由 selector 根据 channel 读写事件的发生将其交由某个空闲的线程处理 NIO 的 Buffer 和 channel 都是既可以读也可以写 Netty线程模型Netty通过Reactor模型基于多路复用器接收并处理用户请求，内部实现boss和work两个线程池，其中boss的线程负责处理请求的accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read和write事件，交由对应的Handler处理。 Netty 抽象出两组线程池BossGroup和WorkerGroup，BossGroup专门负责接收客户端的连接, WorkerGroup专门负责网络的读写 BossGroup和WorkerGroup类型都是NioEventLoopGroup NioEventLoopGroup 相当于一个事件循环线程组, 这个组中含有多个事件循环线程 ， 每一个事件循环线程是NioEventLoop 每个NioEventLoop都有一个selector , 用于监听注册在其上的socketChannel的网络通讯 每个BossNioEventLoop线程内部循环执行的步骤有 3 步 处理accept事件 , 与client 建立连接 , 生成 NioSocketChannel 将NioSocketChannel注册到某个worker NIOEventLoop上的selector 处理任务队列的任务 ， 即runAllTasks 每个workerNIOEventLoop线程循环执行的步骤 轮询注册到自己selector上的所有NioSocketChannel 的read, write事件 处理 I/O 事件， 即read , write 事件， 在对应NioSocketChannel 处理业务 runAllTasks处理任务队列TaskQueue的任务 ，一些耗时的业务处理一般可以放入TaskQueue中慢慢处理，这样不影响数据在 pipeline 中的流动处理 Netty模块组件 Bootstrap、ServerBootstrap：Bootstrap 意思是引导，一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组件，Netty 中 Bootstrap 类是客户端程序的启动引导类，ServerBootstrap 是服务端启动引导类。 Future、ChannelFuture：正如前面介绍，在 Netty 中所有的 IO 操作都是异步的，不能立刻得知消息是否被正确处理。但是可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 Future 和 ChannelFutures，他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件。 Channel：Netty 网络通信的组件，能够用于执行网络 I/O 操作。Channel 为用户提供： 当前网络连接的通道的状态（例如是否打开？是否已连接？） 网络连接的配置参数 （例如接收缓冲区大小） 提供异步的网络 I/O 操作(如建立连接，读写，绑定端口)，异步调用意味着任何 I/O 调用都将立即返回，并且不保证在调用结束时所请求的 I/O 操作已完成。 调用立即返回一个 ChannelFuture 实例，通过注册监听器到 ChannelFuture 上，可以 I/O 操作成功、失败或取消时回调通知调用方。 支持关联 I/O 操作与对应的处理程序。 不同协议、不同的阻塞类型的连接都有不同的 Channel 类型与之对应。 NioSocketChannel，异步的客户端 TCP Socket 连接。 NioServerSocketChannel，异步的服务器端 TCP Socket 连接。 NioDatagramChannel，异步的 UDP 连接。 NioSctpChannel，异步的客户端 Sctp 连接。 NioSctpServerChannel，异步的 Sctp 服务器端连接。 这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。 Selector：Netty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询(Select) 这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel 。 NioEventLoop：NioEventLoop 中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用 NioEventLoop 的 run 方法，执行 I/O 任务和非 I/O 任务：I/O 任务，即 selectionKey 中 ready 的事件，如 accept、connect、read、write 等，由 processSelectedKeys 方法触发。非 IO 任务，添加到 taskQueue 中的任务，如 register0、bind0 等任务，由 runAllTasks 方法触发。 NioEventLoopGroup：NioEventLoopGroup，主要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件，而一个 Channel 只对应于一个线程。 ChannelHandler：ChannelHandler 是一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline(业务处理链)中的下一个处理程序。 ChannelHandlerContext：保存 Channel 相关的所有上下文信息，同时关联一个 ChannelHandler 对象。 ChannelPipline：保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作。ChannelPipeline 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 Channel 中各个的 ChannelHandler 如何相互交互。在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下： 一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。read事件(入站事件)和write事件(出站事件)在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰。 Netty粘包拆包TCP是一个流协议，就是没有界限的一长串二进制数据。TCP作为传输层协议并不不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行数据包的划分，所以在业务上认为是一个完整的包，可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。面向流的通信是无消息保护边界的。 解决方案 消息定长度，传输的数据大小固定长度，例如每段的长度固定为100字节，如果不够空位补空格 在数据包尾部添加特殊分隔符，比如下划线，中划线等，这种方法简单易行，但选择分隔符的时候一定要注意每条数据的内部一定不能出现分隔符。 发送长度：发送每条数据的时候，将数据的长度一并发送，比如可以选择每条数据的前4位是数据的长度，应用层处理时可以根据长度来判断每条数据的开始和结束。 Netty提供了多个解码器，可以进行分包的操作，如下： LineBasedFrameDecoder （回车换行分包） DelimiterBasedFrameDecoder（特殊分隔符分包） FixedLengthFrameDecoder（固定长度报文来分包） 数据库ACID理论​ 事务处理几乎是每一个信息系统中都会涉及到的问题，它存在的意义就是保证系统中的数据是正确的，不同数据间不会产生矛盾，也就是保证数据状态的一致性（Consistency），理论上，要达成这个目标需要三方面的共同努力： 原子性（Atomic）：在同一项业务处理过程中，事务保证了多个对数据的修改，要么同时成功，要么一起被撤销。原子性是由undolog日志来保证的，它记录了需要回滚的日志信息，事务回滚时，撤销已经执行成功的sql。 隔离性（Isolation）：在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。隔离性是由MVCC来保证的。 持久性（Durability）：事务应当保证所有被成功提交的数据修改都能够正确地被持久化，不丢失数据。持久性由redolog来保证的，mysql修改数据的时候会在redolog中记录一份日志数据，就算数据没有保存成功，只要日志保存成功了，数据仍然不会丢失。 以上就是事务的“ACID”的概念提法。我自己对这种已经形成习惯的“ACID”的提法是不太认同的，因为这四种特性并不正交，A、I、D 是手段，C 是目的，完全是为了拼凑个单词缩写才弄到一块去，误导的弊端已经超过了易于传播的好处。 Mysql索引结构mysql的索引结构有：二叉树、红黑树、hash表、BTree、B+Tree 二叉树 Hash表 B+Tree InnoDB和MyISAM区别 区别 InnoDB MyISAM 事务 支持 不支持 外键 支持 不支持 索引 聚簇索引和非聚簇索引 非聚簇索引 行锁 支持 不支持 表锁 支持 支持 存储文件 frm(表结构)，ibd(数据和索引) frm，myi(索引文件)，myd(数据文件) 具体行数 全表扫描统计行数 通过变量保存行数 MyISAM不支持事务，在执行查询语句SELECT前，会自动给涉及的所有表加读锁,在执行update、insert、delete操作会自动给涉及的表加写锁。 InnoDB在执行查询语句SELECT时(非串行隔离级别)，(因为有mvcc机制)不会加锁。但是update、insert、delete操作会加行锁。简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。 B树和B+数的区别B-Tree B+Tree(B-Tree变种) B+Tree非叶子节点不存储data，只存储冗余索引，叶子节点包含所有索引字段 。优点：可以放更多的索引，BTree非叶子节点会存储索引和数据 B+Tree叶子节点用指针连接。优点：提高区间访问的性能（范围查找），BTree叶子节点指针为空 事务隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncomm 读已提交（read-committed） 否 是 是 可重复读（repeatable-read） mysql默认 否 否 是 串行化（serializable） 否 否 否 Mysql在可重复度隔离级别下通过MVCC保证事务隔离性 幻读是指当一个事务A读取某一个范围的数据时，另一个事务B在这个范围插入行，A事务再次读取这个范围数据时，会产生幻读 Mysql幻读是怎么解决的首先要确认一下幻读是怎么产生的，先弄清两个概念，那就是当前读和快照读 当前读 像select lock in share mode(共享锁)，select for update，update，insert，delete（排他锁）这些操作都是一种当前读，为什么叫当前读？就是他读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取记录进行加锁 快照读 ​ 像不加锁的select操作就是快照读，也就是不加锁的非阻塞读；快照读的前提是隔离级别不是串行化，串行级别的快照读会退化成当前读，快照读的实现是基于多版本并发控制，也就是MVCC，可以认为MVCC是行锁的一个变种，但是很多情况下避免加锁操作，快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本 如果只有快照读是不会产生幻读问题，只有快照读和当前读一起使用的时候才会产生幻读。 Mysql在可重复度隔离级别下可以通过MVCC和临键锁（记录锁+间隙锁）解决幻读问题。 MVCC对于mvcc的理解，可以从数据库三种并发场景来说 第一种是读和读的并发：就是两个线程A和B同时进行读操作，这种情况下呢，不会产生任何的并发问题 第二种是读写并发：就是说两个线程A和B在同一时刻分别进行读写操作，这种情况下可能会对数据库的数据造成一些问题，第一、事务隔离性问题；第二、会造成脏读，幻读，不可重复读的问题 第三种是写和写的并发：就是两个线程A和B同时进行写操作，这种情况下可能会存在数据更新的丢失问题 MVCC就是为了解决事务操作中并发安全问题的，无锁并发控制技术，全称就是：多版本并发控制，他是通过数据库记录中的隐式字段Undo日志和ReadView来实现的，MVCC主要解决三个问题：第一、通过MVCC可以解决读写并发阻塞问题，从而提高数据库的并发处理能力；第二、MVCC采用的是乐观锁的方式实现，降低了死锁的概率；第三、解决了一致性读的问题，也就是事务启动的时候，根据某个条件去读取到的数据，知道事务结束的时候再去执行相同条件，还是读到同一份数据，不会发生变化变化，而我们在使用MVCC的时候，一般是根据业务场景来选择组合搭配，乐观锁或者悲观锁，MVCC用来解决读写冲突，而乐观锁悲观锁用来解决写和写的冲突，从而最大程度去提高数据库的并发性能。 什么场景会引发幻读幻读是指在同一个事务中，存在前后两次查询同一个范围的数据，但是第二次查询却看到了第一次查询没看到的行，一般情况下特指事务执行中新增的其他行。 sql在mysql的执行过程 事务怎么保证一致性redo log是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。如数据库掉电，InnoDB存储引擎会使用redo log恢复到掉电前的时刻，以此来保证数据的完整性。在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到redo log日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redo log中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术，他的关键点是先写日志，再写磁盘。 binlog 、undo 、redo redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。 undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。 二进制日志（binlog） 聚簇和非聚簇索引 聚簇索引也好、非聚簇索引也好，都是索引的一个基本分类，他们最本质的点在于存储引擎，如果我们用InnoDB存储引擎，他的存储文件是.frm和.ibd文件，这意味着InnoDB里面存放数据文件和索引文件是在同一个文件.ibd文件里，所以他的数据和索引是放在一起存储的，这种存储方式称之为聚簇索引。InnerDB在进行数据插入的时候，必须要绑定一个索引列上，默认是主键，如果没有主键，会选择唯一键，如果没有唯一键，会生成6字节的rowid，跟数据绑定在一起 像MyISAM存储引擎，他存储文件是.frm，.myi(索引文件)，.myd(数据文件)文件，他是把索引文件和数据文件分开存储的，这种存储方式称为非聚簇索引，InnoDB既有聚簇索引也有非聚簇索引，MyISAM只有非聚簇索引 数据库慢sql优化 尽量创建联合索引, 多表关联查询：所有的join查询，都是通过嵌套循环连接完成的，嵌套循环join有三个变种： Simple Nested-Loop Join ：从表中取出匹配所有列，匹配后合并，开销大。select * from t1,t2(笛卡尔积) Index Nested-Loop Join ： 索引嵌套连接，由于非驱动表有索引，通过索引减少比较，加速查询，我们再做关联查询的时候必须要求关联字段有索引；查询过程：1、根据关联字段索引进行查找，在索引上找到符合的值后再回表查询，只有匹配到索引后才会回表，至于驱动表选择，Mysql优化器一般会选择记录少的作为驱动表，但是当SQL特别复杂的时候不排除会选择错。2、如果非驱动表关联主键，性能会非常高，如果不是主键，关联后返回行数特别多的话，效率也会很低，要多次回表操作。 Block Nested-Loop Join：当连接条件没有索引的时候会用这种方式关联，比Simple Nested-Loop Join 多了一个中间处理过程，有些情况下，可能join的列就是没有索引，那么MySQL会选择Block Nested-Loop Join算法，其实就是使用Join buffer将驱动表的查询Join相关列都缓存到Join buffer中，然后批量与非驱动表进行比较，降低了非驱动表的访问频次。查看join buffer:show variables like &#39;join_buffer_size;&#39; 索引失效的情况谈到索引主要从两方面来分析：IO 和数据结构：不管索引数据还是行数据，都是存在磁盘里面的，我们尽可能少的取出数据 IO—–&gt;读取次数少、量少——&gt;分块读取——&gt;局部性原理、磁盘预读 数据结构——&gt;B+树——&gt;二叉树、AVL树、红黑树、B树 组合索引不遵循最左匹配原则 组合索引前面索引列使用范围查询(&lt;,&gt;,like),会导致后续索引失效； 不要在索引上做任何操作（计算，函数，类型转换） is null和is not null 无法使用索引 尽量少使用or操作符，否则连接时索引会失效 字符串不添加引号会导致索引失效（隐式类型转换） 两表关联使用的条件字段中字段的长度，编码不一致会导致索引失效 like语句中，以%开头的模糊查询会导致索引失效 如果mysql中使用全表扫描比索引快，也会导致索引失效 （force index:强制使用索引） 如何做分库分表​ 使用mycat或者shardingsphere中间件做分库分表，选择合适的中间件，水平分库，水平分表，垂直分库，垂直分表，在进行分库分表的时候尽量遵循以下原则 能不切分尽量不要切分 如果要切分一定要选择合适的切分规则，提前规划好 如果切分尽量通过数据冗余或表分组来降低跨库Join的可能 由于数据库中间件对数据Join实现的优劣难以把握，而且实现高性能难度极大，业务尽量少使用多表Join Mysql主从复制 从库通过手工执行change master to 语句连接主库，提供连接用户信息（userName、passWord、port、ip）二进制日志的起点位置（file名 position号）；start slave 从库的IO线程和主库的dump线程建立连接 从库根据change master to 语句提供的file名和position号，IO线程向主库发起binlog请求 主库dump线程根据从库请求，将本地binlog以events的方式发给从库IO线程 从库IO线程接受binlog events，并放到本地relay-log中(顺序IO)，传送过来的信息会记录到master.info中 从库SQL线程应用relay-log,并且把应用过的记录到relay-log.info中，默认情况下，已经应用过的relay会自动被清理purge 缓存:Redis/ESRedis数据类型 String Hash List：类似于数组 Set：无序集合 用户列表，求集合的交集，并集等操作 ZSet：有序集合 1）点击新闻：ZINCRBY hotNews:20190819 1 守护香港 2）展示当日排行前十：ZREVRANGE hotNews:20190819 0 9 WITHSCORES 3）七日搜索榜单计算：ZUNIONSTORE hotNews:20190813-20190819 7 hotNews:20190813 hotNews:20190814… hotNews:20190819 4）展示七日排行前十：ZREVRANGE hotNews:20190813-20190819 0 9 WITHSCORES Redis单线程模型Redis基于Reactor模式开发的网络事件处理器，这个文件事件处理器是单线程的，采用IO多路复用机制监听多个Socker，根据Socker上的事件类型选择对应的事件处理器处理这个事件，可以实现高性能的网络通信。文件事件处理器包含4个部分，多个Socker，IO多路复用程序，文件事件分派器和事件处理器(命令请求处理器，命令回复处理器，链接应答处理器)，多个Socket可能并发产生不同操作，每个操作对应不同的文件事件，但是IO多路复用会监听多个Socket，会将Socket放入一个队列，每次从队列中取出一个Socket给时间分派器，时间分派器把Socket给对应的事件处理器。 单线程快的原因：1.纯内存操作；2.核心是基于非阻塞的IO多路复用机制；3.单线程反而避免多线程的频繁上下文切换 分布式锁怎么实现的？ 基于数据库实现分布式锁：唯一索引，状态机唯一联合索引 基于缓存（Redis等）实现分布式锁：SET key value NX PX 30000 基于Zookeeper实现分布式锁； setnx用到的参数SET key value NX PX 30000 第三个参数：把key、value set到redis中的策略 nx ： not exists, 只有key 不存在时才把key value set 到redis xx ： is exists ，只有 key 存在是，才把key value set 到redis 第四个参数：过期时间单位 ex ：seconds 秒 px : milliseconds 毫秒 使用其他值，抛出 异常 ： redis.clients.jedis.exceptions.JedisDataException : ERR syntax error 第五个参数：有两种可选的值， int 和long 的time，都是过期时间 ，expx 参数是px的时候，使用long类型的参数，可以表示更多时间 缓存穿透，击穿，雪崩 缓存雪崩：缓存同一时间大面积失效，后面请求都落到数据库上，造成大量请求直接打到数据库。 过期时间随机，防止同一时间大量数据过期 缓存预热：项目启动加载缓存到redis 互斥锁：修改的时候只允许一个线程修改数据库，其他读写线程等待 加相应缓存标记，记录缓存是否失效，如果失效，更新缓存(内存消耗大，一般不用) 缓存穿透：指数据库没有数据，导致请求落到数据库上 接口层增加校验，对id进行规则拦截 缓存取不到数据，设置null值到缓存，设置短时间超时，防止网络攻击 布隆过滤器，所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据就会被这个bitmap拦截 缓存击穿：缓存没有，数据库中有数据（一般是缓存时间到期），并发用户特别多，同时大量请求落到数据库，缓存击穿指并发查询同一条数据，缓存雪崩是不同数据都过期 key不过期 加互斥锁 Redis持久化 RDB快照(snapshot) Redis 将内存数据快照保存在名字为 dump.rdb 的二进制文件中。可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据；**# save 60 1000 //** (60秒改1000次进行一次RDB持久化)关闭RDB只需要将所有的save保存策略注释掉即可。 问题：会阻塞客户端命令。 还可以手动执行命令生成RDB快照，进入redis客户端执行命令save或bgsave可以生成dump.rdb文件，每次命令执行都会将所有redis内存快照到一个新的rdb文件里，并覆盖原有rdb快照文件。 bgsave的写时复制(COW)机制：Redis 借助操作系统提供的写时复制技术（Copy-On-Write, COW），在生成快照的同时，依然可以正常处理写命令。bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些数据也都是读操作，那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，在这个过程中，主线程仍然可以修改原来的数据。 AOF(append-only file) 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式： AOF 持久化，将修改的每一条指令记录进文件appendonly.aof中(先写入os cache，每隔一段时间fsync到磁盘) 缓存与数据库数据一致性 解决方案： 对于并发几率很小的数据(如个人维度的订单数据、用户数据等)，这种几乎不用考虑这个问题，很少会发生缓存不一致，可以给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。 就算并发很高，如果业务上能容忍短时间的缓存数据不一致(如商品名称，商品分类菜单等)，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。 如果不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。 也可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。 ES简介ES他是建立在全文搜索引擎库ApacheLucene基础上的一个开源搜索和分析引擎，ES本身具有一个分布式存储，检索速度快的特性，所以我们经常用它去实现全文检索这一类的场景，比如像网站搜索，公司内部用ELK做日志聚集和检索，来去快速查找服务器的日志记录，去定位问题，基本上涉及到TB级别的数据场景，用ES是一个比较好的选择 ES查询快的原因 第一、Lucene是擅长管理大量的索引数据的，另一方面他会对数据进行分词以后在保存索引，这样能搞提升数据的检索效率 第二、ES采用倒排索引，所谓倒排索引，就是通过属性值来确定数据记录的位置的索引，来避免全表扫描这样一个问题， 第三、ES采用分片存储机制 第四、ES扩展性好，我们可以水平扩展增加服务器，提升ES处理性能，可以达到百台服务器节点扩展 第五、ES内部提供了数据汇总和索引生命周期管理的一些功能，可以方便我们更加高效的存储和搜索数据 使用ES注意事项 ES里面不建议使用复杂的关联查询，会对性能影响很大 避免深度分页查询，因为ES分页是支持front和size参数，在查询的时候，每个分片必须构造一个长度为front加size的优先队列，然后回传到网关节点，网关节点再对这些队列进行排序再找到正确的size文档。而当front足够大的时候容易造成OOM以及网络传输性能差的一些问题 中间件消息队列 Rabbitmq生产高可用怎么实现的 生产部署为集群模式：避免单机模式下MQ服务器挂了导致服务不可用，还可以承载更高的并发量，但是集群模式有个问题，就是在哪个节点上创建队列，该队列只会存在该节点上，其他集群节点不会备份该队列，一旦该节点宕机，该队列中的消息就会丢失(亲测设置持久化也丢失) 使用镜像队列：可以解决集群模式下，每个机器上只有一个队列的问题，让消息在其他节点再备份一份。开启方式：任何节点添加policy策略即可，该集群就具有镜像队列能力，可设置备份的份数和备份队列规则，即使其中一个节点宕机，也会保证整个集群中保存2份 高可用负载均衡：haproxy+keepalive，nginx，lvs等实现高可用负载均衡 其他：Federation Exchange联邦交换机插件解决两地接受消息确认消息延迟问题，也可以用Shovel来做数据同步，需要安装插件 zookeeperzookeeper的理解 集群管理：提供了CP模型来保证集群中每个节点的数据一致性 分布式锁 集群选举 zookeeper选举机制 LeaderElection AuthFastLeaderElection FastLeaderElection （最新默认） 目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下： 服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking(选举状态)。 服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。 服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为领导者，服务器1,2成为小弟。 服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为小弟。 服务器5启动，后面的逻辑同服务器4成为小弟。 微服务全局序号生成规则？ UUID：没顺序，长度过长，作为主键索引效率低 数据库自增id：实现简单，保证唯一递增，扩展性差，有单点故障风险 redis生成id 雪花算法 通过一个序列表记录当前序列号，机器每次从序列表中获取一定步长的序列数然后缓存再本地，等用完后再重新从步长表获取 理论CAP理论​ CAP 理论又叫 Brewer 理论，这是加州大学伯克利分校的埃里克 · 布鲁尔（Eric Brewer）教授，在 2000 年 7 月“ACM 分布式计算原理研讨会（PODC）”上提出的一个猜想。CAP理论原稿（那时候还只是猜想）然后到了 2002 年，麻省理工学院的赛斯 · 吉尔伯特（Seth Gilbert）和南希 · 林奇（Nancy Lynch）就以严谨的数学推理证明了这个 CAP 猜想。在这之后，CAP 理论就正式成为了分布式计算领域公认的著名定理。这个定理里，描述了一个分布式的系统中，当涉及到共享数据问题时，以下三个特性最多只能满足其中两个： 一致性（Consistency）：代表在任何时刻、任何分布式节点中，我们所看到的数据都是没有矛盾的。这与 ACID 中的 C 是相同的单词，但它们又有不同的定义（分别指 Replication 的一致性和数据库状态的一致性）。在分布式事务中，ACID 的 C 要以满足 CAP 中的 C 为前提。 可用性（Availability）：代表系统不间断地提供服务的能力。 分区容忍性（Partition Tolerance）：代表分布式环境中，当部分节点因网络原因而彼此失联（即与其他节点形成“网络分区”）时，系统仍能正确地提供服务的能力。 DDDddd不是一种架构风格，而是一种方法论，什么是方法论，每个人按照自己的想法来设计就是一套方法论；ddd是一种业务比较认可，对于微服务拆分的一种方法论。 项目 最近做的比较熟悉的项目是哪个？画一下项目技术架构图 写两个类，能够实现堆内存溢出和栈内存溢出 写一个线程安全的单例。 两个可变有序链表放到新数组中，有序 算法","categories":[{"name":"面试","slug":"面试","permalink":"https://zhangyong3214.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://zhangyong3214.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Spring技术笔记","slug":"学习笔记/Spring","date":"2022-01-27T08:31:13.127Z","updated":"2022-01-27T08:31:13.127Z","comments":true,"path":"2022/01/27/学习笔记/Spring/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Spring/","excerpt":"","text":"Spring底层核心原理解析下载Spring源码git clone的地址为：https://gitee.com/archguide/spring-framework-5.3.10.git Bean的创建过程那么Spring到底是如何来创建一个Bean的呢，这个就是Bean创建的生命周期，大致过程如下： 利用该类的构造方法来实例化得到一个对象（但是如何一个类中有多个构造方法，Spring则会进行选择，这个叫做推断构造方法） 得到一个对象后，Spring会判断该对象中是否存在被@Autowired注解了的属性，把这些属性找出来并由Spring进行赋值（依赖注入） 依赖注入后，Spring会判断该对象是否实现了BeanNameAware接口、BeanClassLoaderAware接口、BeanFactoryAware接口，如果实现了，就表示当前对象必须实现该接口中所定义的setBeanName()、setBeanClassLoader()、setBeanFactory()方法，那Spring就会调用这些方法并传入相应的参数（Aware回调） Aware回调后，Spring会判断该对象中是否存在某个方法被@PostConstruct注解了，如果存在，Spring会调用当前对象的此方法（初始化前） 紧接着，Spring会判断该对象是否实现了InitializingBean接口，如果实现了，就表示当前对象必须实现该接口中的afterPropertiesSet()方法，那Spring就会调用当前对象中的afterPropertiesSet()方法（初始化） 最后，Spring会判断当前对象需不需要进行AOP，如果不需要那么Bean就创建完了，如果需要进行AOP，则会进行动态代理并生成一个代理对象做为Bean（初始化后） 通过最后一步，我们可以发现，当Spring根据UserService类来创建一个Bean时： 如果不用进行AOP，那么Bean就是UserService类的构造方法所得到的对象。 如果需要进行AOP，那么Bean就是UserService的代理类所实例化得到的对象，而不是UserService本身所得到的对象。 Bean对象创建出来后： 如果当前Bean是单例Bean，那么会把该Bean对象存入一个Map&lt;String,Object&gt;，Map的key为beanName，value为Bean对象。这样下次getBean时就可以直接从Map中拿到对应的Bean对象了。（实际上，在Spring源码中，这个Map就是单例池） 如果当前Bean是原型Bean，那么后续没有其他动作，不会存入一个Map，下次getBean时会再次执行上述创建过程，得到一个新的Bean对象。 推断构造方法Spring在基于某个类生成Bean的过程中，需要利用该类的构造方法来实例化得到一个对象，但是如果一个类存在多个构造方法，Spring会使用哪个呢？ Spring的判断逻辑如下： 如果一个类只存在一个构造方法，不管该构造方法是无参构造方法，还是有参构造方法，Spring都会用这个构造方法 如果一个类存在多个构造方法a. 这些构造方法中，存在一个无参的构造方法，那么Spring就会用这个无参的构造方法b. 这些构造方法中，不存在一个无参的构造方法，那么Spring就会报错 Spring的设计思想是这样的： 如果一个类只有一个构造方法，那么没得选择，只能用这个构造方法 如果一个类存在多个构造方法，Spring不知道如何选择，就会看是否有无参的构造方法，因为无参构造方法本身表示了一种默认的意义 不过如果某个构造方法上加了@Autowired注解，那就表示程序员告诉Spring就用这个加了注解的方法，那Spring就会用这个加了@Autowired注解构造方法了 需要重视的是，如果Spring选择了一个有参的构造方法，Spring在调用这个有参构造方法时，需要传入参数，那这个参数是怎么来的呢？ Spring会根据入参的类型和入参的名字去Spring中找Bean对象（以单例Bean为例，Spring会从单例池那个Map中去找）： 先根据入参类型找，如果只找到一个，那就直接用来作为入参 如果根据类型找到多个，则再根据入参名字来确定唯一一个 最终如果没有找到，则会报错，无法创建当前Bean对象 确定用哪个构造方法，确定入参的Bean对象，这个过程就叫做推断构造方法。 AOP大致流程AOP就是进行动态代理，在创建一个Bean的过程中，Spring在最后一步会去判断当前正在创建的这个Bean是不是需要进行AOP，如果需要则会进行动态代理。 如何判断当前Bean对象需不需要进行AOP: 找出所有的切面Bean 遍历切面中的每个方法，看是否写了@Before、@After等注解 如果写了，则判断所对应的Pointcut是否和当前Bean对象的类是否匹配 如果匹配则表示当前Bean对象有匹配的的Pointcut，表示需要进行AOP 利用cglib进行AOP的大致流程： 生成代理类UserServiceProxy，代理类继承UserService 代理类中重写了父类的方法，比如UserService中的test()方法 代理类中还会有一个target属性，该属性的值为被代理对象（也就是通过UserService类推断构造方法实例化出来的对象，进行了依赖注入、初始化等步骤的对象） 代理类中的test()方法被执行时的逻辑如下：a. 执行切面逻辑（@Before）b. 调用target.test() 当我们从Spring容器得到UserService的Bean对象时，拿到的就是UserServiceProxy所生成的对象，也就是代理对象。UserService代理对象.test()—&gt;执行切面逻辑—&gt;target.test()，注意target对象不是代理对象，而是被代理对象。 Spring事务当我们在某个方法上加了@Transactional注解后，就表示该方法在调用时会开启Spring事务，而这个方法所在的类所对应的Bean对象会是该类的代理对象。 Spring事务的代理对象执行某个方法时的步骤： 判断当前执行的方法是否存在@Transactional注解 如果存在，则利用事务管理器（TransactionMananger）新建一个数据库连接 修改数据库连接的autocommit为false 执行target.test()，执行程序员所写的业务逻辑代码，也就是执行sql 执行完了之后如果没有出现异常，则提交，否则回滚 Spring事务是否会失效的判断标准：某个加了@Transactional注解的方法被调用时，要判断到底是不是直接被代理对象调用的，如果是则事务会生效，如果不是则失效。","categories":[{"name":"框架","slug":"框架","permalink":"https://zhangyong3214.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"}]},{"title":"企业开发规范和技巧","slug":"开发工作/开发规范和技巧","date":"2022-01-27T08:31:13.127Z","updated":"2022-01-27T08:31:13.127Z","comments":true,"path":"2022/01/27/开发工作/开发规范和技巧/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C/%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%E5%92%8C%E6%8A%80%E5%B7%A7/","excerpt":"","text":"开发规范前言​ 没有看过阿里开发规范的同学可以先阅读一遍规范里面的内容，《Java 开发手册》是阿里巴巴集团技术团队的集体智慧结晶和经验总结，经历了多次大规模一 线实战的检验及不断完善，公开到业界后，众多社区开发者踊跃参与，共同打磨完善，系统化地整理 成册。为提高软件的最终交付质量，五花八门的错误码人为地 增加排查问题的难度;数据库的表结构和索引设计缺陷带来的系统架构缺陷或性能风险;工程结构混 乱导致后续项目维护艰难;没有鉴权的漏洞代码易被黑客攻击等等，制定一套开发规范出来还是很有必要的，对于增强代码的可读性，提高项目的维护成本，提高问题的排查速度，都会有重要的作用。 命名","categories":[{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"开发","slug":"开发","permalink":"https://zhangyong3214.github.io/tags/%E5%BC%80%E5%8F%91/"}]},{"title":"RabbitMQ消息中间件技术笔记","slug":"学习笔记/RabbitMQ","date":"2022-01-27T08:31:13.126Z","updated":"2022-01-27T08:31:13.127Z","comments":true,"path":"2022/01/27/学习笔记/RabbitMQ/","link":"","permalink":"https://zhangyong3214.github.io/2022/01/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/RabbitMQ/","excerpt":"","text":"MQ相关概念什么是MQMQ(message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用了 MQ之后，消息发送上游只需要依赖 MQ，不用依赖其他服务。 为什么要用MQ 流量消峰 举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。 应用解耦 以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。 异步提速 有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完，以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题，A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样 B 服务也不用做这些操作。A 服务还能及时的得到异步处理成功的消息。 MQ的分类 ActiveMQ优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，消息可靠性较低的概率丢失数据。 缺点：官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。 Kafka大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为大数据而生的消息中间件，以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。 优点：性能卓越，单机写入 TPS 约在百万条/秒，最大的优点，就是吞吐量高。时效性 ms 级可用性非常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用,消费者采用 Pull 方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;有优秀的第三方Kafka Web 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；功能支持：功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。 缺点：Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序，但是一台代理宕机后，就会产生消息乱序，社区更新较慢。 RocketMQRocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场景。 优点：单机吞吐量十万级,可用性非常高，分布式架构,消息可以做到 0 丢失,MQ 功能较为完善，还是分布式的，扩展性好,支持 10 亿级别的消息堆积，不会因为堆积导致性能下降,源码是 java 我们可以自己阅读源码，定制自己公司的 MQ。 缺点：支持的客户端语言不多，目前是 java 及 c++，其中 c++不成熟；社区活跃度一般,没有在 MQ核心中去实现 JMS 等接口,有些系统要迁移需要修改大量代码。 RabbitMQ2007 年发布，是一个在 AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。 优点：由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备,健壮、稳定、易用、跨平台、支持多种语言 如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持 AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用,社区活跃度高；更新频率相当高。 缺点：商业版需要收费,学习成本较高。 MQ的选择KafkaKafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。 RocketMQ天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。 RabbitMQ结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。 RabbitMQ简介2007年，Rabbit 技术公司基于 AMQP 标准开发的 RabbitMQ 1.0 发布。RabbitMQ 采用 Erlang 语言开发。Erlang 语言由 Ericson 设计，专门为开发高并发和分布式系统的一种语言，在电信领域使用广泛。 RabbitMQ四大核心概念 生产者产生数据发送消息的程序是生产者 交换机交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定。 队列 队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式。 消费者 消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。 RabbitMQ的工作模式 简单模式 HelloWorld： 一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。 工作队列模式 Work Queue： 一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。 发布订阅模式 Publish/subscribe：需要设置类型为 fanout 的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。 路由模式 Routing： 需要设置类型为 direct 的交换机，交换机和队列进行绑定，并且指定 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 通配符模式 Topic：需要设置类型为 topic 的交换机，交换机和队列进行绑定，并且指定通配符方式的 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 RabbitMQ工作原理 Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等 Connection：publisher／consumer 和 broker 之间的 TCP 连接 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCPConnection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。 l Channel 作为轻量级的Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange ： message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout(multicast) Queue ： 消息最终被送到这里等待 consumer 取走 Binding ： exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据 RabbitMQ安装略….推荐使用Docker安装学习，参考文章：Docker操作笔记-从小白到入门 RabbitMQ在安装好后，可以访问http://ip地址:15672 ;其自带了guest/guest的 用户名和密码。 角色说明 超级管理员(administrator)：可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操 作。 监控者(monitoring)：可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用 情况，磁盘使用情况等)。 策略制定者(policymaker)：可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上 图红框标识的部分)。 普通管理者(management)：仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他：无法登陆管理控制台，通常就是普通的生产者和消费者。 消息应答及持久化消息应答机制概念消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成了部分突然它挂掉了，会发生什么情况。RabbitMQ 一旦向消费者传递了一条消息，便立即将该消息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息。以及后续发送给该消费这的消息，因为它无法接收到。为了保证消息在发送过程中不丢失，rabbitmq 引入消息应答机制，消息应答就是: 消费者在接收到消息并且处理该消息之后，告诉rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。 自动应答消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡,因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失了,当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，当然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终使得内存耗尽，最终这些消费者线程被操作系统杀死， 所以这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。 总结：尽量少用自动应答，自动应答是在接收到消息的一刹那就进行了应答，如果后续对消息进行了处理出现错误，不能重新从队列中获取消息处理。 手动应答消息应答的方法 Channel.basicAck(用于肯定确认)：RabbitMQ 已知道该消息并且成功的处理消息，可以将其丢弃了 Channel.basicNack(用于否定确认) Channel.basicReject(用于否定确认)：与 Channel.basicNack 相比少一个参数(是否批量处理)，不处理该消息了直接拒绝，可以将其丢弃了 手动应答的好处是可以批量应答并且减少网络拥堵 multiple 的 true 和 false 代表不同意思 true 代表批量应答 channel 上未应答的消息，比如说 channel 上有传送 tag 的消息 5,6,7,8 当前 tag 是 8 那么此时5-8 的这些还未应答的消息都会被确认收到消息应答 false 同上面相比只会应答 tag=8 的消息 5,6,7 这三个消息依然不会被确认收到消息应答 消息自动重新入队如果消费者由于某些原因失去连接(其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。 消息手动应答代码编写默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改为手动应答，消费者在上面代码的基础上增加下面画红色部分代码。 消息生产者123456789101112131415161718public class Producer &#123; // 队列名称 public static final String TASK_QUEUE_NAME = &quot;ack_queue&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 声明队列：队列名称，是否持久化，是否共享，自动删除，参数 channel.queueDeclare(TASK_QUEUE_NAME, false, false, false, null); Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) &#123; String message = scanner.next(); channel.basicPublish(&quot;&quot;, TASK_QUEUE_NAME, null, message.getBytes(StandardCharsets.UTF_8)); log.info(&quot;生产者发送消息：&#123;&#125;&quot;, message); &#125; &#125;&#125; RabbitMQ 连接工具类 123456789101112131415public class RabbitMqUtils &#123; // 得到一个连接的 channel public static Channel getChannel() throws Exception &#123; // 创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;127.0.0.1&quot;); factory.setPort(5672); factory.setUsername(&quot;guest&quot;); factory.setPassword(&quot;guest&quot;); factory.setVirtualHost(&quot;demo&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); return channel; &#125;&#125; 消费者1234567891011121314151617181920212223242526public class Work01 &#123; private static final String ACK_QUEUE_NAME = &quot;ack_queue&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); System.out.println(&quot;Work01 等待接收消息处理时间较短&quot;); // 消息消费的时候如何处理消息 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody()); // 业务处理耗时1秒 SleepUtils.sleep(1); System.out.println(&quot; 接收到消息:&quot; + message); /** * 采用手动应答 * 1. 消息标记 tag * 2. 是否批量应答未应答消息：不批量信道中的消息 */ channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;; // ***采用手动应答 boolean autoAck = false; channel.basicConsume(ACK_QUEUE_NAME, autoAck, deliverCallback, (consumerTag) -&gt; &#123; System.out.println(consumerTag + &quot; 消费者取消消费接口回调逻辑&quot;); &#125;); &#125;&#125; 睡眠工具 123456789public class SleepUtils &#123; public static void sleep(int second) &#123; try &#123; Thread.sleep(1000L * second); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; RabbitMQ 持久化持久化概念刚刚我们已经看到了如何处理任务不丢失的情况，但是如何保障当 RabbitMQ 服务停掉以后消息生产者发送过来的消息不丢失。默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事：我们需要将队列和消息都标记为持久化。 队列实现持久化之前我们创建的队列都是非持久化的，rabbitmq 如果重启的化，该队列就会被删除掉，如果 要队列实现持久化 需要在声明队列的时候把 durable 参数设置为持久化 但是需要注意的就是如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误。 以下为控制台中持久化与非持久化队列的 UI 显示区： 这个时候即使重启 rabbitmq 队列也依然存在。 消息实现持久化要想让消息实现持久化需要在消息生产者修改代码，MessageProperties.PERSISTENT_TEXT_PLAIN 添加这个属性，如下图 将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是 这里依然存在当消息刚准备存储在磁盘的时候 但是还没有存储完，消息还在缓存的一个间隔点。此时并没 有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。如果需要 更强有力的持久化策略，参考后边课件发布确认章节。 不公平分发在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好，但是RabbitMQ 并不知道这种情况它依然很公平的进行分发。 注：为了避免这种情况，我们可以设置参数 channel.basicQos(1)，不公平分发由消费方设置，生产环境应该设置为不公平分发。 意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略。 发布确认发布确认原理生产者将信道设置成 confirm 模式，一旦信道进入confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker 就会发送一个确认给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传 给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消 息，生产者应用程序同样可以在回调方法中处理该nack消息。 发布确认的策略开启发布确认的方法发布确认默认是没有开启的，如果要开启需要调用方法 confirmSelect，每当你要想使用发布确认，都需要在 channel 上调用该方法。 12Channel channel = connection.createchannel();channel.confirmselect(); 第一种：单个确认发布这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它 被确认发布，后续的消息才能继续发布,waitForConfirmsOrDie(long)这个方法只有在消息被确认 的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。这种确认方式有一个最大的缺点就是:发布速度特别的慢，因为如果没有确认发布的消息就会 阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某 些应用程序来说这可能已经足够了。 123456789101112131415161718192021// 发布单条消息1000条耗时测试： 722mspublic static void publishMessageOne() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = i + &quot;&quot;; channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); // 发送之后马上进行发布确认，服务端返回 false 或超时时间内未返回，生产者可以消息重发 boolean flag = channel.waitForConfirms(); if (flag) &#123; System.out.println(&quot; 消息发送成功&quot;); &#125; &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个单独确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 第二种：批量确认发布上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地 提高吞吐量，当然这种方式的缺点就是:当发生故障导致发布出现问题时，不知道是哪个消息出现 问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种 方案仍然是同步的，也一样阻塞消息的发布。 123456789101112131415161718192021222324252627282930// 批量发布确认 发布1000个消息，耗时141mspublic static void publishMessageBatch() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); // 批量确认消息大小 int batchSize = 100; // 未确认消息个数 int outstandingMessageCount = 0; long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = i + &quot;&quot;; channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); outstandingMessageCount++; // 100条确认一次 if (outstandingMessageCount == batchSize) &#123; channel.waitForConfirms(); outstandingMessageCount = 0; &#125; &#125; // 为了确保还有剩余没有确认消息 再次确认 if (outstandingMessageCount &gt; 0) &#123; channel.waitForConfirms(); &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个批量确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 第三种：异步确认发布异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说， 他是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功， 下面就让我们来详细讲解异步确认是怎么实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 异步发布确认 发布1000个消息，耗时62mspublic static void publishMessageAsync() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); /** * 线程安全有序的一个哈希表，适用于高并发的情况 * 1. 轻松的将序号与消息进行关联 * 2. 轻松批量删除条目 只要给到序列号 * 3. 支持并发访问 */ ConcurrentSkipListMap&lt;Long, String&gt; outstandingConfirms = new ConcurrentSkipListMap&lt;&gt;(); /** * 确认收到消息的一个回调 * 1. 消息序列号 * 2.true 可以确认小于等于当前序列号的消息 * false 确认当前序列号消息 */ ConfirmCallback ackCallback = (sequenceNumber, multiple) -&gt; &#123; if (multiple) &#123; // 返回的是小于等于当前序列号的未确认消息 是一个 map ConcurrentNavigableMap&lt;Long, String&gt; confirmed = outstandingConfirms.headMap(sequenceNumber, true); // 清除该部分未确认消息 confirmed.clear(); &#125;else&#123; // 只清除当前序列号的消息 outstandingConfirms.remove(sequenceNumber); &#125; &#125;; ConfirmCallback nackCallback = (sequenceNumber, multiple) -&gt; &#123; String message = outstandingConfirms.get(sequenceNumber); System.out.println(&quot; 发布的消息&quot;+message+&quot; 未被确认，序列号&quot;+sequenceNumber); &#125;; /** * 添加一个异步确认的监听器 * 1. 确认收到消息的回调 * 2. 未收到消息的回调 */ channel.addConfirmListener(ackCallback, null); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = &quot; 消息&quot; + i; /** * channel.getNextPublishSeqNo() 获取下一个消息的序列号 * 通过序列号与消息体进行一个关联 * 全部都是未确认的消息体 */ outstandingConfirms.put(channel.getNextPublishSeqNo(), message); channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个异步确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 如何处理异步未确认消息好的解决的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列， 比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传 递。 3种发布确认速度对比 单独发布消息：同步等待确认，简单，但吞吐量非常有限。 批量发布消息：批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是那条消息出现了问题。 异步处理：最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些。 交换机在上一节中，我们创建了一个工作队列。我们假设的是工作队列背后，每个任务都恰好交付给一个消 费者(工作进程)。在这一部分中，我们将做一些完全不同的事情-我们将消息传达给多个消费者。这种模式 称为 ”发布/订阅”，为了说明这种模式，我们将构建一个简单的日志系统。它将由两个程序组成:第一个程序将发出日志消 息，第二个程序是消费者。其中我们会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘，另外一个消费者接收到消息后把消息打印在屏幕上，事实上第一个程序发出的日志消息将广播给所有消费者。 Exchanges概念RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。相反，**生产者只能将消息发送到交换机(exchange)**，交换机工作的内容非常简单，一方面它接收来 自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息。是应该把这些消 息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。 Exchanges 的类型 直接(direct) — 路由类型 主题(topic) — 通配符匹配模式 标题(headers) — 已经不用了 扇出(fanout) — 发布订阅类型 无名 exchange第一个参数是交换机的名称。空字符串表示默认或无名称交换机：消息能路由发送到队列中其实是由 routingKey(bindingkey)绑定 key 指定的。 临时队列每当我们连接到 Rabbit 时，我们都需要一个全新的空队列，为此我们可以创建一个具有随机名称的队列，或者能让服务器为我们选择一个随机队列名称那就更好了。其次一旦我们断开了消费者的连接，队列将被自动删除。创建临时队列的方式如下:String queueName = channel.queueDeclare().getQueue(); 绑定(bindings)什么是 bingding 呢，binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和那个队 列进行了绑定关系。比如说下面这张图告诉我们的就是 X 与 Q1 和 Q2 进行了绑定 Fanout(发布订阅交换机)Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的 所有队列中。系统中默认有些 exchange 类型 Fanout 实战 Logs 和临时队列的绑定关系如下图 发布订阅发布者1234567891011121314151617181920public class EmitLog &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; /** * 声明一个 exchange * 1.exchange 的名称 * 2.exchange 的类型 */ channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); Scanner sc = new Scanner(System.in); System.out.println(&quot; 请输入信息&quot;); while (sc.hasNext()) &#123; String message = sc.nextLine(); channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot; 生产者发出消息&quot; + message); &#125; &#125; &#125;&#125; 发布订阅接收者112345678910111213141516171819202122public class ReceiveLogs01 &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); // 把该临时队列绑定我们的 exchange 其中 routingkey( 也称之为 binding key) 为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); System.out.println(&quot;01等待接收消息, 把接收到的消息打印在屏幕.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;01控制台打印接收到的消息&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 发布订阅接收者212345678910111213141516171819202122public class ReceiveLogs02 &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); // 把该临时队列绑定我们的 exchange 其中 routingkey( 也称之为 binding key) 为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); System.out.println(&quot;02等待接收消息, 把接收到的消息打印在屏幕.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;02控制台打印接收到的消息&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; Direct exchange(直接交换机)上一节中，我们构建了一个简单的日志记录系统。我们能够向许多接收者广播日志消息。在本节我们将向其中添加一些特别的功能-比方说我们只让某个消费者订阅发布的部分消息。例如我们只把严重错误消息定向存储到日志文件(以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息。我们再次来回顾一下什么是 bindings，绑定是交换机和队列之间的桥梁关系。也可以这么理解：队列只对它绑定的交换机的消息感兴趣。绑定用参数：routingKey 来表示也可称该参数为 binding key，创建绑定我们用代码:channel.queueBind(queueName, EXCHANGE_NAME, &quot;routingKey&quot;);绑定之后的意义由其交换类型决定。 直接交换机发布者12345678910111213141516171819202122public class EmitLogDirect &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 创建多个 bindingKey Map&lt;String, String&gt; bindingKeyMap = new HashMap&lt;&gt;(); bindingKeyMap.put(&quot;info&quot;, &quot; 普通 info 信息&quot;); bindingKeyMap.put(&quot;warning&quot;, &quot; 警告 warning 信息&quot;); bindingKeyMap.put(&quot;error&quot;, &quot; 错误 error 信息&quot;); //debug 没有消费这接收这个消息 所有就丢失了 bindingKeyMap.put(&quot;debug&quot;, &quot; 调试 debug 信息&quot;); for (Map.Entry&lt;String, String&gt; bindingKeyEntry : bindingKeyMap.entrySet()) &#123; String bindingKey = bindingKeyEntry.getKey(); String message = bindingKeyEntry.getValue(); channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(StandardCharsets.UTF_8)); System.out.println(&quot; 生产者发出消息:&quot; + message); &#125; &#125; &#125;&#125; 直接交换机消费者11234567891011121314151617181920public class ReceiveLogsDirect01 &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = &quot;disk&quot;; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, &quot;error&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); message = &quot; 接收绑定键:&quot; + delivery.getEnvelope().getRoutingKey() + &quot;, 消息:&quot; + message; // 写磁盘忽略 System.out.println(&quot; 错误日志已经接收&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 直接交换机消费者212345678910111213141516171819public class ReceiveLogsDirect02 &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = &quot;console&quot;; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, &quot;info&quot;); channel.queueBind(queueName, EXCHANGE_NAME, &quot;warning&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot; 接 收 绑 定 键 :&quot; + delivery.getEnvelope().getRoutingKey() + &quot;, 消息:&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; Topics(主题交换机)在上一个小节中，我们改进了日志记录系统。我们没有使用只能进行随意广播的 fanout 交换机，而是使用了 direct 交换机，从而有能实现有选择性地接收日志。尽管使用 direct 交换机改进了我们的系统，但是它仍然存在局限性-比方说我们想接收的日志类型有info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候 direct 就办不到了。这个时候就只能使用 topic 类型。 Topic 要求发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词，比如说：”stock.usd.nyse”, “nyse.vmw”,”quick.orange.rabbit”.这种类型的。当然这个单词列表最多不能超过 255 个字节。在这个规则列表中，其中有两个替换符是大家需要注意的 *(星号)可以代替一个单词 #(井号)可以替代零个或多个单词 Topic 匹配案例下图绑定关系如下： Q1–&gt;绑定的是：中间带 orange 带 3 个单词的字符串(.orange.) Q2–&gt;绑定的是：最后一个单词是 rabbit 的 3 个单词(..rabbit) 第一个单词是 lazy 的多个单词(lazy.#) 上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的quick.orange.rabbit ———— 被队列 Q1Q2 接收到lazy.orange.elephant ———— 被队列 Q1Q2 接收到quick.orange.fox ———— 被队列 Q1 接收到lazy.brown.fox ———— 被队列 Q2 接收到lazy.pink.rabbit ———— 虽然满足两个绑定但只被队列 Q2 接收一次quick.brown.fox ———— 不匹配任何绑定不会被任何队列接收到会被丢弃quick.orange.male.rabbit ———— 是四个单词不匹配任何绑定会被丢弃lazy.orange.male.rabbit ———— 是四个单词但匹配 Q2 当队列绑定关系是下列这种情况时需要引起注意 当一个队列绑定键是#,那么这个队列将接收所有数据，就有点像 fanout 了，如果队列绑定键当中没有#和*出现，那么该队列绑定类型就是 direct 了。 死信队列死信的概念先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理 解，一般来说，producer 将消息投递到 broker 或者直接到 queue 里了，consumer 从 queue 取出消息 进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有 后续的处理，就变成了死信，有死信自然就有了死信队列。 应用场景:为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息 消费发生异常时，将消息投入死信队列中.还有比如说: 用户在商城下单成功并点击去支付后在指定时 间未支付时自动失效 死信的来源 消息 TTL 过期 队列达到最大长度(队列满了，无法再添加数据到 mq 中) 消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false. 代码架构图 消息TTL过期代码死信生产者123456789101112131415161718public class Producer &#123; private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); // 设置消息的 TTL 时间 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(&quot;10000&quot;).build(); // 该信息是用作演示队列个数限制 for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; channel.basicPublish(NORMAL_EXCHANGE, &quot;zhangsan&quot;, properties, message.getBytes()); System.out.println(&quot; 生产者发送消息:&quot; + message); &#125; &#125; &#125;&#125; 死信消费者C1消费者 C1 ( 启动之后关闭该消费者 模拟其接收不到消息) 12345678910111213141516171819202122232425262728293031323334public class Consumer01 &#123; // 普通交换机名称 private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; // 死信交换机名称 private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 声明死信和普通交换机 类型为 direct channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); // 声明死信队列 String deadQueue = &quot;dead-queue&quot;; channel.queueDeclare(deadQueue, false, false, false, null); // 死信队列绑定死信交换机与 routingkey channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;); // 正常队列绑定死信队列信息 Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); // 正常队列设置死信交换机 参数 key 是固定值 params.put(&quot;x-dead-letter-exchange&quot;, DEAD_EXCHANGE); // 正常队列设置死信 routing-key 参数 key 是固定值 params.put(&quot;x-dead-letter-routing-key&quot;, &quot;lisi&quot;); String normalQueue = &quot;normal-queue&quot;; channel.queueDeclare(normalQueue, false, false, false, params); channel.queueBind(normalQueue, NORMAL_EXCHANGE, &quot;zhangsan&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot;Consumer01 接收到消息&quot; + message); &#125;; channel.basicConsume(normalQueue, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 死信队列消费者消费者 C2 ( 以上步骤完成后 启动 C2 消费者它消费死信队列里面的消息) 123456789101112131415161718public class Consumer02 &#123; private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); String deadQueue = &quot;dead-queue&quot;; channel.queueDeclare(deadQueue, false, false, false, null); channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;); System.out.println(&quot; 等待接收死信队列消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot;Consumer02 接收死信队列的消息&quot; + message); &#125;; channel.basicConsume(deadQueue, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 队列达到最大长度生产者消息生产者代码去掉 TTL 属性 123456789101112131415public class TooLongProducer &#123; private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); // 该信息是用作演示队列个数限制 for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; channel.basicPublish(NORMAL_EXCHANGE, &quot;zhangsan&quot;, null, message.getBytes()); System.out.println(&quot; 生产者发送消息:&quot; + message); &#125; &#125; &#125;&#125; 消费者C1 消费者修改以下代码 ( 启动之后关闭该消费者 模拟其接收不到消息) 注意此时需要把原先队列删除 因为参数改变了 ,C2 消费者代码不变( 启动 C2 消费者) 消息被拒进入死信代码略 延迟队列延时队列,队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。 延迟队列使用场景 订单在十分钟之内未支付则自动取消 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 用户注册成功后，如果三天内没有登陆则进行短信提醒。 用户发起退款，如果三天内没有得到处理则通知相关运营人员。 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议 RabbitMQ 中的 TTLTTL 是什么呢？TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者进入了设置 TTL 属性的队列，那么这条消息如果在 TTL 设置的时间内没有被消费，则会成为”死信”。如果同时配置了队列的 TTL 和消息的TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。 消息设置 TTL另一种方式便是针对每条消息设置 TTL 队列设置 TTL第一种是在创建队列的时候设置队列的“x-message-ttl”属性 两者的区别如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队列中)，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。 前一小节我们介绍了死信队列，刚刚又介绍了 TTL，至此利用 RabbitMQ 实现延时队列的两大要素已经集齐，接下来只需要将它们进行融合，再加入一点点调味料，延时队列就可以新鲜出炉了。想想看，延时队列，不就是想要消息延迟多久被处理吗，TTL 则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就完事了，因为里面的消息都是希望被立即处理的消息。 整合SpringBoot添加依赖123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;!--RabbitMQ 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--RabbitMQ 测试依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 修改配置文件1234spring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=123 死信队列实现延迟MQ创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是 direct，创建一个死信队列 QD，它们的绑定关系如下： 配置文件类代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class TtlQueueConfig &#123; public static final String X_EXCHANGE = &quot;X&quot;; public static final String QUEUE_A = &quot;QA&quot;; public static final String QUEUE_B = &quot;QB&quot;; public static final String Y_DEAD_LETTER_EXCHANGE = &quot;Y&quot;; public static final String DEAD_LETTER_QUEUE = &quot;QD&quot;; // 声明 xExchange @Bean(&quot;xExchange&quot;) public DirectExchange xExchange() &#123; return new DirectExchange(X_EXCHANGE); &#125; // 声明 xExchange @Bean(&quot;yExchange&quot;) public DirectExchange yExchange() &#123; return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); &#125; // 声明队列 A ttl 为 10s 并绑定到对应的死信交换机 @Bean(&quot;queueA&quot;) public Queue queueA() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); // 声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE); // 声明当前队列的死信路由 key args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;); // 声明队列的 TTL args.put(&quot;x-message-ttl&quot;, 10000); return QueueBuilder.durable(QUEUE_A).withArguments(args).build(); &#125; // 声明队列 A 绑定 X 交换机 @Bean public Binding queueaBindingX(@Qualifier(&quot;queueA&quot;) Queue queueA, @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123; return BindingBuilder.bind(queueA).to(xExchange).with(&quot;XA&quot;); &#125; // 声明队列 B ttl 为 40s 并绑定到对应的死信交换机 @Bean(&quot;queueB&quot;) public Queue queueB() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); // 声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE); // 声明当前队列的死信路由 key args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;); // 声明队列的 TTL args.put(&quot;x-message-ttl&quot;, 40000); return QueueBuilder.durable(QUEUE_B).withArguments(args).build(); &#125; // 声明队列 B 绑定 X 交换机 @Bean public Binding queuebBindingX(@Qualifier(&quot;queueB&quot;) Queue queue1B, @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123; return BindingBuilder.bind(queue1B).to(xExchange).with(&quot;XB&quot;); &#125; // 声明死信队列 QD @Bean(&quot;queueD&quot;) public Queue queueD() &#123; return new Queue(DEAD_LETTER_QUEUE); &#125; // 声明死信队列 QD 绑定关系 @Bean public Binding deadLetterBindingQAD(@Qualifier(&quot;queueD&quot;) Queue queueD, @Qualifier(&quot;yExchange&quot;) DirectExchange yExchange) &#123; return BindingBuilder.bind(queueD).to(yExchange).with(&quot;YD&quot;); &#125;&#125; 生产者代码1234567891011121314@Slf4j@RequestMapping(&quot;ttl&quot;)@RestControllerpublic class SendMsgController &#123; @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(&quot;sendMsg/&#123;message&#125;&quot;) public void sendMsg(@PathVariable String message) &#123; log.info(&quot; 当前时间：&#123;&#125;, 发送一条信息给两个 TTL 队列:&#123;&#125;&quot;, new Date(), message); rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XA&quot;, &quot; 消息来自 ttl 为 为 10S 的队列: &quot; + message); rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XB&quot;, &quot; 消息来自 ttl 为 为 40S 的队列: &quot; + message); &#125;&#125; 消费者代码123456789@Slf4j@Componentpublic class DeadLetterQueueConsumer &#123; @RabbitListener(queues = &quot;QD&quot;) public void receiveD(Message message, Channel channel) throws IOException &#123; String msg = new String(message.getBody()); log.info(&quot; 当前时间：&#123;&#125;, 收到死信队列信息&#123;&#125;&quot;, new Date().toString(), msg); &#125;&#125; 第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息，然后被消费掉，这样一个延时队列就打造完成了。不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？ 延时队列优化在这里新增了一个队列 QC,绑定关系如下,该队列不设置 TTL 时间 看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时“死亡“，因为 RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列，如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。 Rabbitmq插件实现延迟队列参考文章 SpringBoot+RabbitMQ用死信队列和插件形式实现延迟队列 Docker安装Rabbitmq及其延时队列插件 安装延时队列插件在官网 ，下载rabbitmq_delayed_message_exchange插件，然后解压放置到 RabbitMQ 的插件目录。进入 RabbitMQ 的安装目录下的 plgins 目录，执行下面命令让该插件生效，然后重启 RabbitMQ /usr/lib/rabbitmq/lib/rabbitmq_server-3.8.8/plugins rabbitmq-plugins enable rabbitmq_delayed_message_exchange 发布确认高级姿势在生产环境中由于一些不明原因，导致 rabbitmq 重启，在 RabbitMQ 重启期间生产者消息投递失败，导致消息丢失，需要手动处理和恢复。于是，我们开始思考，如何才能进行 RabbitMQ 的消息可靠投递呢？特别是在这样比较极端的情况，RabbitMQ 集群不可用的时候，无法投递的消息该如何处理呢: 发布确认 springboot 版本确认机制方案 代码架构图 配置文件12# 在配置文件当中需要添加spring.rabbitmq.publisher-confirm-type=correlated NONE：禁用发布确认模式，是默认值 CORRELATED：发布消息成功到交换器后会触发回调方法 SIMPLE：经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker，注：此配置同步确认消息，生产不建议使用 交换机发布确认代码1234567891011121314151617181920212223242526272829public class MessageConfirmCallBack&lt;T&gt; implements RabbitTemplate.ConfirmCallback &#123; @Resource private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setConfirmCallback(this); &#125; /** * 交换机确认回调方法 (发布者发送消息是否到交换机触发回调) * 1. 发消息 交换机接收到消息，回调 * 1.1 correlationData 保存毁掉消息的id及相关信息 * 1.2 交换机接收到消息 true * 1.3 失败原因-null * 2. 发消息 交换机接收失败 回调 * 2.1 correlationData 保存毁掉消息的id及相关信息 * 2.2 false * 2.3 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if (ack) &#123; log.info(&quot;发布确认:交换机收到消息id：&#123;&#125;&quot;, correlationData.getId()); &#125; else &#123; log.info(&quot;发布确认:交换机未收到消息，id为：&#123;&#125;,原因：&#123;&#125;&quot;, correlationData.getId(), cause); // TODO 保存数据库重新发送等逻辑保证消息重新发送给交换机 &#125; &#125;&#125; 回退消息在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的。那么如何让无法被路由的消息帮我想办法处理一下？最起码通知我一声，我好自己处理啊。通过设置 mandatory 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者。 添加配置12# 消息回退配置，如果消息无法路由，则回退给生产者spring.rabbitmq.publisher-returns=true 回退代码演示1234567891011121314151617181920212223public class MessageReturnCallBack&lt;T&gt; implements RabbitTemplate.ReturnCallback &#123; @Resource private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setReturnCallback(this); &#125; /** * 可以将消息传递过程中不可达到目的地(队列)的消息返回给生产者 * 只有不可达 才会回退消息 * 请注意!!!如果你使用了延迟队列插件，那么一定会调用该callback方法，因为数据并没有提交上去， * 而是提交在交换器中，过期时间到了才提交上去，并非是bug！你可以用if进行判断交换机名称来捕捉该报错 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; if(exchange.equals(delayedQueueProperties.getDelayedExchangeName()))&#123; return; &#125; log.info(&quot;消息&#123;&#125;，被交换机&#123;&#125;退回，退回原因：&#123;&#125;，路由Key：&#123;&#125;&quot;, new String(message.getBody()), exchange, replyText, routingKey); &#125;&#125; 备份交换机有了 mandatory 参数和回退消息，我们获得了对无法投递消息的感知能力，有机会在生产者的消息无法被投递时发现并处理。但有时候，我们并不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更加麻烦而且容易出错。而且设置 mandatory 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，该怎么做呢？前面在设置死信队列的文章中，我们提到，可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。在 RabbitMQ 中，有一种备份交换机的机制存在，可以很好的应对这个问题。什么是备份交换机呢？备份交换机可以理解为 RabbitMQ 中交换机的“备胎”，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 Fanout ，这样就能把所有消息都投递到与其绑定的队列中，然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。 备份交换机代码声明在原来的代码上面多声明一个交换机和两个队列，还有一个报警消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// @Configurationpublic class ConfirmConfig &#123; public static final String CONFIRM_EXCHANGE_NAME = &quot;confirm.exchange&quot;; public static final String CONFIRM_QUEUE_NAME = &quot;confirm.queue&quot;; public static final String BACKUP_EXCHANGE_NAME = &quot;backup.exchange&quot;; public static final String BACKUP_QUEUE_NAME = &quot;backup.queue&quot;; public static final String WARNING_QUEUE_NAME = &quot;warning.queue&quot;; // 声明确认队列 @Bean(&quot;confirmQueue&quot;) public Queue confirmQueue() &#123; return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); &#125; // 声明确认队列绑定关系 @Bean public Binding queueBinding(@Qualifier(&quot;confirmQueue&quot;) Queue queue, @Qualifier(&quot;confirmExchange&quot;) DirectExchange exchange) &#123; return BindingBuilder.bind(queue).to(exchange).with(&quot;key1&quot;); &#125; // 声明备份 Exchange @Bean(&quot;backupExchange&quot;) public FanoutExchange backupExchange() &#123; return new FanoutExchange(BACKUP_EXCHANGE_NAME); &#125; // 声明确认 Exchange 交换机的备份交换机 @Bean(&quot;confirmExchange&quot;) public DirectExchange confirmExchange() &#123; ExchangeBuilder exchangeBuilder = ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME) .durable(true) // 设置该交换机的备份交换机 .withArgument(&quot;alternate-exchange&quot;, BACKUP_EXCHANGE_NAME); return (DirectExchange) exchangeBuilder.build(); &#125; // 声明警告队列 @Bean(&quot;warningQueue&quot;) public Queue warningQueue() &#123; return QueueBuilder.durable(WARNING_QUEUE_NAME).build(); &#125; // 声明报警队列绑定关系 @Bean public Binding warningBinding(@Qualifier(&quot;warningQueue&quot;) Queue queue, @Qualifier(&quot;backupExchange&quot;) FanoutExchange backupExchange) &#123; return BindingBuilder.bind(queue).to(backupExchange); &#125; // 声明备份队列 @Bean(&quot;backQueue&quot;) public Queue backQueue() &#123; return QueueBuilder.durable(BACKUP_QUEUE_NAME).build(); &#125; // 声明备份队列绑定关系 @Bean public Binding backupBinding(@Qualifier(&quot;backQueue&quot;) Queue queue, @Qualifier(&quot;backupExchange&quot;) FanoutExchange backupExchange) &#123; return BindingBuilder.bind(queue).to(backupExchange); &#125;&#125; 报警消费者1234567891011@Component@Slf4jpublic class WarningConsumer &#123; public static final String WARNING_QUEUE_NAME = &quot;warning.queue&quot;; @RabbitListener(queues = WARNING_QUEUE_NAME) public void receiveWarningMsg(Message message) &#123; String msg = new String(message.getBody()); log.error(&quot; 报警发现不可路由消息：&#123;&#125;&quot;, msg); &#125;&#125; 测试注意事项 重新启动项目的时候需要把原来的 confirm.exchange 删除因为我们修改了其绑定属性，不然报错。 备份交换机和回退优先级mandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，消息究竟何去何从？谁优先级高，经过上面结果显示答案是备份交换机优先级高。 RabbitMQ其他知识点幂等性用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等 消息重复消费消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断，故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。 解决思路MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识比如时间戳 或者 UUID 或者订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。 消费端的幂等性保障在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性，这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。业界主流的幂等性有两种操作:a.唯一 ID+指纹码机制,利用数据库主键去重, b.利用 redis 的原子性去实现 唯一ID+ 指纹码机制指纹码:我们的一些规则或者时间戳加别的服务给到的唯一信息码,它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中,优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。 Redis原子性利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费，此方式为目前用的最多的方案。 优先级队列使用场景在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单,淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧，但是，tmall商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果，小米这样大商家一年起码能给我们创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化,如果发现是大客户的订单给一个相对比较高的优先级，否则就是默认优先级。 如何添加a.控制台页面添加 b.队列中代码添加优先级 123Map&lt;String, Object&gt; params = new HashMap();params.put(&quot;x-max-priority&quot;, 10);channel.queueDeclare(&quot;hello&quot;, true, false, false, params); c.消息中代码添加优先级 1AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); d.注意事项 要让队列实现优先级需要做的事情有如下事情:队列需要设置为优先级队列，消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息进行排序 实战生产者1234567891011121314151617181920public class Producer &#123; private static final String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel();) &#123; // 给消息赋予一个 priority 属性 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; if (i == 5) &#123; channel.basicPublish(&quot;&quot;, QUEUE_NAME, properties, message.getBytes()); &#125; else &#123; channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes()); &#125; System.out.println(&quot; 发送消息完成:&quot; + message); &#125; &#125; &#125;&#125; 消费者12345678910111213141516171819public class Consumer &#123; private static final String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 设置队列的最大优先级 最大可以设置到 255 官网推荐 1-10 如果设置太高比较吃内存和 CPU Map&lt;String, Object&gt; params = new HashMap(); params.put(&quot;x-max-priority&quot;, 10); channel.queueDeclare(QUEUE_NAME, true, false, false, params); System.out.println(&quot; 消费者启动等待消费......&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String receivedMessage = new String(delivery.getBody()); System.out.println(&quot; 接收到消息:&quot; + receivedMessage); &#125;; channel.basicConsume(QUEUE_NAME, true, deliverCallback, (consumerTag) -&gt; &#123; System.out.println(&quot; 消费者无法消费 消息时调用，如队列被删除&quot;); &#125;); &#125;&#125; 惰性队列RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因(比如消费者下线、宕机亦或者是由于维护而关闭等)而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中，这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法，但是效果始终不太理想，尤其是在消息量特别大的时候。 两种模式队列具备两种模式：default 和 lazy。默认的为 default 模式，在 3.6.0 之前的版本无需做任何变更。lazy模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。在队列声明的时候可以通过“x-queue-mode”参数来设置队列的模式，取值为“default”和“lazy”。下面示例中演示了一个惰性队列的声明细节： 123Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-queue-mode&quot;, &quot;lazy&quot;);channel.queueDeclare(&quot;myqueue&quot;, false, false, false, args); 内存开销对比 在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅占用 1.5MB RabbitMQ 集群clustering集群模式使用集群的原因最开始我们介绍了如何安装及运行 RabbitMQ 服务，不过这些是单机版的，无法满足目前真实应用的要求。如果 RabbitMQ 服务器遇到内存崩溃、机器掉电或者主板故障等情况，该怎么办？单台 RabbitMQ服务器可以满足每秒 1000 条消息的吞吐量，那么如果应用需要 RabbitMQ 服务满足每秒 10 万条消息的吞吐量呢？购买昂贵的服务器来增强单机 RabbitMQ 务的性能显得捉襟见肘，搭建一个 RabbitMQ 集群才是解决实际问题的关键。 搭建步骤1.修改 3 台机器的主机名称 vim /etc/hostname 2.配置各个节点的 hosts 文件，让各个节点都能互相识别对方 vim /etc/hosts10.211.55.74 node110.211.55.75 node210.211.55.76 node3 3.以确保各个节点的 cookie 文件使用的是同一个值 在 node1 上执行远程操作命令scp /var/lib/rabbitmq/.erlang.cookie root@node2:/var/lib/rabbitmq/.erlang.cookiescp /var/lib/rabbitmq/.erlang.cookie root@node3:/var/lib/rabbitmq/.erlang.cookie 4.启动 RabbitMQ 服务,顺带启动 Erlang 虚拟机和 RbbitMQ 应用服务(在三台节点上分别执行以下命令) rabbitmq-server -detached 5.在节点 2 执行 1234rabbitmqctl stop_app (rabbitmqctl stop 会将 Erlang 虚拟机关闭，rabbitmqctl stop_app 只关闭 RabbitMQ 服务)rabbitmqctl resetrabbitmqctl join_cluster rabbit@node1rabbitmqctl start_app(只启动应用服务) 6.在节点 3 执行 1234rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster rabbit@node2rabbitmqctl start_app 7.集群状态 rabbitmqctl cluster_status 8.需要重新设置用户 创建账号rabbitmqctl add_user admin 123设置用户角色rabbitmqctl set_user_tags admin administrator设置用户权限rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 9.解除集群节点(node2 和 node3 机器分别执行) 12345rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_apprabbitmqctl cluster_statusrabbitmqctl forget_cluster_node rabbit@node2(node1 机器上执行) 镜像队列使用镜像的原因如果 RabbitMQ 集群中只有一个 Broker 节点，那么该节点的失效将导致整体服务的临时性不可用，并且也可能会导致消息的丢失。可以将所有消息都设置为持久化，并且对应队列的durable属性也设置为true，但是这样仍然无法避免由于缓存导致的问题：因为消息在发送之后和被写入磁盘井执行刷盘动作之间存在一个短暂却会产生问题的时间窗。通过 publisherconfirm 机制能够确保客户端知道哪些消息己经存入磁盘，尽管如此，一般不希望遇到因单点故障导致的服务不可用。引入镜像队列(Mirror Queue)的机制，可以将队列镜像到集群中的其他 Broker 节点之上，如果集群中的一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性。 搭建步骤1.启动三台集群节点 2.随便找一个节点添加 policy 3.在 node1 上创建一个队列发送一条消息，队列存在镜像队列 4.停掉 node1 之后发现 node2 成为镜像队列 5.就算整个集群只剩下一台机器了 依然能消费队列里面的消息 说明队列里面的消息被镜像队列传递到相应机器里面了 实现高可用负载均衡整体架构图 Haproxy 实现负载均衡HAProxy 提供高可用性、负载均衡及基于 TCPHTTP 应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案，包括 Twitter,Reddit,StackOverflow,GitHub 在内的多家知名互联网公司在使用。HAProxy 实现了一种事件驱动、单一进程模型，此模型支持非常大的井发连接数。 扩展 nginx,lvs,haproxy 之间的区别: http://www.ha97.com/5646.html Keepalived实现双机试想如果前面配置的 HAProxy 主机突然宕机或者网卡失效，那么虽然 RbbitMQ 集群没有任何故障但是对于外界的客户端来说所有的连接都会被断开结果将是灾难性的为了确保负载均衡服务的可靠性同样显得十分重要，这里就要引入 Keepalived 它能够通过自身健康检查、资源接管功能做高可用(双机热备)，实现故障转移。 Federation Exchange​ (broker 北京)，(broker 深圳)彼此之间相距甚远，网络延迟是一个不得不面对的问题。有一个在北京的业务(Client 北京) 需要连接(broker 北京)，向其中的交换器 exchangeA 发送消息，此时的网络延迟很小，(Client 北京)可以迅速将消息发送至 exchangeA 中，就算在开启了 publisherconfirm 机制或者事务机制的情况下，也可以迅速收到确认信息。此时又有个在深圳的业务(Client 深圳)需要向 exchangeA 发送消息，那么(Client 深圳) (broker 北京)之间有很大的网络延迟，(Client 深圳) 将发送消息至 exchangeA 会经历一定的延迟，尤其是在开启了 publisherconfirm 机制或者事务机制的情况下，(Client 深圳) 会等待很长的延迟时间来接收(broker 北京)的确认信息，进而必然造成这条发送线程的性能降低，甚至造成一定程度上的阻塞。​ 将业务(Client 深圳)部署到北京的机房可以解决这个问题，但是如果(Client 深圳)调用的另些服务都部署在深圳，那么又会引发新的时延问题，总不见得将所有业务全部部署在一个机房，那么容灾又何以实现？这里使用 Federation 插件就可以很好地解决这个问题. 搭建步骤1.需要保证每台节点单独运行 2.在每台机器上开启 federation 相关插件 12rabbitmq-plugins enable rabbitmq_federationrabbitmq-plugins enable rabbitmq_federation_management 3.原理图(先运行 consumer 在 node2 创建 fed_exchange) 4.在 downstream(node2)配置 upstream(node1) 5.添加 policy 6.成功的前提 Federation Queue联邦队列可以在多个 Broker 节点(或者集群)之间为单个队列提供均衡负载的功能。一个联邦队列可以连接一个或者多个上游队列(upstream queue)，并从这些上游队列中获取消息以满足本地消费者消费消息的需求。 搭建步骤1.原理图 2.添加 upstream(同上) 3.添加 policy ShovelFederation 具备的数据转发功能类似，Shovel 够可靠、持续地从一个 Broker 中的队列(作为源端，即source)拉取数据并转发至另一个 Broker 中的交换器(作为目的端，即 destination)。作为源端的队列和作为目的端的交换器可以同时位于同一个 Broker，也可以位于不同的 Broker 上。Shovel 可以翻译为”铲子”，是一种比较形象的比喻，这个”铲子”可以将消息从一方”铲子”另一方。Shovel 行为就像优秀的客户端应用程序能够负责连接源和目的地、负责消息的读写及负责连接失败问题的处理。 搭建步骤1.开启插件(需要的机器都开启) 12rabbitmq-plugins enable rabbitmq_shovelrabbitmq-plugins enable rabbitmq_shovel_management 2.原理图在源头发送的消息直接回进入到目的地队列 3.添加 shovel 源和目的地 RabbitMQ工具类在企业开发过程中，直接使用SpringBoot提供的RabbitTemplate还是略显复杂，通常我们一个系统发送消息基本上也是只依赖于一个交换机和一个队列（延迟消息需单独依赖于延迟交换机），基于此，我们可以把交换机、队列以及路由key等声明直接放在配置文件中，然后封装发送普通消息的工具类，和发送延迟消息的工具类，发送的消息体内容我们可以增加交易码这个概念，消费者通过不同交易码，处理不同的业务。消息体通过泛型，在发消息时声明消息体类型，通过json序列化传输。 工具类使用延迟消息发送项目启动时，直接声明好延迟交换机，延迟队列以及路由key，发送延迟消息只需要一句代码 12345public void sendDelayMsg(@PathVariable String message, @PathVariable Integer delayTime) &#123; log.info(&quot;当前时间：&#123;&#125;,发送一条时长&#123;&#125;毫秒TTL信息给队列QC:&#123;&#125;&quot;, new Date(), delayTime, message); MsgData&lt;String&gt; msgData = new MsgData&lt;&gt;(&quot;0001&quot;, message, &quot;这是我的测试延迟消息！&quot;); EventDispatcherUtil.eventDispatch(msgData, delayTime);&#125; 普通消息发送普通消息通过发布订阅模式实现，其他系统若要接收次消息，只需要声明一个队列然后添加监听，绑定到此交换机上即可，发送普通消息也只需要一句代码实现 12345public void sendFanoutMsg(@PathVariable String message) &#123; log.info(&quot;当前时间：&#123;&#125;,发送一条信息给队列QC:&#123;&#125;&quot;, new Date(), message); MsgData&lt;String&gt; msgData = new MsgData&lt;&gt;(&quot;0001&quot;, message, &quot;这是我的测订阅消息！&quot;); EventDispatcherUtil.eventDispatch(msgData);&#125; RabbitMQ相关面试题如何保证消息不丢失？ 队列和消息持久化：保证MQ宕机了消息不丢失，必须保证在磁盘上才能（3.4.2、3.4.3） 消息发布确认：开启消息发布确认，MQ将消息发送到交换机并且保存在磁盘上之后返回一个确认，此时可以保证生产者发送的消息绝对不丢失。见：9.1 消息回退处理：当消息到达交换机无法路由到队列时，交换机把消息回退给生产者，也可以通过备份交换机实现。见：9.2 消息应答机制：设置为手动应答，保证消费者正确处理完消息，如果处理失败，消息重新入队 集群环境下，添加镜像队列。见：11.2 消息的类型主要是交换机的类型，包括： 直接(direct)：路由类型 主题(topic) 标题(headers) ：已经不用了 扇出(fanout)：发布订阅类型","categories":[{"name":"中间件","slug":"中间件","permalink":"https://zhangyong3214.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"}]}],"categories":[{"name":"面试","slug":"面试","permalink":"https://zhangyong3214.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"教程","slug":"教程","permalink":"https://zhangyong3214.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"笔记","slug":"笔记","permalink":"https://zhangyong3214.github.io/categories/%E7%AC%94%E8%AE%B0/"},{"name":"软件分享","slug":"软件分享","permalink":"https://zhangyong3214.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/"},{"name":"框架","slug":"框架","permalink":"https://zhangyong3214.github.io/categories/%E6%A1%86%E6%9E%B6/"},{"name":"中间件","slug":"中间件","permalink":"https://zhangyong3214.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://zhangyong3214.github.io/tags/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/"},{"name":"软件工具","slug":"软件工具","permalink":"https://zhangyong3214.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"},{"name":"面试","slug":"面试","permalink":"https://zhangyong3214.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"开发","slug":"开发","permalink":"https://zhangyong3214.github.io/tags/%E5%BC%80%E5%8F%91/"}]}